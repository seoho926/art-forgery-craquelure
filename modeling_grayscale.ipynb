{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 17.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.11.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz (289kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 26.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (2.8.0)\n",
      "Building wheels for collected packages: keras-applications\n",
      "  Running setup.py bdist_wheel for keras-applications ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/dd/f2/5d/2689b5547f32c4e258c3b7ccbe7f1d0f2afbb84fb01e830792\n",
      "Successfully built keras-applications\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-19.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 463 images belonging to 2 classes.\n",
      "Found 1839 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'data/Cracks/train'\n",
    "test_data_dir = 'data/Cracks/test'\n",
    "\n",
    "# Get all the data in the directory data/validation, and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(256, 256), batch_size=463, color_mode='grayscale')\n",
    "\n",
    "# Get all the data in the directory data/train, and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(256, 256), batch_size=1839, color_mode='grayscale')\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7F86ED4A50B8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing an image\n",
    "array_to_img(train_images[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1839, 256, 256, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (1839, 256, 256, 1) (1839, 2)\n",
      "test data shape: (463, 256, 256, 1) (463, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking shape of data\n",
    "print('train data shape:', np.shape(train_images), np.shape(train_labels))\n",
    "print('test data shape:', np.shape(test_images), np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img: (1839, 65536)\n",
      "test_img: (463, 65536)\n"
     ]
    }
   ],
   "source": [
    "# Unrowing/reshaping\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "print('train_img:', np.shape(train_img))\n",
    "\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "print('test_img:', np.shape(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the labels\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dutch': 0, 'Flemish': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels final: (1839, 1)\n",
      "test labels final: (463, 1)\n"
     ]
    }
   ],
   "source": [
    "# Transposing the labels\n",
    "train_y = np.reshape(train_labels[:,0], (1839,1))\n",
    "print('train labels final:', np.shape(train_y))\n",
    "\n",
    "test_y = np.reshape(test_labels[:,0], (463,1))\n",
    "print('test labels final:', np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(65536,))) #2 hidden layers\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1287 samples, validate on 552 samples\n",
      "Epoch 1/5\n",
      "1287/1287 [==============================] - 2s 1ms/step - loss: 8.9437 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 2/5\n",
      "1287/1287 [==============================] - 1s 439us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 3/5\n",
      "1287/1287 [==============================] - 1s 431us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 4/5\n",
      "1287/1287 [==============================] - 1s 432us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 5/5\n",
      "1287/1287 [==============================] - 1s 436us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_3: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e755a5e199f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.add(layers.Conv2D(20, (3, 3), activation='relu',\n\u001b[0;32m----> 4\u001b[0;31m                         input_shape=(256, 256,  1)))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_3: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model1 = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 133s 103ms/step - loss: 0.7820 - accuracy: 0.4965 - val_loss: 0.6893 - val_accuracy: 0.5727\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6865 - accuracy: 0.5559 - val_loss: 0.6751 - val_accuracy: 0.5727\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 133s 102ms/step - loss: 0.6688 - accuracy: 0.5559 - val_loss: 0.6672 - val_accuracy: 0.5727\n",
      "Epoch 4/5\n",
      "1297/1297 [==============================] - 133s 103ms/step - loss: 0.6643 - accuracy: 0.5659 - val_loss: 0.6906 - val_accuracy: 0.5566\n",
      "Epoch 5/5\n",
      "1297/1297 [==============================] - 132s 102ms/step - loss: 0.6893 - accuracy: 0.5389 - val_loss: 0.6850 - val_accuracy: 0.5727\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.7362 - accuracy: 0.4811 - val_loss: 0.6913 - val_accuracy: 0.5637\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6900 - accuracy: 0.5598 - val_loss: 0.6872 - val_accuracy: 0.5637\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6883 - accuracy: 0.5598 - val_loss: 0.6815 - val_accuracy: 0.5637\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6872 - accuracy: 0.5598 - val_loss: 0.6840 - val_accuracy: 0.5637\n",
      "Epoch 5/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6876 - accuracy: 0.5598 - val_loss: 0.6818 - val_accuracy: 0.5637\n",
      "Epoch 6/10\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 0.6865 - accuracy: 0.5598 - val_loss: 0.6857 - val_accuracy: 0.5637\n",
      "Epoch 7/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6863 - accuracy: 0.5598 - val_loss: 0.6840 - val_accuracy: 0.5637\n",
      "Epoch 8/10\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6825 - accuracy: 0.5598 - val_loss: 0.6756 - val_accuracy: 0.5637\n",
      "Epoch 9/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6717 - accuracy: 0.5598 - val_loss: 0.6869 - val_accuracy: 0.5637\n",
      "Epoch 10/10\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 0.6845 - accuracy: 0.5598 - val_loss: 0.6769 - val_accuracy: 0.5637\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(100, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(50, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 231s 178ms/step - loss: 0.8093 - accuracy: 0.5544 - val_loss: 0.6850 - val_accuracy: 0.5566\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 229s 176ms/step - loss: 0.6949 - accuracy: 0.5628 - val_loss: 0.6839 - val_accuracy: 0.5566\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 228s 176ms/step - loss: 0.6953 - accuracy: 0.5305 - val_loss: 0.6844 - val_accuracy: 0.5566\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 228s 176ms/step - loss: 0.6849 - accuracy: 0.5628 - val_loss: 0.6793 - val_accuracy: 0.5566\n",
      "Epoch 5/10\n",
      "1297/1297 [==============================] - 229s 177ms/step - loss: 0.6785 - accuracy: 0.5628 - val_loss: 0.6784 - val_accuracy: 0.5566\n",
      "Epoch 6/10\n",
      "1297/1297 [==============================] - 228s 175ms/step - loss: 0.6769 - accuracy: 0.5628 - val_loss: 0.6636 - val_accuracy: 0.5566\n",
      "Epoch 7/10\n",
      " 100/1297 [=>............................] - ETA: 3:04 - loss: 0.6396 - accuracy: 0.6500"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_4 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=3, kernel_size=128, strides=(3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=128, strides=(3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=64, strides=(3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=32, strides=(3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=1, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 241s 186ms/step - loss: 0.9748 - accuracy: 0.4796 - val_loss: 0.6925 - val_accuracy: 0.5530\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 239s 184ms/step - loss: 0.6914 - accuracy: 0.5644 - val_loss: 0.6905 - val_accuracy: 0.5530\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 239s 185ms/step - loss: 0.6888 - accuracy: 0.5644 - val_loss: 0.6886 - val_accuracy: 0.5530\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 240s 185ms/step - loss: 0.6870 - accuracy: 0.5644 - val_loss: 0.6876 - val_accuracy: 0.5530\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1956eb95c245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_5 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=(3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=20, kernel_size=5, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=40, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=80, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=160, kernel_size=1, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6833 - accuracy: 0.5659 - val_loss: 0.6885 - val_accuracy: 0.5530\n",
      "Epoch 2/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6822 - accuracy: 0.5652 - val_loss: 0.7032 - val_accuracy: 0.5530\n",
      "Epoch 3/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6802 - accuracy: 0.5644 - val_loss: 0.6854 - val_accuracy: 0.5530\n",
      "Epoch 4/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6641 - accuracy: 0.5644 - val_loss: 0.6800 - val_accuracy: 0.5530\n",
      "Epoch 5/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6601 - accuracy: 0.5590 - val_loss: 0.6719 - val_accuracy: 0.5314\n",
      "Epoch 6/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6547 - accuracy: 0.5520 - val_loss: 0.6764 - val_accuracy: 0.5278\n",
      "Epoch 7/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6471 - accuracy: 0.5821 - val_loss: 0.6755 - val_accuracy: 0.5206\n",
      "Epoch 8/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6351 - accuracy: 0.5682 - val_loss: 0.6731 - val_accuracy: 0.5566\n",
      "Epoch 9/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6454 - accuracy: 0.6060 - val_loss: 0.6812 - val_accuracy: 0.5278\n",
      "Epoch 10/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5891 - val_loss: 0.6932 - val_accuracy: 0.5296\n",
      "Epoch 11/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6849 - accuracy: 0.5428 - val_loss: 0.6910 - val_accuracy: 0.4847\n",
      "Epoch 12/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6832 - accuracy: 0.5405 - val_loss: 0.6900 - val_accuracy: 0.5332\n",
      "Epoch 13/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6808 - accuracy: 0.5636 - val_loss: 0.6890 - val_accuracy: 0.5224\n",
      "Epoch 14/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6806 - accuracy: 0.5636 - val_loss: 0.6870 - val_accuracy: 0.5530\n",
      "Epoch 15/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5644 - val_loss: 0.6723 - val_accuracy: 0.5422\n",
      "Epoch 16/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6554 - accuracy: 0.5736 - val_loss: 0.6744 - val_accuracy: 0.5135\n",
      "Epoch 17/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6589 - accuracy: 0.5883 - val_loss: 0.6828 - val_accuracy: 0.5458\n",
      "Epoch 18/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6478 - accuracy: 0.5790 - val_loss: 0.6735 - val_accuracy: 0.5206\n",
      "Epoch 19/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6805 - accuracy: 0.5297 - val_loss: 0.6908 - val_accuracy: 0.4973\n",
      "Epoch 20/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6865 - accuracy: 0.5289 - val_loss: 0.6896 - val_accuracy: 0.5278\n",
      "Epoch 21/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6820 - accuracy: 0.5690 - val_loss: 0.6742 - val_accuracy: 0.5332\n",
      "Epoch 22/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6791 - accuracy: 0.5374 - val_loss: 0.7106 - val_accuracy: 0.5458\n",
      "Epoch 23/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5536 - val_loss: 0.6886 - val_accuracy: 0.5530\n",
      "Epoch 24/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6809 - accuracy: 0.5644 - val_loss: 0.6955 - val_accuracy: 0.5530\n",
      "Epoch 25/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6703 - accuracy: 0.5644 - val_loss: 0.6765 - val_accuracy: 0.5530\n",
      "Epoch 26/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6600 - accuracy: 0.5644 - val_loss: 0.6871 - val_accuracy: 0.5530\n",
      "Epoch 27/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6826 - accuracy: 0.5644 - val_loss: 0.6864 - val_accuracy: 0.5530\n",
      "Epoch 28/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6617 - accuracy: 0.5644 - val_loss: 0.6846 - val_accuracy: 0.5530\n",
      "Epoch 29/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6748 - accuracy: 0.5644 - val_loss: 0.6838 - val_accuracy: 0.5530\n",
      "Epoch 30/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6666 - accuracy: 0.5644 - val_loss: 0.6986 - val_accuracy: 0.5530\n",
      "Epoch 31/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6651 - accuracy: 0.5644 - val_loss: 0.6797 - val_accuracy: 0.5530\n",
      "Epoch 32/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6397 - accuracy: 0.5744 - val_loss: 0.6988 - val_accuracy: 0.5458\n",
      "Epoch 33/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6391 - accuracy: 0.5983 - val_loss: 0.6813 - val_accuracy: 0.5673\n",
      "Epoch 34/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.6170 - accuracy: 0.6191 - val_loss: 0.7396 - val_accuracy: 0.5332\n",
      "Epoch 35/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6071 - accuracy: 0.6345 - val_loss: 0.7588 - val_accuracy: 0.5476\n",
      "Epoch 36/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6010 - accuracy: 0.6523 - val_loss: 0.9549 - val_accuracy: 0.5583\n",
      "Epoch 37/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6282 - accuracy: 0.6176 - val_loss: 0.8407 - val_accuracy: 0.5512\n",
      "Epoch 38/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6126 - accuracy: 0.6415 - val_loss: 0.7106 - val_accuracy: 0.5637\n",
      "Epoch 39/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6049 - accuracy: 0.6554 - val_loss: 0.7641 - val_accuracy: 0.5512\n",
      "Epoch 40/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5889 - accuracy: 0.6484 - val_loss: 1.1228 - val_accuracy: 0.5242\n",
      "Epoch 41/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5837 - val_loss: 0.6947 - val_accuracy: 0.5117\n",
      "Epoch 42/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6683 - accuracy: 0.5821 - val_loss: 0.6876 - val_accuracy: 0.5224\n",
      "Epoch 43/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6292 - accuracy: 0.6160 - val_loss: 0.8359 - val_accuracy: 0.5458\n",
      "Epoch 44/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6168 - accuracy: 0.6307 - val_loss: 0.8044 - val_accuracy: 0.5171\n",
      "Epoch 45/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6060 - accuracy: 0.6430 - val_loss: 0.8263 - val_accuracy: 0.5260\n",
      "Epoch 46/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6013 - accuracy: 0.6469 - val_loss: 0.7822 - val_accuracy: 0.5673\n",
      "Epoch 47/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5962 - accuracy: 0.6638 - val_loss: 0.8260 - val_accuracy: 0.5512\n",
      "Epoch 48/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6029 - accuracy: 0.6500 - val_loss: 0.8352 - val_accuracy: 0.5619\n",
      "Epoch 49/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6063 - accuracy: 0.6500 - val_loss: 0.7191 - val_accuracy: 0.5781\n",
      "Epoch 50/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.5967 - accuracy: 0.6631 - val_loss: 0.7523 - val_accuracy: 0.5619\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_6 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((6, 6)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 1.2859 - accuracy: 0.4603 - val_loss: 0.7118 - val_accuracy: 0.4057\n",
      "Epoch 2/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7160 - accuracy: 0.4534 - val_loss: 1.0765 - val_accuracy: 0.5907\n",
      "Epoch 3/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 1.0607 - accuracy: 0.5359 - val_loss: 0.8590 - val_accuracy: 0.4093\n",
      "Epoch 4/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.7960 - accuracy: 0.4518 - val_loss: 0.6941 - val_accuracy: 0.4811\n",
      "Epoch 5/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6934 - accuracy: 0.4904 - val_loss: 0.6943 - val_accuracy: 0.4758\n",
      "Epoch 6/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6921 - accuracy: 0.4927 - val_loss: 0.6756 - val_accuracy: 0.5907\n",
      "Epoch 7/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6833 - accuracy: 0.5482 - val_loss: 0.6894 - val_accuracy: 0.5099\n",
      "Epoch 8/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6841 - accuracy: 0.5582 - val_loss: 0.6727 - val_accuracy: 0.5907\n",
      "Epoch 9/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6838 - accuracy: 0.5482 - val_loss: 0.6749 - val_accuracy: 0.5907\n",
      "Epoch 10/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6858 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 11/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6866 - accuracy: 0.5482 - val_loss: 0.6766 - val_accuracy: 0.5907\n",
      "Epoch 12/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6868 - accuracy: 0.5482 - val_loss: 0.6771 - val_accuracy: 0.5907\n",
      "Epoch 13/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6859 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 14/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6847 - accuracy: 0.5482 - val_loss: 0.6744 - val_accuracy: 0.5907\n",
      "Epoch 15/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6829 - accuracy: 0.5482 - val_loss: 0.6716 - val_accuracy: 0.5907\n",
      "Epoch 16/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6807 - accuracy: 0.5482 - val_loss: 0.6690 - val_accuracy: 0.5907\n",
      "Epoch 17/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6780 - accuracy: 0.5482 - val_loss: 0.6659 - val_accuracy: 0.5907\n",
      "Epoch 18/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6749 - accuracy: 0.5482 - val_loss: 0.6629 - val_accuracy: 0.5907\n",
      "Epoch 19/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6716 - accuracy: 0.5482 - val_loss: 0.6634 - val_accuracy: 0.5907\n",
      "Epoch 20/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6703 - accuracy: 0.5482 - val_loss: 0.6609 - val_accuracy: 0.5889\n",
      "Epoch 21/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6683 - accuracy: 0.5490 - val_loss: 0.6499 - val_accuracy: 0.5907\n",
      "Epoch 22/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6638 - accuracy: 0.5490 - val_loss: 0.6509 - val_accuracy: 0.6140\n",
      "Epoch 23/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6652 - accuracy: 0.5251 - val_loss: 0.6436 - val_accuracy: 0.6086\n",
      "Epoch 24/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6635 - accuracy: 0.5520 - val_loss: 0.6392 - val_accuracy: 0.5943\n",
      "Epoch 25/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6604 - accuracy: 0.5536 - val_loss: 0.6513 - val_accuracy: 0.6014\n",
      "Epoch 26/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.5628 - val_loss: 0.6539 - val_accuracy: 0.5763\n",
      "Epoch 27/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6603 - accuracy: 0.5790 - val_loss: 0.6477 - val_accuracy: 0.5943\n",
      "Epoch 28/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6572 - accuracy: 0.5644 - val_loss: 0.6409 - val_accuracy: 0.5853\n",
      "Epoch 29/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6552 - accuracy: 0.5667 - val_loss: 0.6370 - val_accuracy: 0.6230\n",
      "Epoch 30/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6553 - accuracy: 0.5821 - val_loss: 0.6361 - val_accuracy: 0.5996\n",
      "Epoch 31/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6526 - accuracy: 0.5705 - val_loss: 0.6355 - val_accuracy: 0.6104\n",
      "Epoch 32/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6499 - accuracy: 0.5806 - val_loss: 0.6353 - val_accuracy: 0.6140\n",
      "Epoch 33/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6476 - accuracy: 0.5883 - val_loss: 0.6302 - val_accuracy: 0.6050\n",
      "Epoch 34/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6452 - accuracy: 0.5906 - val_loss: 0.6398 - val_accuracy: 0.6176\n",
      "Epoch 35/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6456 - accuracy: 0.6191 - val_loss: 0.6208 - val_accuracy: 0.6230\n",
      "Epoch 36/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6412 - accuracy: 0.5921 - val_loss: 0.6208 - val_accuracy: 0.6320\n",
      "Epoch 37/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6354 - accuracy: 0.6122 - val_loss: 0.6372 - val_accuracy: 0.5691\n",
      "Epoch 38/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6397 - accuracy: 0.5952 - val_loss: 0.6204 - val_accuracy: 0.6320\n",
      "Epoch 39/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6319 - accuracy: 0.6137 - val_loss: 0.6205 - val_accuracy: 0.6355\n",
      "Epoch 40/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6275 - accuracy: 0.6153 - val_loss: 0.6112 - val_accuracy: 0.6427\n",
      "Epoch 41/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6199 - accuracy: 0.6207 - val_loss: 0.6143 - val_accuracy: 0.6409\n",
      "Epoch 42/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6158 - accuracy: 0.6145 - val_loss: 0.6235 - val_accuracy: 0.5907\n",
      "Epoch 43/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6155 - accuracy: 0.6307 - val_loss: 0.6262 - val_accuracy: 0.6320\n",
      "Epoch 44/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6316 - accuracy: 0.6222 - val_loss: 0.7848 - val_accuracy: 0.4722\n",
      "Epoch 45/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7072 - accuracy: 0.5420 - val_loss: 0.6337 - val_accuracy: 0.6517\n",
      "Epoch 46/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6332 - accuracy: 0.6130 - val_loss: 0.6596 - val_accuracy: 0.5889\n",
      "Epoch 47/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6627 - accuracy: 0.5490 - val_loss: 0.6579 - val_accuracy: 0.5907\n",
      "Epoch 48/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6575 - accuracy: 0.5482 - val_loss: 0.6586 - val_accuracy: 0.5907\n",
      "Epoch 49/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6558 - accuracy: 0.5482 - val_loss: 0.6560 - val_accuracy: 0.5907\n",
      "Epoch 50/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6533 - accuracy: 0.5482 - val_loss: 0.6495 - val_accuracy: 0.5907\n",
      "Epoch 51/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6485 - accuracy: 0.5482 - val_loss: 0.6437 - val_accuracy: 0.5907\n",
      "Epoch 52/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6439 - accuracy: 0.5497 - val_loss: 0.6386 - val_accuracy: 0.6014\n",
      "Epoch 53/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6370 - accuracy: 0.5613 - val_loss: 0.6350 - val_accuracy: 0.6463\n",
      "Epoch 54/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6302 - accuracy: 0.6145 - val_loss: 0.6258 - val_accuracy: 0.6697\n",
      "Epoch 55/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6217 - accuracy: 0.6438 - val_loss: 0.6234 - val_accuracy: 0.6840\n",
      "Epoch 56/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6103 - accuracy: 0.6777 - val_loss: 0.6171 - val_accuracy: 0.6750\n",
      "Epoch 57/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5983 - accuracy: 0.6692 - val_loss: 0.6173 - val_accuracy: 0.6373\n",
      "Epoch 58/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5822 - accuracy: 0.6731 - val_loss: 0.6380 - val_accuracy: 0.6014\n",
      "Epoch 59/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5952 - accuracy: 0.6739 - val_loss: 0.7106 - val_accuracy: 0.4955\n",
      "Epoch 60/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6650 - accuracy: 0.5906 - val_loss: 0.6576 - val_accuracy: 0.6553\n",
      "Epoch 61/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.6507 - val_loss: 0.6570 - val_accuracy: 0.6445\n",
      "Epoch 62/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6430 - accuracy: 0.6315 - val_loss: 0.6276 - val_accuracy: 0.6194\n",
      "Epoch 63/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6075 - accuracy: 0.6369 - val_loss: 0.6378 - val_accuracy: 0.6068\n",
      "Epoch 64/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6107 - accuracy: 0.6261 - val_loss: 0.6196 - val_accuracy: 0.6499\n",
      "Epoch 65/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6041 - accuracy: 0.6554 - val_loss: 0.6248 - val_accuracy: 0.6535\n",
      "Epoch 66/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6072 - accuracy: 0.6500 - val_loss: 0.6215 - val_accuracy: 0.6176\n",
      "Epoch 67/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5951 - accuracy: 0.6677 - val_loss: 0.6263 - val_accuracy: 0.6176\n",
      "Epoch 68/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5890 - accuracy: 0.6677 - val_loss: 0.5969 - val_accuracy: 0.6697\n",
      "Epoch 69/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5739 - accuracy: 0.6746 - val_loss: 0.6498 - val_accuracy: 0.5871\n",
      "Epoch 70/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5736 - accuracy: 0.6847 - val_loss: 0.6041 - val_accuracy: 0.6804\n",
      "Epoch 71/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5836 - accuracy: 0.6608 - val_loss: 0.5980 - val_accuracy: 0.6894\n",
      "Epoch 72/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5632 - accuracy: 0.6901 - val_loss: 0.6024 - val_accuracy: 0.6517\n",
      "Epoch 73/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5423 - accuracy: 0.7101 - val_loss: 0.6210 - val_accuracy: 0.6553\n",
      "Epoch 74/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5698 - accuracy: 0.6715 - val_loss: 0.5848 - val_accuracy: 0.6804\n",
      "Epoch 75/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5447 - accuracy: 0.6893 - val_loss: 0.6066 - val_accuracy: 0.6715\n",
      "Epoch 76/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5553 - accuracy: 0.6862 - val_loss: 0.6095 - val_accuracy: 0.6732\n",
      "Epoch 77/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5486 - accuracy: 0.6931 - val_loss: 0.6334 - val_accuracy: 0.6750\n",
      "Epoch 78/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5488 - accuracy: 0.6870 - val_loss: 0.6385 - val_accuracy: 0.6427\n",
      "Epoch 79/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5333 - accuracy: 0.6870 - val_loss: 0.6291 - val_accuracy: 0.6697\n",
      "Epoch 80/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5164 - accuracy: 0.7093 - val_loss: 0.6236 - val_accuracy: 0.6553\n",
      "Epoch 81/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5032 - accuracy: 0.7155 - val_loss: 0.6364 - val_accuracy: 0.6445\n",
      "Epoch 82/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4938 - accuracy: 0.7247 - val_loss: 0.6467 - val_accuracy: 0.6463\n",
      "Epoch 83/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4965 - accuracy: 0.7294 - val_loss: 0.6474 - val_accuracy: 0.6050\n",
      "Epoch 84/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4819 - accuracy: 0.7294 - val_loss: 0.6352 - val_accuracy: 0.6589\n",
      "Epoch 85/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4732 - accuracy: 0.7386 - val_loss: 0.6344 - val_accuracy: 0.6786\n",
      "Epoch 86/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4626 - accuracy: 0.7448 - val_loss: 0.6572 - val_accuracy: 0.6661\n",
      "Epoch 87/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4486 - accuracy: 0.7625 - val_loss: 0.6715 - val_accuracy: 0.6643\n",
      "Epoch 88/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4360 - accuracy: 0.7641 - val_loss: 0.7322 - val_accuracy: 0.6571\n",
      "Epoch 89/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4441 - accuracy: 0.7679 - val_loss: 0.6906 - val_accuracy: 0.6535\n",
      "Epoch 90/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4262 - accuracy: 0.7918 - val_loss: 0.6937 - val_accuracy: 0.6284\n",
      "Epoch 91/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4567 - accuracy: 0.7641 - val_loss: 0.6842 - val_accuracy: 0.6571\n",
      "Epoch 92/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4473 - accuracy: 0.7502 - val_loss: 0.6850 - val_accuracy: 0.6248\n",
      "Epoch 93/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4393 - accuracy: 0.7564 - val_loss: 0.6552 - val_accuracy: 0.6625\n",
      "Epoch 94/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4129 - accuracy: 0.7918 - val_loss: 0.6953 - val_accuracy: 0.6481\n",
      "Epoch 95/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4211 - accuracy: 0.7795 - val_loss: 0.6442 - val_accuracy: 0.6517\n",
      "Epoch 96/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4090 - accuracy: 0.7926 - val_loss: 0.7113 - val_accuracy: 0.6230\n",
      "Epoch 97/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4137 - accuracy: 0.7857 - val_loss: 0.8536 - val_accuracy: 0.6230\n",
      "Epoch 98/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3917 - accuracy: 0.7826 - val_loss: 0.6926 - val_accuracy: 0.6535\n",
      "Epoch 99/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4027 - accuracy: 0.8011 - val_loss: 0.7286 - val_accuracy: 0.6553\n",
      "Epoch 100/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3983 - accuracy: 0.8026 - val_loss: 0.7429 - val_accuracy: 0.6230\n",
      "Epoch 101/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.3960 - accuracy: 0.8134 - val_loss: 0.7510 - val_accuracy: 0.6122\n",
      "Epoch 102/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4043 - accuracy: 0.7911 - val_loss: 0.7057 - val_accuracy: 0.6643\n",
      "Epoch 103/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3677 - accuracy: 0.8126 - val_loss: 0.7889 - val_accuracy: 0.6355\n",
      "Epoch 104/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3734 - accuracy: 0.8196 - val_loss: 0.7482 - val_accuracy: 0.6427\n",
      "Epoch 105/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3632 - accuracy: 0.8227 - val_loss: 0.7024 - val_accuracy: 0.6661\n",
      "Epoch 106/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3462 - accuracy: 0.8443 - val_loss: 0.7406 - val_accuracy: 0.6661\n",
      "Epoch 107/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3321 - accuracy: 0.8396 - val_loss: 0.7909 - val_accuracy: 0.6607\n",
      "Epoch 108/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3103 - accuracy: 0.8527 - val_loss: 0.8074 - val_accuracy: 0.6571\n",
      "Epoch 109/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3073 - accuracy: 0.8589 - val_loss: 0.8451 - val_accuracy: 0.6535\n",
      "Epoch 110/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3063 - accuracy: 0.8581 - val_loss: 0.9177 - val_accuracy: 0.6589\n",
      "Epoch 111/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2832 - accuracy: 0.8720 - val_loss: 1.1454 - val_accuracy: 0.6427\n",
      "Epoch 112/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5090 - accuracy: 0.7926 - val_loss: 1.1000 - val_accuracy: 0.6409\n",
      "Epoch 113/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6093 - accuracy: 0.7556 - val_loss: 0.7613 - val_accuracy: 0.6463\n",
      "Epoch 114/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4474 - accuracy: 0.7764 - val_loss: 0.7598 - val_accuracy: 0.6302\n",
      "Epoch 115/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4723 - accuracy: 0.7672 - val_loss: 0.7355 - val_accuracy: 0.5763\n",
      "Epoch 116/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5355 - accuracy: 0.7224 - val_loss: 0.7415 - val_accuracy: 0.6050\n",
      "Epoch 117/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4771 - accuracy: 0.7672 - val_loss: 0.7024 - val_accuracy: 0.6194\n",
      "Epoch 118/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4131 - accuracy: 0.8150 - val_loss: 0.6951 - val_accuracy: 0.6409\n",
      "Epoch 119/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3914 - accuracy: 0.8165 - val_loss: 0.6674 - val_accuracy: 0.6320\n",
      "Epoch 120/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3733 - accuracy: 0.8304 - val_loss: 0.6813 - val_accuracy: 0.6373\n",
      "Epoch 121/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3541 - accuracy: 0.8489 - val_loss: 0.7130 - val_accuracy: 0.6463\n",
      "Epoch 122/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3334 - accuracy: 0.8358 - val_loss: 0.7456 - val_accuracy: 0.6517\n",
      "Epoch 123/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3003 - accuracy: 0.8674 - val_loss: 0.8520 - val_accuracy: 0.6607\n",
      "Epoch 124/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2935 - accuracy: 0.8736 - val_loss: 0.9049 - val_accuracy: 0.6409\n",
      "Epoch 125/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2728 - accuracy: 0.8813 - val_loss: 0.9159 - val_accuracy: 0.6409\n",
      "Epoch 126/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2628 - accuracy: 0.8805 - val_loss: 0.9145 - val_accuracy: 0.6373\n",
      "Epoch 127/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2610 - accuracy: 0.8890 - val_loss: 0.8690 - val_accuracy: 0.6571\n",
      "Epoch 128/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2620 - accuracy: 0.8843 - val_loss: 0.8782 - val_accuracy: 0.6571\n",
      "Epoch 129/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2462 - accuracy: 0.8913 - val_loss: 0.9131 - val_accuracy: 0.6571\n",
      "Epoch 130/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2302 - accuracy: 0.9052 - val_loss: 0.9133 - val_accuracy: 0.6643\n",
      "Epoch 131/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.2284 - accuracy: 0.8998 - val_loss: 0.9936 - val_accuracy: 0.6625\n",
      "Epoch 132/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2246 - accuracy: 0.9082 - val_loss: 1.0289 - val_accuracy: 0.6553\n",
      "Epoch 133/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2070 - accuracy: 0.9129 - val_loss: 1.0721 - val_accuracy: 0.6553\n",
      "Epoch 134/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2064 - accuracy: 0.9152 - val_loss: 1.0562 - val_accuracy: 0.6732\n",
      "Epoch 135/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.1948 - accuracy: 0.9229 - val_loss: 0.9783 - val_accuracy: 0.6607\n",
      "Epoch 136/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2023 - accuracy: 0.9183 - val_loss: 0.9592 - val_accuracy: 0.6535\n",
      "Epoch 137/200\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_7 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=1000,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/500\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0542 - acc: 0.9800 - val_loss: 4.8865 - val_acc: 0.5673\n",
      "Epoch 2/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0526 - acc: 0.9830 - val_loss: 3.8052 - val_acc: 0.6122\n",
      "Epoch 3/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0112 - acc: 0.9931 - val_loss: 4.2008 - val_acc: 0.5978\n",
      "Epoch 4/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9946 - val_loss: 4.0361 - val_acc: 0.6302\n",
      "Epoch 5/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0066 - acc: 0.9977 - val_loss: 4.1366 - val_acc: 0.6230\n",
      "Epoch 6/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0841 - acc: 0.9738 - val_loss: 4.3061 - val_acc: 0.5763\n",
      "Epoch 7/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1218 - acc: 0.9653 - val_loss: 3.3528 - val_acc: 0.6104\n",
      "Epoch 8/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0365 - acc: 0.9884 - val_loss: 3.3635 - val_acc: 0.6032\n",
      "Epoch 9/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0114 - acc: 0.9954 - val_loss: 3.3668 - val_acc: 0.6122\n",
      "Epoch 10/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 3.4501 - val_acc: 0.6140\n",
      "Epoch 11/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0100 - acc: 0.9946 - val_loss: 3.5490 - val_acc: 0.6122\n",
      "Epoch 12/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0294 - acc: 0.9861 - val_loss: 3.3413 - val_acc: 0.6140\n",
      "Epoch 13/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0271 - acc: 0.9830 - val_loss: 3.4524 - val_acc: 0.5925\n",
      "Epoch 14/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0129 - acc: 0.9931 - val_loss: 3.6805 - val_acc: 0.6014\n",
      "Epoch 15/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0100 - acc: 0.9954 - val_loss: 3.5620 - val_acc: 0.6050\n",
      "Epoch 16/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 3.5593 - val_acc: 0.6104\n",
      "Epoch 17/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 3.7795 - val_acc: 0.6194\n",
      "Epoch 18/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 3.8217 - val_acc: 0.6086\n",
      "Epoch 19/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.2594 - acc: 0.9044 - val_loss: 1.3718 - val_acc: 0.5440\n",
      "Epoch 20/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1091 - acc: 0.9491 - val_loss: 2.5084 - val_acc: 0.5925\n",
      "Epoch 21/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 3.1336 - val_acc: 0.5961\n",
      "Epoch 22/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0090 - acc: 0.9961 - val_loss: 3.3260 - val_acc: 0.5996\n",
      "Epoch 23/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0109 - acc: 0.9954 - val_loss: 3.4304 - val_acc: 0.5978\n",
      "Epoch 24/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0098 - acc: 0.9961 - val_loss: 3.6061 - val_acc: 0.6050\n",
      "Epoch 25/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 3.6194 - val_acc: 0.6014\n",
      "Epoch 26/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0952 - acc: 0.9692 - val_loss: 2.7855 - val_acc: 0.6050\n",
      "Epoch 27/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0720 - acc: 0.9776 - val_loss: 2.5212 - val_acc: 0.6230\n",
      "Epoch 28/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9907 - val_loss: 2.8383 - val_acc: 0.6176\n",
      "Epoch 29/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 3.0252 - val_acc: 0.6158\n",
      "Epoch 30/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0039 - acc: 0.9992 - val_loss: 3.1664 - val_acc: 0.6068\n",
      "Epoch 31/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 3.2672 - val_acc: 0.6032\n",
      "Epoch 32/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 3.3670 - val_acc: 0.6050\n",
      "Epoch 33/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 3.4478 - val_acc: 0.6032\n",
      "Epoch 34/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0468 - acc: 0.9900 - val_loss: 3.4187 - val_acc: 0.5961\n",
      "Epoch 35/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3658 - acc: 0.9067 - val_loss: 2.0230 - val_acc: 0.5925\n",
      "Epoch 36/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0486 - acc: 0.9823 - val_loss: 2.8499 - val_acc: 0.5799\n",
      "Epoch 37/500\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 3.0220 - val_acc: 0.6122\n",
      "Epoch 38/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0088 - acc: 0.9969 - val_loss: 3.1904 - val_acc: 0.5925\n",
      "Epoch 39/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3246 - acc: 0.8975 - val_loss: 2.0007 - val_acc: 0.5943\n",
      "Epoch 40/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0669 - acc: 0.9815 - val_loss: 2.5389 - val_acc: 0.5817\n",
      "Epoch 41/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9846 - val_loss: 2.4448 - val_acc: 0.6086\n",
      "Epoch 42/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0288 - acc: 0.9892 - val_loss: 2.6544 - val_acc: 0.5925\n",
      "Epoch 43/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0257 - acc: 0.9900 - val_loss: 2.8005 - val_acc: 0.5978\n",
      "Epoch 44/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0178 - acc: 0.9884 - val_loss: 2.9891 - val_acc: 0.5943\n",
      "Epoch 45/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9931 - val_loss: 3.1611 - val_acc: 0.5925\n",
      "Epoch 46/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 3.2269 - val_acc: 0.5996\n",
      "Epoch 47/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 3.2916 - val_acc: 0.5996\n",
      "Epoch 48/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0102 - acc: 0.9938 - val_loss: 3.1307 - val_acc: 0.5907\n",
      "Epoch 49/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0987 - acc: 0.9522 - val_loss: 2.6610 - val_acc: 0.5601\n",
      "Epoch 50/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9815 - val_loss: 2.7463 - val_acc: 0.5907\n",
      "Epoch 51/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9907 - val_loss: 3.0980 - val_acc: 0.5943\n",
      "Epoch 52/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9946 - val_loss: 3.2145 - val_acc: 0.6068\n",
      "Epoch 53/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0576 - acc: 0.9738 - val_loss: 3.0086 - val_acc: 0.5548\n",
      "Epoch 54/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0582 - acc: 0.9738 - val_loss: 3.0022 - val_acc: 0.6068\n",
      "Epoch 55/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 3.0723 - val_acc: 0.6140\n",
      "Epoch 56/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0122 - acc: 0.9977 - val_loss: 3.0839 - val_acc: 0.6104\n",
      "Epoch 57/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0101 - acc: 0.9961 - val_loss: 3.2881 - val_acc: 0.6212\n",
      "Epoch 58/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0450 - acc: 0.9807 - val_loss: 2.6459 - val_acc: 0.5727\n",
      "Epoch 59/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0814 - acc: 0.9630 - val_loss: 2.8003 - val_acc: 0.6068\n",
      "Epoch 60/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0084 - acc: 0.9961 - val_loss: 3.0562 - val_acc: 0.6068\n",
      "Epoch 61/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0150 - acc: 0.9900 - val_loss: 3.0624 - val_acc: 0.6104\n",
      "Epoch 62/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0166 - acc: 0.9884 - val_loss: 3.3788 - val_acc: 0.6104\n",
      "Epoch 63/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 3.3620 - val_acc: 0.6284\n",
      "Epoch 64/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0077 - acc: 0.9961 - val_loss: 3.4234 - val_acc: 0.6302\n",
      "Epoch 65/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0209 - acc: 0.9938 - val_loss: 3.2064 - val_acc: 0.5907\n",
      "Epoch 66/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.9869 - val_loss: 3.2074 - val_acc: 0.6086\n",
      "Epoch 67/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0869 - acc: 0.9668 - val_loss: 2.8276 - val_acc: 0.5619\n",
      "Epoch 68/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0555 - acc: 0.9807 - val_loss: 2.6582 - val_acc: 0.5853\n",
      "Epoch 69/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0174 - acc: 0.9900 - val_loss: 2.9639 - val_acc: 0.6104\n",
      "Epoch 70/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0115 - acc: 0.9931 - val_loss: 2.8999 - val_acc: 0.6194\n",
      "Epoch 71/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 2.9881 - val_acc: 0.6176\n",
      "Epoch 72/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0628 - acc: 0.9707 - val_loss: 2.9394 - val_acc: 0.5619\n",
      "Epoch 73/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0514 - acc: 0.9800 - val_loss: 3.0135 - val_acc: 0.5889\n",
      "Epoch 74/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0300 - acc: 0.9854 - val_loss: 2.9444 - val_acc: 0.6212\n",
      "Epoch 75/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 3.1245 - val_acc: 0.6266\n",
      "Epoch 76/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0108 - acc: 0.9954 - val_loss: 3.2596 - val_acc: 0.6122\n",
      "Epoch 77/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9638 - val_loss: 2.8438 - val_acc: 0.5889\n",
      "Epoch 78/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0296 - acc: 0.9869 - val_loss: 3.0837 - val_acc: 0.5853\n",
      "Epoch 79/500\n",
      "1024/1297 [======================>.......] - ETA: 0s - loss: 0.1132 - acc: 0.9443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-dc19821f9d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_8 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=500,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1287 samples, validate on 552 samples\n",
      "Epoch 1/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.8795 - acc: 0.5338 - val_loss: 0.7437 - val_acc: 0.5525\n",
      "Epoch 2/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.7255 - acc: 0.5548 - val_loss: 0.7317 - val_acc: 0.5489\n",
      "Epoch 3/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.7010 - acc: 0.5726 - val_loss: 0.7255 - val_acc: 0.5217\n",
      "Epoch 4/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6928 - acc: 0.5789 - val_loss: 0.7298 - val_acc: 0.5362\n",
      "Epoch 5/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6868 - acc: 0.5781 - val_loss: 0.7219 - val_acc: 0.5399\n",
      "Epoch 6/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6751 - acc: 0.5952 - val_loss: 0.7111 - val_acc: 0.5616\n",
      "Epoch 7/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6693 - acc: 0.5944 - val_loss: 0.7115 - val_acc: 0.5489\n",
      "Epoch 8/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6684 - acc: 0.5921 - val_loss: 0.7063 - val_acc: 0.5580\n",
      "Epoch 9/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6611 - acc: 0.5983 - val_loss: 0.6992 - val_acc: 0.5652\n",
      "Epoch 10/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6579 - acc: 0.6045 - val_loss: 0.7040 - val_acc: 0.5725\n",
      "Epoch 11/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6572 - acc: 0.6123 - val_loss: 0.6964 - val_acc: 0.5598\n",
      "Epoch 12/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6532 - acc: 0.5967 - val_loss: 0.6977 - val_acc: 0.5435\n",
      "Epoch 13/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6483 - acc: 0.6099 - val_loss: 0.6961 - val_acc: 0.5489\n",
      "Epoch 14/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6457 - acc: 0.6115 - val_loss: 0.6915 - val_acc: 0.5634\n",
      "Epoch 15/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6442 - acc: 0.6076 - val_loss: 0.6957 - val_acc: 0.5507\n",
      "Epoch 16/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6425 - acc: 0.6185 - val_loss: 0.6889 - val_acc: 0.5707\n",
      "Epoch 17/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6413 - acc: 0.6146 - val_loss: 0.6920 - val_acc: 0.5616\n",
      "Epoch 18/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6373 - acc: 0.6239 - val_loss: 0.6966 - val_acc: 0.5707\n",
      "Epoch 19/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6405 - acc: 0.6131 - val_loss: 0.6901 - val_acc: 0.5562\n",
      "Epoch 20/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6367 - acc: 0.6239 - val_loss: 0.6945 - val_acc: 0.5489\n",
      "Epoch 21/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6355 - acc: 0.6325 - val_loss: 0.6873 - val_acc: 0.5725\n",
      "Epoch 22/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6333 - acc: 0.6232 - val_loss: 0.6879 - val_acc: 0.5634\n",
      "Epoch 23/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6312 - acc: 0.6255 - val_loss: 0.6907 - val_acc: 0.5598\n",
      "Epoch 24/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6308 - acc: 0.6247 - val_loss: 0.6856 - val_acc: 0.5634\n",
      "Epoch 25/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6290 - acc: 0.6301 - val_loss: 0.6846 - val_acc: 0.5670\n",
      "Epoch 26/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6286 - acc: 0.6270 - val_loss: 0.6865 - val_acc: 0.5670\n",
      "Epoch 27/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6264 - acc: 0.6294 - val_loss: 0.6862 - val_acc: 0.5670\n",
      "Epoch 28/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6260 - acc: 0.6356 - val_loss: 0.6868 - val_acc: 0.5725\n",
      "Epoch 29/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6208 - acc: 0.6457 - val_loss: 0.6880 - val_acc: 0.5652\n",
      "Epoch 30/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6202 - acc: 0.6434 - val_loss: 0.6919 - val_acc: 0.5634\n",
      "Epoch 31/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6221 - acc: 0.6356 - val_loss: 0.6824 - val_acc: 0.5670\n",
      "Epoch 32/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6218 - acc: 0.6441 - val_loss: 0.6833 - val_acc: 0.5725\n",
      "Epoch 33/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6225 - acc: 0.6441 - val_loss: 0.6872 - val_acc: 0.5652\n",
      "Epoch 34/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6164 - acc: 0.6410 - val_loss: 0.6880 - val_acc: 0.5652\n",
      "Epoch 35/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6125 - acc: 0.6503 - val_loss: 0.6878 - val_acc: 0.5688\n",
      "Epoch 36/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6152 - acc: 0.6441 - val_loss: 0.6809 - val_acc: 0.5688\n",
      "Epoch 37/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6114 - acc: 0.6550 - val_loss: 0.6862 - val_acc: 0.5670\n",
      "Epoch 38/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6148 - acc: 0.6418 - val_loss: 0.6839 - val_acc: 0.5616\n",
      "Epoch 39/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6093 - acc: 0.6581 - val_loss: 0.6806 - val_acc: 0.5707\n",
      "Epoch 40/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6084 - acc: 0.6542 - val_loss: 0.6813 - val_acc: 0.5688\n",
      "Epoch 41/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6079 - acc: 0.6472 - val_loss: 0.6832 - val_acc: 0.5652\n",
      "Epoch 42/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6070 - acc: 0.6566 - val_loss: 0.6877 - val_acc: 0.5761\n",
      "Epoch 43/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6052 - acc: 0.6597 - val_loss: 0.6821 - val_acc: 0.5707\n",
      "Epoch 44/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6047 - acc: 0.6643 - val_loss: 0.6804 - val_acc: 0.5761\n",
      "Epoch 45/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6030 - acc: 0.6573 - val_loss: 0.6840 - val_acc: 0.5634\n",
      "Epoch 46/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6031 - acc: 0.6566 - val_loss: 0.6817 - val_acc: 0.5761\n",
      "Epoch 47/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6049 - acc: 0.6511 - val_loss: 0.6857 - val_acc: 0.5725\n",
      "Epoch 48/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.6010 - acc: 0.6597 - val_loss: 0.6832 - val_acc: 0.5743\n",
      "Epoch 49/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5981 - acc: 0.6682 - val_loss: 0.6798 - val_acc: 0.5743\n",
      "Epoch 50/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5960 - acc: 0.6651 - val_loss: 0.6804 - val_acc: 0.5743\n",
      "Epoch 51/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5964 - acc: 0.6597 - val_loss: 0.6844 - val_acc: 0.5652\n",
      "Epoch 52/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5943 - acc: 0.6636 - val_loss: 0.6849 - val_acc: 0.5707\n",
      "Epoch 53/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5936 - acc: 0.6667 - val_loss: 0.6871 - val_acc: 0.5652\n",
      "Epoch 54/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5938 - acc: 0.6612 - val_loss: 0.6884 - val_acc: 0.5797\n",
      "Epoch 55/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5917 - acc: 0.6713 - val_loss: 0.6885 - val_acc: 0.5652\n",
      "Epoch 56/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5927 - acc: 0.6682 - val_loss: 0.6836 - val_acc: 0.5652\n",
      "Epoch 57/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5931 - acc: 0.6636 - val_loss: 0.6869 - val_acc: 0.5851\n",
      "Epoch 58/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5877 - acc: 0.6651 - val_loss: 0.6830 - val_acc: 0.5815\n",
      "Epoch 59/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5863 - acc: 0.6706 - val_loss: 0.6828 - val_acc: 0.5815\n",
      "Epoch 60/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5858 - acc: 0.6636 - val_loss: 0.6840 - val_acc: 0.5797\n",
      "Epoch 61/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5856 - acc: 0.6698 - val_loss: 0.6937 - val_acc: 0.5725\n",
      "Epoch 62/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5847 - acc: 0.6768 - val_loss: 0.6862 - val_acc: 0.5815\n",
      "Epoch 63/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5825 - acc: 0.6760 - val_loss: 0.6870 - val_acc: 0.5688\n",
      "Epoch 64/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5802 - acc: 0.6799 - val_loss: 0.6856 - val_acc: 0.5815\n",
      "Epoch 65/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5784 - acc: 0.6900 - val_loss: 0.6881 - val_acc: 0.5815\n",
      "Epoch 66/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5804 - acc: 0.6791 - val_loss: 0.6841 - val_acc: 0.5815\n",
      "Epoch 67/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5779 - acc: 0.6783 - val_loss: 0.6854 - val_acc: 0.5797\n",
      "Epoch 68/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5775 - acc: 0.6830 - val_loss: 0.6865 - val_acc: 0.5851\n",
      "Epoch 69/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5760 - acc: 0.6783 - val_loss: 0.6847 - val_acc: 0.5797\n",
      "Epoch 70/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5721 - acc: 0.6931 - val_loss: 0.6914 - val_acc: 0.5815\n",
      "Epoch 71/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5732 - acc: 0.6814 - val_loss: 0.6874 - val_acc: 0.5797\n",
      "Epoch 72/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5737 - acc: 0.6822 - val_loss: 0.6865 - val_acc: 0.5833\n",
      "Epoch 73/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5735 - acc: 0.6869 - val_loss: 0.6859 - val_acc: 0.5870\n",
      "Epoch 74/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5697 - acc: 0.6892 - val_loss: 0.6870 - val_acc: 0.5851\n",
      "Epoch 75/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5701 - acc: 0.6970 - val_loss: 0.6906 - val_acc: 0.5870\n",
      "Epoch 76/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5671 - acc: 0.6884 - val_loss: 0.6907 - val_acc: 0.5870\n",
      "Epoch 77/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5672 - acc: 0.6962 - val_loss: 0.6880 - val_acc: 0.5797\n",
      "Epoch 78/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5650 - acc: 0.6915 - val_loss: 0.6922 - val_acc: 0.5779\n",
      "Epoch 79/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5633 - acc: 0.6939 - val_loss: 0.6865 - val_acc: 0.5797\n",
      "Epoch 80/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5632 - acc: 0.6946 - val_loss: 0.6923 - val_acc: 0.5833\n",
      "Epoch 81/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5628 - acc: 0.6923 - val_loss: 0.6932 - val_acc: 0.5906\n",
      "Epoch 82/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5656 - acc: 0.6853 - val_loss: 0.6928 - val_acc: 0.5924\n",
      "Epoch 83/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5580 - acc: 0.7040 - val_loss: 0.6942 - val_acc: 0.5924\n",
      "Epoch 84/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5581 - acc: 0.7024 - val_loss: 0.6916 - val_acc: 0.5870\n",
      "Epoch 85/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5592 - acc: 0.7016 - val_loss: 0.6918 - val_acc: 0.5870\n",
      "Epoch 86/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5630 - acc: 0.6977 - val_loss: 0.6909 - val_acc: 0.5833\n",
      "Epoch 87/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5548 - acc: 0.7009 - val_loss: 0.6879 - val_acc: 0.5833\n",
      "Epoch 88/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5548 - acc: 0.7055 - val_loss: 0.6935 - val_acc: 0.5906\n",
      "Epoch 89/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5518 - acc: 0.7040 - val_loss: 0.7003 - val_acc: 0.5870\n",
      "Epoch 90/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5538 - acc: 0.7001 - val_loss: 0.6956 - val_acc: 0.5978\n",
      "Epoch 91/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5521 - acc: 0.7024 - val_loss: 0.6948 - val_acc: 0.5924\n",
      "Epoch 92/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5520 - acc: 0.7032 - val_loss: 0.6955 - val_acc: 0.5870\n",
      "Epoch 93/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5516 - acc: 0.6962 - val_loss: 0.6940 - val_acc: 0.5870\n",
      "Epoch 94/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5493 - acc: 0.7047 - val_loss: 0.7054 - val_acc: 0.5652\n",
      "Epoch 95/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5487 - acc: 0.7086 - val_loss: 0.6932 - val_acc: 0.5870\n",
      "Epoch 96/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5501 - acc: 0.7009 - val_loss: 0.6925 - val_acc: 0.5851\n",
      "Epoch 97/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5448 - acc: 0.7125 - val_loss: 0.6952 - val_acc: 0.5870\n",
      "Epoch 98/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5441 - acc: 0.7110 - val_loss: 0.6969 - val_acc: 0.5924\n",
      "Epoch 99/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5504 - acc: 0.7032 - val_loss: 0.6964 - val_acc: 0.5978\n",
      "Epoch 100/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5422 - acc: 0.7078 - val_loss: 0.6966 - val_acc: 0.5960\n",
      "Epoch 101/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5414 - acc: 0.7156 - val_loss: 0.6971 - val_acc: 0.5906\n",
      "Epoch 102/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5416 - acc: 0.7055 - val_loss: 0.7009 - val_acc: 0.5924\n",
      "Epoch 103/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5375 - acc: 0.7148 - val_loss: 0.6949 - val_acc: 0.5888\n",
      "Epoch 104/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5365 - acc: 0.7102 - val_loss: 0.7018 - val_acc: 0.6014\n",
      "Epoch 105/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5359 - acc: 0.7195 - val_loss: 0.6992 - val_acc: 0.5906\n",
      "Epoch 106/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5352 - acc: 0.7086 - val_loss: 0.7014 - val_acc: 0.5996\n",
      "Epoch 107/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5403 - acc: 0.7226 - val_loss: 0.7081 - val_acc: 0.5707\n",
      "Epoch 108/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5362 - acc: 0.7047 - val_loss: 0.7018 - val_acc: 0.5906\n",
      "Epoch 109/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5335 - acc: 0.7141 - val_loss: 0.6992 - val_acc: 0.5833\n",
      "Epoch 110/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5320 - acc: 0.7148 - val_loss: 0.7005 - val_acc: 0.6033\n",
      "Epoch 111/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5314 - acc: 0.7086 - val_loss: 0.6984 - val_acc: 0.5942\n",
      "Epoch 112/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5312 - acc: 0.7110 - val_loss: 0.7097 - val_acc: 0.5707\n",
      "Epoch 113/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5295 - acc: 0.7133 - val_loss: 0.6971 - val_acc: 0.5924\n",
      "Epoch 114/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5280 - acc: 0.7288 - val_loss: 0.7023 - val_acc: 0.5906\n",
      "Epoch 115/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5255 - acc: 0.7117 - val_loss: 0.7079 - val_acc: 0.5851\n",
      "Epoch 116/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5237 - acc: 0.7218 - val_loss: 0.7068 - val_acc: 0.5906\n",
      "Epoch 117/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5241 - acc: 0.7280 - val_loss: 0.7035 - val_acc: 0.5942\n",
      "Epoch 118/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5244 - acc: 0.7211 - val_loss: 0.7083 - val_acc: 0.5978\n",
      "Epoch 119/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5214 - acc: 0.7203 - val_loss: 0.7057 - val_acc: 0.5996\n",
      "Epoch 120/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5229 - acc: 0.7218 - val_loss: 0.7056 - val_acc: 0.5906\n",
      "Epoch 121/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5200 - acc: 0.7350 - val_loss: 0.7100 - val_acc: 0.5978\n",
      "Epoch 122/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5170 - acc: 0.7273 - val_loss: 0.7104 - val_acc: 0.5924\n",
      "Epoch 123/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5180 - acc: 0.7343 - val_loss: 0.7087 - val_acc: 0.5924\n",
      "Epoch 124/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5162 - acc: 0.7319 - val_loss: 0.7043 - val_acc: 0.5960\n",
      "Epoch 125/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5130 - acc: 0.7350 - val_loss: 0.7094 - val_acc: 0.5942\n",
      "Epoch 126/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5130 - acc: 0.7335 - val_loss: 0.7079 - val_acc: 0.6033\n",
      "Epoch 127/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5162 - acc: 0.7288 - val_loss: 0.7082 - val_acc: 0.5978\n",
      "Epoch 128/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5115 - acc: 0.7358 - val_loss: 0.7157 - val_acc: 0.5924\n",
      "Epoch 129/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5135 - acc: 0.7405 - val_loss: 0.7152 - val_acc: 0.5851\n",
      "Epoch 130/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5088 - acc: 0.7343 - val_loss: 0.7120 - val_acc: 0.6087\n",
      "Epoch 131/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5087 - acc: 0.7312 - val_loss: 0.7143 - val_acc: 0.5815\n",
      "Epoch 132/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5089 - acc: 0.7312 - val_loss: 0.7182 - val_acc: 0.5906\n",
      "Epoch 133/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5092 - acc: 0.7343 - val_loss: 0.7136 - val_acc: 0.5996\n",
      "Epoch 134/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5121 - acc: 0.7242 - val_loss: 0.7143 - val_acc: 0.5996\n",
      "Epoch 135/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5048 - acc: 0.7420 - val_loss: 0.7182 - val_acc: 0.5942\n",
      "Epoch 136/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5082 - acc: 0.7397 - val_loss: 0.7129 - val_acc: 0.5996\n",
      "Epoch 137/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5006 - acc: 0.7382 - val_loss: 0.7241 - val_acc: 0.5924\n",
      "Epoch 138/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5035 - acc: 0.7413 - val_loss: 0.7149 - val_acc: 0.5960\n",
      "Epoch 139/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5004 - acc: 0.7475 - val_loss: 0.7291 - val_acc: 0.5779\n",
      "Epoch 140/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.5004 - acc: 0.7389 - val_loss: 0.7216 - val_acc: 0.5888\n",
      "Epoch 141/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.4958 - acc: 0.7467 - val_loss: 0.7183 - val_acc: 0.6033\n",
      "Epoch 142/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.4947 - acc: 0.7529 - val_loss: 0.7223 - val_acc: 0.5978\n",
      "Epoch 143/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4940 - acc: 0.7576 - val_loss: 0.7252 - val_acc: 0.5924\n",
      "Epoch 144/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4949 - acc: 0.7436 - val_loss: 0.7200 - val_acc: 0.6051\n",
      "Epoch 145/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4925 - acc: 0.7451 - val_loss: 0.7275 - val_acc: 0.5960\n",
      "Epoch 146/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4949 - acc: 0.7483 - val_loss: 0.7192 - val_acc: 0.5978\n",
      "Epoch 147/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4913 - acc: 0.7584 - val_loss: 0.7243 - val_acc: 0.5942\n",
      "Epoch 148/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4934 - acc: 0.7529 - val_loss: 0.7231 - val_acc: 0.5996\n",
      "Epoch 149/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4874 - acc: 0.7599 - val_loss: 0.7232 - val_acc: 0.5942\n",
      "Epoch 150/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4873 - acc: 0.7560 - val_loss: 0.7267 - val_acc: 0.5942\n",
      "Epoch 151/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4862 - acc: 0.7607 - val_loss: 0.7247 - val_acc: 0.5996\n",
      "Epoch 152/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4825 - acc: 0.7552 - val_loss: 0.7323 - val_acc: 0.5851\n",
      "Epoch 153/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4827 - acc: 0.7568 - val_loss: 0.7390 - val_acc: 0.5761\n",
      "Epoch 154/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4819 - acc: 0.7576 - val_loss: 0.7249 - val_acc: 0.6051\n",
      "Epoch 155/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4837 - acc: 0.7552 - val_loss: 0.7239 - val_acc: 0.6033\n",
      "Epoch 156/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4808 - acc: 0.7638 - val_loss: 0.7297 - val_acc: 0.6033\n",
      "Epoch 157/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4807 - acc: 0.7700 - val_loss: 0.7338 - val_acc: 0.6014\n",
      "Epoch 158/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4784 - acc: 0.7646 - val_loss: 0.7354 - val_acc: 0.5888\n",
      "Epoch 159/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4786 - acc: 0.7552 - val_loss: 0.7340 - val_acc: 0.5942\n",
      "Epoch 160/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4770 - acc: 0.7669 - val_loss: 0.7301 - val_acc: 0.6051\n",
      "Epoch 161/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4732 - acc: 0.7677 - val_loss: 0.7288 - val_acc: 0.6105\n",
      "Epoch 162/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4733 - acc: 0.7700 - val_loss: 0.7317 - val_acc: 0.6087\n",
      "Epoch 163/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4709 - acc: 0.7692 - val_loss: 0.7375 - val_acc: 0.5996\n",
      "Epoch 164/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4693 - acc: 0.7778 - val_loss: 0.7326 - val_acc: 0.6033\n",
      "Epoch 165/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4672 - acc: 0.7739 - val_loss: 0.7405 - val_acc: 0.5942\n",
      "Epoch 166/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4718 - acc: 0.7638 - val_loss: 0.7297 - val_acc: 0.6087\n",
      "Epoch 167/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4674 - acc: 0.7669 - val_loss: 0.7423 - val_acc: 0.6051\n",
      "Epoch 168/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4689 - acc: 0.7731 - val_loss: 0.7393 - val_acc: 0.6051\n",
      "Epoch 169/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4652 - acc: 0.7622 - val_loss: 0.7462 - val_acc: 0.5906\n",
      "Epoch 170/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4618 - acc: 0.7879 - val_loss: 0.7398 - val_acc: 0.6069\n",
      "Epoch 171/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4658 - acc: 0.7630 - val_loss: 0.7421 - val_acc: 0.6033\n",
      "Epoch 172/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4662 - acc: 0.7661 - val_loss: 0.7395 - val_acc: 0.6014\n",
      "Epoch 173/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4630 - acc: 0.7700 - val_loss: 0.7442 - val_acc: 0.5960\n",
      "Epoch 174/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4574 - acc: 0.7739 - val_loss: 0.7480 - val_acc: 0.5960\n",
      "Epoch 175/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4570 - acc: 0.7747 - val_loss: 0.7469 - val_acc: 0.6051\n",
      "Epoch 176/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4572 - acc: 0.7817 - val_loss: 0.7468 - val_acc: 0.5978\n",
      "Epoch 177/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4535 - acc: 0.7824 - val_loss: 0.7467 - val_acc: 0.6087\n",
      "Epoch 178/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4540 - acc: 0.7824 - val_loss: 0.7441 - val_acc: 0.6069\n",
      "Epoch 179/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4542 - acc: 0.7894 - val_loss: 0.7494 - val_acc: 0.6105\n",
      "Epoch 180/1200\n",
      "1287/1287 [==============================] - 2s 2ms/step - loss: 0.4610 - acc: 0.7723 - val_loss: 0.7518 - val_acc: 0.6014\n",
      "Epoch 181/1200\n",
      " 704/1287 [===============>..............] - ETA: 0s - loss: 0.4539 - acc: 0.7812"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.00001)\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.00001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_9 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=1200,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
