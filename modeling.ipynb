{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 17.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.11.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz (289kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 26.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (2.8.0)\n",
      "Building wheels for collected packages: keras-applications\n",
      "  Running setup.py bdist_wheel for keras-applications ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/dd/f2/5d/2689b5547f32c4e258c3b7ccbe7f1d0f2afbb84fb01e830792\n",
      "Successfully built keras-applications\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-19.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 463 images belonging to 2 classes.\n",
      "Found 1854 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'data/Cracks/train'\n",
    "test_data_dir = 'data/Cracks/test'\n",
    "\n",
    "# Get all the data in the directory data/validation, and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(256, 256), batch_size=463, color_mode='grayscale')\n",
    "\n",
    "# Get all the data in the directory data/train, and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(256, 256), batch_size=1854, color_mode='grayscale')\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7F50A6D3F9E8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing an image\n",
    "array_to_img(train_images[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (1854, 256, 256, 1) (1854, 2)\n",
      "test data shape: (463, 256, 256, 1) (463, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking shape of data\n",
    "print('train data shape:', np.shape(train_images), np.shape(train_labels))\n",
    "print('test data shape:', np.shape(test_images), np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img: (1854, 65536)\n",
      "test_img: (463, 65536)\n"
     ]
    }
   ],
   "source": [
    "# Unrowing/reshaping\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "print('train_img:', np.shape(train_img))\n",
    "\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "print('test_img:', np.shape(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the labels\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dutch': 0, 'Flemish': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels final: (1854, 1)\n",
      "test labels final: (463, 1)\n"
     ]
    }
   ],
   "source": [
    "# Transposing the labels\n",
    "train_y = np.reshape(train_labels[:,0], (1854,1))\n",
    "print('train labels final:', np.shape(train_y))\n",
    "\n",
    "test_y = np.reshape(test_labels[:,0], (463,1))\n",
    "print('test labels final:', np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(65536,))) #2 hidden layers\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 1s 580us/step - loss: 7.6516 - accuracy: 0.5112 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 0s 377us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 0s 374us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 4/5\n",
      "1297/1297 [==============================] - 0s 372us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 5/5\n",
      "1297/1297 [==============================] - 0s 370us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First CNN\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(100, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 673s 519ms/step - loss: 8.6901 - accuracy: 0.4549 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 668s 515ms/step - loss: 8.9600 - accuracy: 0.4441 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 664s 512ms/step - loss: 8.9600 - accuracy: 0.4441 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 4/5\n",
      " 900/1297 [===================>..........] - ETA: 3:01 - loss: 9.1157 - accuracy: 0.4344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b2a4256263c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 8.5945 - accuracy: 0.4549 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 8.9600 - accuracy: 0.4441 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 3/5\n",
      " 350/1297 [=======>......................] - ETA: 1:25 - loss: 8.8880 - accuracy: 0.4486"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3df4d6f24b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 133s 103ms/step - loss: 0.7820 - accuracy: 0.4965 - val_loss: 0.6893 - val_accuracy: 0.5727\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6865 - accuracy: 0.5559 - val_loss: 0.6751 - val_accuracy: 0.5727\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 133s 102ms/step - loss: 0.6688 - accuracy: 0.5559 - val_loss: 0.6672 - val_accuracy: 0.5727\n",
      "Epoch 4/5\n",
      "1297/1297 [==============================] - 133s 103ms/step - loss: 0.6643 - accuracy: 0.5659 - val_loss: 0.6906 - val_accuracy: 0.5566\n",
      "Epoch 5/5\n",
      "1297/1297 [==============================] - 132s 102ms/step - loss: 0.6893 - accuracy: 0.5389 - val_loss: 0.6850 - val_accuracy: 0.5727\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.7362 - accuracy: 0.4811 - val_loss: 0.6913 - val_accuracy: 0.5637\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6900 - accuracy: 0.5598 - val_loss: 0.6872 - val_accuracy: 0.5637\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6883 - accuracy: 0.5598 - val_loss: 0.6815 - val_accuracy: 0.5637\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6872 - accuracy: 0.5598 - val_loss: 0.6840 - val_accuracy: 0.5637\n",
      "Epoch 5/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6876 - accuracy: 0.5598 - val_loss: 0.6818 - val_accuracy: 0.5637\n",
      "Epoch 6/10\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 0.6865 - accuracy: 0.5598 - val_loss: 0.6857 - val_accuracy: 0.5637\n",
      "Epoch 7/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6863 - accuracy: 0.5598 - val_loss: 0.6840 - val_accuracy: 0.5637\n",
      "Epoch 8/10\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6825 - accuracy: 0.5598 - val_loss: 0.6756 - val_accuracy: 0.5637\n",
      "Epoch 9/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6717 - accuracy: 0.5598 - val_loss: 0.6869 - val_accuracy: 0.5637\n",
      "Epoch 10/10\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 0.6845 - accuracy: 0.5598 - val_loss: 0.6769 - val_accuracy: 0.5637\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(100, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(50, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 231s 178ms/step - loss: 0.8093 - accuracy: 0.5544 - val_loss: 0.6850 - val_accuracy: 0.5566\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 229s 176ms/step - loss: 0.6949 - accuracy: 0.5628 - val_loss: 0.6839 - val_accuracy: 0.5566\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 228s 176ms/step - loss: 0.6953 - accuracy: 0.5305 - val_loss: 0.6844 - val_accuracy: 0.5566\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 228s 176ms/step - loss: 0.6849 - accuracy: 0.5628 - val_loss: 0.6793 - val_accuracy: 0.5566\n",
      "Epoch 5/10\n",
      "1297/1297 [==============================] - 229s 177ms/step - loss: 0.6785 - accuracy: 0.5628 - val_loss: 0.6784 - val_accuracy: 0.5566\n",
      "Epoch 6/10\n",
      "1297/1297 [==============================] - 228s 175ms/step - loss: 0.6769 - accuracy: 0.5628 - val_loss: 0.6636 - val_accuracy: 0.5566\n",
      "Epoch 7/10\n",
      " 100/1297 [=>............................] - ETA: 3:04 - loss: 0.6396 - accuracy: 0.6500"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_4 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=3, kernel_size=128, strides=(3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=128, strides=(3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=64, strides=(3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=32, strides=(3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=1, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 241s 186ms/step - loss: 0.9748 - accuracy: 0.4796 - val_loss: 0.6925 - val_accuracy: 0.5530\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 239s 184ms/step - loss: 0.6914 - accuracy: 0.5644 - val_loss: 0.6905 - val_accuracy: 0.5530\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 239s 185ms/step - loss: 0.6888 - accuracy: 0.5644 - val_loss: 0.6886 - val_accuracy: 0.5530\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 240s 185ms/step - loss: 0.6870 - accuracy: 0.5644 - val_loss: 0.6876 - val_accuracy: 0.5530\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1956eb95c245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_5 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=(3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=20, kernel_size=5, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=40, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=80, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=160, kernel_size=1, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6833 - accuracy: 0.5659 - val_loss: 0.6885 - val_accuracy: 0.5530\n",
      "Epoch 2/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6822 - accuracy: 0.5652 - val_loss: 0.7032 - val_accuracy: 0.5530\n",
      "Epoch 3/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6802 - accuracy: 0.5644 - val_loss: 0.6854 - val_accuracy: 0.5530\n",
      "Epoch 4/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6641 - accuracy: 0.5644 - val_loss: 0.6800 - val_accuracy: 0.5530\n",
      "Epoch 5/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6601 - accuracy: 0.5590 - val_loss: 0.6719 - val_accuracy: 0.5314\n",
      "Epoch 6/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6547 - accuracy: 0.5520 - val_loss: 0.6764 - val_accuracy: 0.5278\n",
      "Epoch 7/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6471 - accuracy: 0.5821 - val_loss: 0.6755 - val_accuracy: 0.5206\n",
      "Epoch 8/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6351 - accuracy: 0.5682 - val_loss: 0.6731 - val_accuracy: 0.5566\n",
      "Epoch 9/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6454 - accuracy: 0.6060 - val_loss: 0.6812 - val_accuracy: 0.5278\n",
      "Epoch 10/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5891 - val_loss: 0.6932 - val_accuracy: 0.5296\n",
      "Epoch 11/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6849 - accuracy: 0.5428 - val_loss: 0.6910 - val_accuracy: 0.4847\n",
      "Epoch 12/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6832 - accuracy: 0.5405 - val_loss: 0.6900 - val_accuracy: 0.5332\n",
      "Epoch 13/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6808 - accuracy: 0.5636 - val_loss: 0.6890 - val_accuracy: 0.5224\n",
      "Epoch 14/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6806 - accuracy: 0.5636 - val_loss: 0.6870 - val_accuracy: 0.5530\n",
      "Epoch 15/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5644 - val_loss: 0.6723 - val_accuracy: 0.5422\n",
      "Epoch 16/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6554 - accuracy: 0.5736 - val_loss: 0.6744 - val_accuracy: 0.5135\n",
      "Epoch 17/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6589 - accuracy: 0.5883 - val_loss: 0.6828 - val_accuracy: 0.5458\n",
      "Epoch 18/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6478 - accuracy: 0.5790 - val_loss: 0.6735 - val_accuracy: 0.5206\n",
      "Epoch 19/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6805 - accuracy: 0.5297 - val_loss: 0.6908 - val_accuracy: 0.4973\n",
      "Epoch 20/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6865 - accuracy: 0.5289 - val_loss: 0.6896 - val_accuracy: 0.5278\n",
      "Epoch 21/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6820 - accuracy: 0.5690 - val_loss: 0.6742 - val_accuracy: 0.5332\n",
      "Epoch 22/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6791 - accuracy: 0.5374 - val_loss: 0.7106 - val_accuracy: 0.5458\n",
      "Epoch 23/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5536 - val_loss: 0.6886 - val_accuracy: 0.5530\n",
      "Epoch 24/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6809 - accuracy: 0.5644 - val_loss: 0.6955 - val_accuracy: 0.5530\n",
      "Epoch 25/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6703 - accuracy: 0.5644 - val_loss: 0.6765 - val_accuracy: 0.5530\n",
      "Epoch 26/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6600 - accuracy: 0.5644 - val_loss: 0.6871 - val_accuracy: 0.5530\n",
      "Epoch 27/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6826 - accuracy: 0.5644 - val_loss: 0.6864 - val_accuracy: 0.5530\n",
      "Epoch 28/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6617 - accuracy: 0.5644 - val_loss: 0.6846 - val_accuracy: 0.5530\n",
      "Epoch 29/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6748 - accuracy: 0.5644 - val_loss: 0.6838 - val_accuracy: 0.5530\n",
      "Epoch 30/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6666 - accuracy: 0.5644 - val_loss: 0.6986 - val_accuracy: 0.5530\n",
      "Epoch 31/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6651 - accuracy: 0.5644 - val_loss: 0.6797 - val_accuracy: 0.5530\n",
      "Epoch 32/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6397 - accuracy: 0.5744 - val_loss: 0.6988 - val_accuracy: 0.5458\n",
      "Epoch 33/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6391 - accuracy: 0.5983 - val_loss: 0.6813 - val_accuracy: 0.5673\n",
      "Epoch 34/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.6170 - accuracy: 0.6191 - val_loss: 0.7396 - val_accuracy: 0.5332\n",
      "Epoch 35/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6071 - accuracy: 0.6345 - val_loss: 0.7588 - val_accuracy: 0.5476\n",
      "Epoch 36/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6010 - accuracy: 0.6523 - val_loss: 0.9549 - val_accuracy: 0.5583\n",
      "Epoch 37/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6282 - accuracy: 0.6176 - val_loss: 0.8407 - val_accuracy: 0.5512\n",
      "Epoch 38/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6126 - accuracy: 0.6415 - val_loss: 0.7106 - val_accuracy: 0.5637\n",
      "Epoch 39/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6049 - accuracy: 0.6554 - val_loss: 0.7641 - val_accuracy: 0.5512\n",
      "Epoch 40/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5889 - accuracy: 0.6484 - val_loss: 1.1228 - val_accuracy: 0.5242\n",
      "Epoch 41/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5837 - val_loss: 0.6947 - val_accuracy: 0.5117\n",
      "Epoch 42/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6683 - accuracy: 0.5821 - val_loss: 0.6876 - val_accuracy: 0.5224\n",
      "Epoch 43/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6292 - accuracy: 0.6160 - val_loss: 0.8359 - val_accuracy: 0.5458\n",
      "Epoch 44/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6168 - accuracy: 0.6307 - val_loss: 0.8044 - val_accuracy: 0.5171\n",
      "Epoch 45/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6060 - accuracy: 0.6430 - val_loss: 0.8263 - val_accuracy: 0.5260\n",
      "Epoch 46/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6013 - accuracy: 0.6469 - val_loss: 0.7822 - val_accuracy: 0.5673\n",
      "Epoch 47/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5962 - accuracy: 0.6638 - val_loss: 0.8260 - val_accuracy: 0.5512\n",
      "Epoch 48/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6029 - accuracy: 0.6500 - val_loss: 0.8352 - val_accuracy: 0.5619\n",
      "Epoch 49/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6063 - accuracy: 0.6500 - val_loss: 0.7191 - val_accuracy: 0.5781\n",
      "Epoch 50/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.5967 - accuracy: 0.6631 - val_loss: 0.7523 - val_accuracy: 0.5619\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_6 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((6, 6)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 1.2859 - accuracy: 0.4603 - val_loss: 0.7118 - val_accuracy: 0.4057\n",
      "Epoch 2/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7160 - accuracy: 0.4534 - val_loss: 1.0765 - val_accuracy: 0.5907\n",
      "Epoch 3/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 1.0607 - accuracy: 0.5359 - val_loss: 0.8590 - val_accuracy: 0.4093\n",
      "Epoch 4/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.7960 - accuracy: 0.4518 - val_loss: 0.6941 - val_accuracy: 0.4811\n",
      "Epoch 5/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6934 - accuracy: 0.4904 - val_loss: 0.6943 - val_accuracy: 0.4758\n",
      "Epoch 6/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6921 - accuracy: 0.4927 - val_loss: 0.6756 - val_accuracy: 0.5907\n",
      "Epoch 7/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6833 - accuracy: 0.5482 - val_loss: 0.6894 - val_accuracy: 0.5099\n",
      "Epoch 8/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6841 - accuracy: 0.5582 - val_loss: 0.6727 - val_accuracy: 0.5907\n",
      "Epoch 9/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6838 - accuracy: 0.5482 - val_loss: 0.6749 - val_accuracy: 0.5907\n",
      "Epoch 10/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6858 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 11/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6866 - accuracy: 0.5482 - val_loss: 0.6766 - val_accuracy: 0.5907\n",
      "Epoch 12/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6868 - accuracy: 0.5482 - val_loss: 0.6771 - val_accuracy: 0.5907\n",
      "Epoch 13/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6859 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 14/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6847 - accuracy: 0.5482 - val_loss: 0.6744 - val_accuracy: 0.5907\n",
      "Epoch 15/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6829 - accuracy: 0.5482 - val_loss: 0.6716 - val_accuracy: 0.5907\n",
      "Epoch 16/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6807 - accuracy: 0.5482 - val_loss: 0.6690 - val_accuracy: 0.5907\n",
      "Epoch 17/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6780 - accuracy: 0.5482 - val_loss: 0.6659 - val_accuracy: 0.5907\n",
      "Epoch 18/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6749 - accuracy: 0.5482 - val_loss: 0.6629 - val_accuracy: 0.5907\n",
      "Epoch 19/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6716 - accuracy: 0.5482 - val_loss: 0.6634 - val_accuracy: 0.5907\n",
      "Epoch 20/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6703 - accuracy: 0.5482 - val_loss: 0.6609 - val_accuracy: 0.5889\n",
      "Epoch 21/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6683 - accuracy: 0.5490 - val_loss: 0.6499 - val_accuracy: 0.5907\n",
      "Epoch 22/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6638 - accuracy: 0.5490 - val_loss: 0.6509 - val_accuracy: 0.6140\n",
      "Epoch 23/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6652 - accuracy: 0.5251 - val_loss: 0.6436 - val_accuracy: 0.6086\n",
      "Epoch 24/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6635 - accuracy: 0.5520 - val_loss: 0.6392 - val_accuracy: 0.5943\n",
      "Epoch 25/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6604 - accuracy: 0.5536 - val_loss: 0.6513 - val_accuracy: 0.6014\n",
      "Epoch 26/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.5628 - val_loss: 0.6539 - val_accuracy: 0.5763\n",
      "Epoch 27/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6603 - accuracy: 0.5790 - val_loss: 0.6477 - val_accuracy: 0.5943\n",
      "Epoch 28/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6572 - accuracy: 0.5644 - val_loss: 0.6409 - val_accuracy: 0.5853\n",
      "Epoch 29/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6552 - accuracy: 0.5667 - val_loss: 0.6370 - val_accuracy: 0.6230\n",
      "Epoch 30/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6553 - accuracy: 0.5821 - val_loss: 0.6361 - val_accuracy: 0.5996\n",
      "Epoch 31/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6526 - accuracy: 0.5705 - val_loss: 0.6355 - val_accuracy: 0.6104\n",
      "Epoch 32/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6499 - accuracy: 0.5806 - val_loss: 0.6353 - val_accuracy: 0.6140\n",
      "Epoch 33/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6476 - accuracy: 0.5883 - val_loss: 0.6302 - val_accuracy: 0.6050\n",
      "Epoch 34/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6452 - accuracy: 0.5906 - val_loss: 0.6398 - val_accuracy: 0.6176\n",
      "Epoch 35/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6456 - accuracy: 0.6191 - val_loss: 0.6208 - val_accuracy: 0.6230\n",
      "Epoch 36/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6412 - accuracy: 0.5921 - val_loss: 0.6208 - val_accuracy: 0.6320\n",
      "Epoch 37/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6354 - accuracy: 0.6122 - val_loss: 0.6372 - val_accuracy: 0.5691\n",
      "Epoch 38/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6397 - accuracy: 0.5952 - val_loss: 0.6204 - val_accuracy: 0.6320\n",
      "Epoch 39/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6319 - accuracy: 0.6137 - val_loss: 0.6205 - val_accuracy: 0.6355\n",
      "Epoch 40/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6275 - accuracy: 0.6153 - val_loss: 0.6112 - val_accuracy: 0.6427\n",
      "Epoch 41/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6199 - accuracy: 0.6207 - val_loss: 0.6143 - val_accuracy: 0.6409\n",
      "Epoch 42/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6158 - accuracy: 0.6145 - val_loss: 0.6235 - val_accuracy: 0.5907\n",
      "Epoch 43/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6155 - accuracy: 0.6307 - val_loss: 0.6262 - val_accuracy: 0.6320\n",
      "Epoch 44/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6316 - accuracy: 0.6222 - val_loss: 0.7848 - val_accuracy: 0.4722\n",
      "Epoch 45/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7072 - accuracy: 0.5420 - val_loss: 0.6337 - val_accuracy: 0.6517\n",
      "Epoch 46/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6332 - accuracy: 0.6130 - val_loss: 0.6596 - val_accuracy: 0.5889\n",
      "Epoch 47/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6627 - accuracy: 0.5490 - val_loss: 0.6579 - val_accuracy: 0.5907\n",
      "Epoch 48/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6575 - accuracy: 0.5482 - val_loss: 0.6586 - val_accuracy: 0.5907\n",
      "Epoch 49/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6558 - accuracy: 0.5482 - val_loss: 0.6560 - val_accuracy: 0.5907\n",
      "Epoch 50/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6533 - accuracy: 0.5482 - val_loss: 0.6495 - val_accuracy: 0.5907\n",
      "Epoch 51/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6485 - accuracy: 0.5482 - val_loss: 0.6437 - val_accuracy: 0.5907\n",
      "Epoch 52/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6439 - accuracy: 0.5497 - val_loss: 0.6386 - val_accuracy: 0.6014\n",
      "Epoch 53/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6370 - accuracy: 0.5613 - val_loss: 0.6350 - val_accuracy: 0.6463\n",
      "Epoch 54/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6302 - accuracy: 0.6145 - val_loss: 0.6258 - val_accuracy: 0.6697\n",
      "Epoch 55/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6217 - accuracy: 0.6438 - val_loss: 0.6234 - val_accuracy: 0.6840\n",
      "Epoch 56/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6103 - accuracy: 0.6777 - val_loss: 0.6171 - val_accuracy: 0.6750\n",
      "Epoch 57/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5983 - accuracy: 0.6692 - val_loss: 0.6173 - val_accuracy: 0.6373\n",
      "Epoch 58/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5822 - accuracy: 0.6731 - val_loss: 0.6380 - val_accuracy: 0.6014\n",
      "Epoch 59/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5952 - accuracy: 0.6739 - val_loss: 0.7106 - val_accuracy: 0.4955\n",
      "Epoch 60/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6650 - accuracy: 0.5906 - val_loss: 0.6576 - val_accuracy: 0.6553\n",
      "Epoch 61/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.6507 - val_loss: 0.6570 - val_accuracy: 0.6445\n",
      "Epoch 62/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6430 - accuracy: 0.6315 - val_loss: 0.6276 - val_accuracy: 0.6194\n",
      "Epoch 63/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6075 - accuracy: 0.6369 - val_loss: 0.6378 - val_accuracy: 0.6068\n",
      "Epoch 64/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6107 - accuracy: 0.6261 - val_loss: 0.6196 - val_accuracy: 0.6499\n",
      "Epoch 65/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6041 - accuracy: 0.6554 - val_loss: 0.6248 - val_accuracy: 0.6535\n",
      "Epoch 66/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6072 - accuracy: 0.6500 - val_loss: 0.6215 - val_accuracy: 0.6176\n",
      "Epoch 67/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5951 - accuracy: 0.6677 - val_loss: 0.6263 - val_accuracy: 0.6176\n",
      "Epoch 68/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5890 - accuracy: 0.6677 - val_loss: 0.5969 - val_accuracy: 0.6697\n",
      "Epoch 69/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5739 - accuracy: 0.6746 - val_loss: 0.6498 - val_accuracy: 0.5871\n",
      "Epoch 70/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5736 - accuracy: 0.6847 - val_loss: 0.6041 - val_accuracy: 0.6804\n",
      "Epoch 71/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5836 - accuracy: 0.6608 - val_loss: 0.5980 - val_accuracy: 0.6894\n",
      "Epoch 72/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5632 - accuracy: 0.6901 - val_loss: 0.6024 - val_accuracy: 0.6517\n",
      "Epoch 73/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5423 - accuracy: 0.7101 - val_loss: 0.6210 - val_accuracy: 0.6553\n",
      "Epoch 74/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5698 - accuracy: 0.6715 - val_loss: 0.5848 - val_accuracy: 0.6804\n",
      "Epoch 75/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5447 - accuracy: 0.6893 - val_loss: 0.6066 - val_accuracy: 0.6715\n",
      "Epoch 76/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5553 - accuracy: 0.6862 - val_loss: 0.6095 - val_accuracy: 0.6732\n",
      "Epoch 77/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5486 - accuracy: 0.6931 - val_loss: 0.6334 - val_accuracy: 0.6750\n",
      "Epoch 78/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5488 - accuracy: 0.6870 - val_loss: 0.6385 - val_accuracy: 0.6427\n",
      "Epoch 79/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5333 - accuracy: 0.6870 - val_loss: 0.6291 - val_accuracy: 0.6697\n",
      "Epoch 80/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5164 - accuracy: 0.7093 - val_loss: 0.6236 - val_accuracy: 0.6553\n",
      "Epoch 81/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5032 - accuracy: 0.7155 - val_loss: 0.6364 - val_accuracy: 0.6445\n",
      "Epoch 82/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4938 - accuracy: 0.7247 - val_loss: 0.6467 - val_accuracy: 0.6463\n",
      "Epoch 83/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4965 - accuracy: 0.7294 - val_loss: 0.6474 - val_accuracy: 0.6050\n",
      "Epoch 84/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4819 - accuracy: 0.7294 - val_loss: 0.6352 - val_accuracy: 0.6589\n",
      "Epoch 85/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4732 - accuracy: 0.7386 - val_loss: 0.6344 - val_accuracy: 0.6786\n",
      "Epoch 86/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4626 - accuracy: 0.7448 - val_loss: 0.6572 - val_accuracy: 0.6661\n",
      "Epoch 87/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4486 - accuracy: 0.7625 - val_loss: 0.6715 - val_accuracy: 0.6643\n",
      "Epoch 88/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4360 - accuracy: 0.7641 - val_loss: 0.7322 - val_accuracy: 0.6571\n",
      "Epoch 89/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4441 - accuracy: 0.7679 - val_loss: 0.6906 - val_accuracy: 0.6535\n",
      "Epoch 90/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4262 - accuracy: 0.7918 - val_loss: 0.6937 - val_accuracy: 0.6284\n",
      "Epoch 91/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4567 - accuracy: 0.7641 - val_loss: 0.6842 - val_accuracy: 0.6571\n",
      "Epoch 92/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4473 - accuracy: 0.7502 - val_loss: 0.6850 - val_accuracy: 0.6248\n",
      "Epoch 93/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4393 - accuracy: 0.7564 - val_loss: 0.6552 - val_accuracy: 0.6625\n",
      "Epoch 94/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4129 - accuracy: 0.7918 - val_loss: 0.6953 - val_accuracy: 0.6481\n",
      "Epoch 95/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4211 - accuracy: 0.7795 - val_loss: 0.6442 - val_accuracy: 0.6517\n",
      "Epoch 96/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4090 - accuracy: 0.7926 - val_loss: 0.7113 - val_accuracy: 0.6230\n",
      "Epoch 97/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4137 - accuracy: 0.7857 - val_loss: 0.8536 - val_accuracy: 0.6230\n",
      "Epoch 98/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3917 - accuracy: 0.7826 - val_loss: 0.6926 - val_accuracy: 0.6535\n",
      "Epoch 99/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4027 - accuracy: 0.8011 - val_loss: 0.7286 - val_accuracy: 0.6553\n",
      "Epoch 100/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3983 - accuracy: 0.8026 - val_loss: 0.7429 - val_accuracy: 0.6230\n",
      "Epoch 101/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.3960 - accuracy: 0.8134 - val_loss: 0.7510 - val_accuracy: 0.6122\n",
      "Epoch 102/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4043 - accuracy: 0.7911 - val_loss: 0.7057 - val_accuracy: 0.6643\n",
      "Epoch 103/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3677 - accuracy: 0.8126 - val_loss: 0.7889 - val_accuracy: 0.6355\n",
      "Epoch 104/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3734 - accuracy: 0.8196 - val_loss: 0.7482 - val_accuracy: 0.6427\n",
      "Epoch 105/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3632 - accuracy: 0.8227 - val_loss: 0.7024 - val_accuracy: 0.6661\n",
      "Epoch 106/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3462 - accuracy: 0.8443 - val_loss: 0.7406 - val_accuracy: 0.6661\n",
      "Epoch 107/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3321 - accuracy: 0.8396 - val_loss: 0.7909 - val_accuracy: 0.6607\n",
      "Epoch 108/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3103 - accuracy: 0.8527 - val_loss: 0.8074 - val_accuracy: 0.6571\n",
      "Epoch 109/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3073 - accuracy: 0.8589 - val_loss: 0.8451 - val_accuracy: 0.6535\n",
      "Epoch 110/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3063 - accuracy: 0.8581 - val_loss: 0.9177 - val_accuracy: 0.6589\n",
      "Epoch 111/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2832 - accuracy: 0.8720 - val_loss: 1.1454 - val_accuracy: 0.6427\n",
      "Epoch 112/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5090 - accuracy: 0.7926 - val_loss: 1.1000 - val_accuracy: 0.6409\n",
      "Epoch 113/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6093 - accuracy: 0.7556 - val_loss: 0.7613 - val_accuracy: 0.6463\n",
      "Epoch 114/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4474 - accuracy: 0.7764 - val_loss: 0.7598 - val_accuracy: 0.6302\n",
      "Epoch 115/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4723 - accuracy: 0.7672 - val_loss: 0.7355 - val_accuracy: 0.5763\n",
      "Epoch 116/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5355 - accuracy: 0.7224 - val_loss: 0.7415 - val_accuracy: 0.6050\n",
      "Epoch 117/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4771 - accuracy: 0.7672 - val_loss: 0.7024 - val_accuracy: 0.6194\n",
      "Epoch 118/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4131 - accuracy: 0.8150 - val_loss: 0.6951 - val_accuracy: 0.6409\n",
      "Epoch 119/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3914 - accuracy: 0.8165 - val_loss: 0.6674 - val_accuracy: 0.6320\n",
      "Epoch 120/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3733 - accuracy: 0.8304 - val_loss: 0.6813 - val_accuracy: 0.6373\n",
      "Epoch 121/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3541 - accuracy: 0.8489 - val_loss: 0.7130 - val_accuracy: 0.6463\n",
      "Epoch 122/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3334 - accuracy: 0.8358 - val_loss: 0.7456 - val_accuracy: 0.6517\n",
      "Epoch 123/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3003 - accuracy: 0.8674 - val_loss: 0.8520 - val_accuracy: 0.6607\n",
      "Epoch 124/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2935 - accuracy: 0.8736 - val_loss: 0.9049 - val_accuracy: 0.6409\n",
      "Epoch 125/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2728 - accuracy: 0.8813 - val_loss: 0.9159 - val_accuracy: 0.6409\n",
      "Epoch 126/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2628 - accuracy: 0.8805 - val_loss: 0.9145 - val_accuracy: 0.6373\n",
      "Epoch 127/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2610 - accuracy: 0.8890 - val_loss: 0.8690 - val_accuracy: 0.6571\n",
      "Epoch 128/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2620 - accuracy: 0.8843 - val_loss: 0.8782 - val_accuracy: 0.6571\n",
      "Epoch 129/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2462 - accuracy: 0.8913 - val_loss: 0.9131 - val_accuracy: 0.6571\n",
      "Epoch 130/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2302 - accuracy: 0.9052 - val_loss: 0.9133 - val_accuracy: 0.6643\n",
      "Epoch 131/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.2284 - accuracy: 0.8998 - val_loss: 0.9936 - val_accuracy: 0.6625\n",
      "Epoch 132/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2246 - accuracy: 0.9082 - val_loss: 1.0289 - val_accuracy: 0.6553\n",
      "Epoch 133/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2070 - accuracy: 0.9129 - val_loss: 1.0721 - val_accuracy: 0.6553\n",
      "Epoch 134/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2064 - accuracy: 0.9152 - val_loss: 1.0562 - val_accuracy: 0.6732\n",
      "Epoch 135/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.1948 - accuracy: 0.9229 - val_loss: 0.9783 - val_accuracy: 0.6607\n",
      "Epoch 136/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2023 - accuracy: 0.9183 - val_loss: 0.9592 - val_accuracy: 0.6535\n",
      "Epoch 137/200\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_7 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=1000,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/500\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0542 - acc: 0.9800 - val_loss: 4.8865 - val_acc: 0.5673\n",
      "Epoch 2/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0526 - acc: 0.9830 - val_loss: 3.8052 - val_acc: 0.6122\n",
      "Epoch 3/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0112 - acc: 0.9931 - val_loss: 4.2008 - val_acc: 0.5978\n",
      "Epoch 4/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9946 - val_loss: 4.0361 - val_acc: 0.6302\n",
      "Epoch 5/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0066 - acc: 0.9977 - val_loss: 4.1366 - val_acc: 0.6230\n",
      "Epoch 6/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0841 - acc: 0.9738 - val_loss: 4.3061 - val_acc: 0.5763\n",
      "Epoch 7/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1218 - acc: 0.9653 - val_loss: 3.3528 - val_acc: 0.6104\n",
      "Epoch 8/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0365 - acc: 0.9884 - val_loss: 3.3635 - val_acc: 0.6032\n",
      "Epoch 9/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0114 - acc: 0.9954 - val_loss: 3.3668 - val_acc: 0.6122\n",
      "Epoch 10/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 3.4501 - val_acc: 0.6140\n",
      "Epoch 11/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0100 - acc: 0.9946 - val_loss: 3.5490 - val_acc: 0.6122\n",
      "Epoch 12/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0294 - acc: 0.9861 - val_loss: 3.3413 - val_acc: 0.6140\n",
      "Epoch 13/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0271 - acc: 0.9830 - val_loss: 3.4524 - val_acc: 0.5925\n",
      "Epoch 14/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0129 - acc: 0.9931 - val_loss: 3.6805 - val_acc: 0.6014\n",
      "Epoch 15/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0100 - acc: 0.9954 - val_loss: 3.5620 - val_acc: 0.6050\n",
      "Epoch 16/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 3.5593 - val_acc: 0.6104\n",
      "Epoch 17/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 3.7795 - val_acc: 0.6194\n",
      "Epoch 18/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 3.8217 - val_acc: 0.6086\n",
      "Epoch 19/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.2594 - acc: 0.9044 - val_loss: 1.3718 - val_acc: 0.5440\n",
      "Epoch 20/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1091 - acc: 0.9491 - val_loss: 2.5084 - val_acc: 0.5925\n",
      "Epoch 21/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 3.1336 - val_acc: 0.5961\n",
      "Epoch 22/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0090 - acc: 0.9961 - val_loss: 3.3260 - val_acc: 0.5996\n",
      "Epoch 23/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0109 - acc: 0.9954 - val_loss: 3.4304 - val_acc: 0.5978\n",
      "Epoch 24/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0098 - acc: 0.9961 - val_loss: 3.6061 - val_acc: 0.6050\n",
      "Epoch 25/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 3.6194 - val_acc: 0.6014\n",
      "Epoch 26/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0952 - acc: 0.9692 - val_loss: 2.7855 - val_acc: 0.6050\n",
      "Epoch 27/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0720 - acc: 0.9776 - val_loss: 2.5212 - val_acc: 0.6230\n",
      "Epoch 28/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9907 - val_loss: 2.8383 - val_acc: 0.6176\n",
      "Epoch 29/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 3.0252 - val_acc: 0.6158\n",
      "Epoch 30/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0039 - acc: 0.9992 - val_loss: 3.1664 - val_acc: 0.6068\n",
      "Epoch 31/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 3.2672 - val_acc: 0.6032\n",
      "Epoch 32/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 3.3670 - val_acc: 0.6050\n",
      "Epoch 33/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 3.4478 - val_acc: 0.6032\n",
      "Epoch 34/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0468 - acc: 0.9900 - val_loss: 3.4187 - val_acc: 0.5961\n",
      "Epoch 35/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3658 - acc: 0.9067 - val_loss: 2.0230 - val_acc: 0.5925\n",
      "Epoch 36/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0486 - acc: 0.9823 - val_loss: 2.8499 - val_acc: 0.5799\n",
      "Epoch 37/500\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 3.0220 - val_acc: 0.6122\n",
      "Epoch 38/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0088 - acc: 0.9969 - val_loss: 3.1904 - val_acc: 0.5925\n",
      "Epoch 39/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3246 - acc: 0.8975 - val_loss: 2.0007 - val_acc: 0.5943\n",
      "Epoch 40/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0669 - acc: 0.9815 - val_loss: 2.5389 - val_acc: 0.5817\n",
      "Epoch 41/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9846 - val_loss: 2.4448 - val_acc: 0.6086\n",
      "Epoch 42/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0288 - acc: 0.9892 - val_loss: 2.6544 - val_acc: 0.5925\n",
      "Epoch 43/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0257 - acc: 0.9900 - val_loss: 2.8005 - val_acc: 0.5978\n",
      "Epoch 44/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0178 - acc: 0.9884 - val_loss: 2.9891 - val_acc: 0.5943\n",
      "Epoch 45/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9931 - val_loss: 3.1611 - val_acc: 0.5925\n",
      "Epoch 46/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 3.2269 - val_acc: 0.5996\n",
      "Epoch 47/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 3.2916 - val_acc: 0.5996\n",
      "Epoch 48/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0102 - acc: 0.9938 - val_loss: 3.1307 - val_acc: 0.5907\n",
      "Epoch 49/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0987 - acc: 0.9522 - val_loss: 2.6610 - val_acc: 0.5601\n",
      "Epoch 50/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9815 - val_loss: 2.7463 - val_acc: 0.5907\n",
      "Epoch 51/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9907 - val_loss: 3.0980 - val_acc: 0.5943\n",
      "Epoch 52/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9946 - val_loss: 3.2145 - val_acc: 0.6068\n",
      "Epoch 53/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0576 - acc: 0.9738 - val_loss: 3.0086 - val_acc: 0.5548\n",
      "Epoch 54/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0582 - acc: 0.9738 - val_loss: 3.0022 - val_acc: 0.6068\n",
      "Epoch 55/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 3.0723 - val_acc: 0.6140\n",
      "Epoch 56/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0122 - acc: 0.9977 - val_loss: 3.0839 - val_acc: 0.6104\n",
      "Epoch 57/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0101 - acc: 0.9961 - val_loss: 3.2881 - val_acc: 0.6212\n",
      "Epoch 58/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0450 - acc: 0.9807 - val_loss: 2.6459 - val_acc: 0.5727\n",
      "Epoch 59/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0814 - acc: 0.9630 - val_loss: 2.8003 - val_acc: 0.6068\n",
      "Epoch 60/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0084 - acc: 0.9961 - val_loss: 3.0562 - val_acc: 0.6068\n",
      "Epoch 61/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0150 - acc: 0.9900 - val_loss: 3.0624 - val_acc: 0.6104\n",
      "Epoch 62/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0166 - acc: 0.9884 - val_loss: 3.3788 - val_acc: 0.6104\n",
      "Epoch 63/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 3.3620 - val_acc: 0.6284\n",
      "Epoch 64/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0077 - acc: 0.9961 - val_loss: 3.4234 - val_acc: 0.6302\n",
      "Epoch 65/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0209 - acc: 0.9938 - val_loss: 3.2064 - val_acc: 0.5907\n",
      "Epoch 66/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.9869 - val_loss: 3.2074 - val_acc: 0.6086\n",
      "Epoch 67/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0869 - acc: 0.9668 - val_loss: 2.8276 - val_acc: 0.5619\n",
      "Epoch 68/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0555 - acc: 0.9807 - val_loss: 2.6582 - val_acc: 0.5853\n",
      "Epoch 69/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0174 - acc: 0.9900 - val_loss: 2.9639 - val_acc: 0.6104\n",
      "Epoch 70/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0115 - acc: 0.9931 - val_loss: 2.8999 - val_acc: 0.6194\n",
      "Epoch 71/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 2.9881 - val_acc: 0.6176\n",
      "Epoch 72/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0628 - acc: 0.9707 - val_loss: 2.9394 - val_acc: 0.5619\n",
      "Epoch 73/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0514 - acc: 0.9800 - val_loss: 3.0135 - val_acc: 0.5889\n",
      "Epoch 74/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0300 - acc: 0.9854 - val_loss: 2.9444 - val_acc: 0.6212\n",
      "Epoch 75/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 3.1245 - val_acc: 0.6266\n",
      "Epoch 76/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0108 - acc: 0.9954 - val_loss: 3.2596 - val_acc: 0.6122\n",
      "Epoch 77/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9638 - val_loss: 2.8438 - val_acc: 0.5889\n",
      "Epoch 78/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0296 - acc: 0.9869 - val_loss: 3.0837 - val_acc: 0.5853\n",
      "Epoch 79/500\n",
      "1024/1297 [======================>.......] - ETA: 0s - loss: 0.1132 - acc: 0.9443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-dc19821f9d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_8 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=500,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/1200\n",
      "1297/1297 [==============================] - 8s 6ms/step - loss: 0.8574 - acc: 0.5505 - val_loss: 0.7647 - val_acc: 0.5368\n",
      "Epoch 2/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7391 - acc: 0.5412 - val_loss: 0.7295 - val_acc: 0.5494\n",
      "Epoch 3/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7188 - acc: 0.5451 - val_loss: 0.7054 - val_acc: 0.5655\n",
      "Epoch 4/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7076 - acc: 0.5582 - val_loss: 0.6957 - val_acc: 0.5673\n",
      "Epoch 5/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7036 - acc: 0.5698 - val_loss: 0.6803 - val_acc: 0.5889\n",
      "Epoch 6/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6925 - acc: 0.5675 - val_loss: 0.6824 - val_acc: 0.5961\n",
      "Epoch 7/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6842 - acc: 0.5790 - val_loss: 0.6792 - val_acc: 0.5799\n",
      "Epoch 8/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6759 - acc: 0.5790 - val_loss: 0.6763 - val_acc: 0.5943\n",
      "Epoch 9/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6714 - acc: 0.5813 - val_loss: 0.6835 - val_acc: 0.5835\n",
      "Epoch 10/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6698 - acc: 0.5860 - val_loss: 0.6817 - val_acc: 0.5763\n",
      "Epoch 11/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6674 - acc: 0.5837 - val_loss: 0.6655 - val_acc: 0.5996\n",
      "Epoch 12/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6613 - acc: 0.5906 - val_loss: 0.6573 - val_acc: 0.5996\n",
      "Epoch 13/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6590 - acc: 0.5991 - val_loss: 0.6558 - val_acc: 0.5943\n",
      "Epoch 14/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6578 - acc: 0.5906 - val_loss: 0.6551 - val_acc: 0.5978\n",
      "Epoch 15/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6554 - acc: 0.6037 - val_loss: 0.6632 - val_acc: 0.5907\n",
      "Epoch 16/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6532 - acc: 0.5998 - val_loss: 0.6578 - val_acc: 0.6014\n",
      "Epoch 17/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6515 - acc: 0.5983 - val_loss: 0.6501 - val_acc: 0.5943\n",
      "Epoch 18/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6492 - acc: 0.5991 - val_loss: 0.6505 - val_acc: 0.5943\n",
      "Epoch 19/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6458 - acc: 0.6091 - val_loss: 0.6543 - val_acc: 0.5996\n",
      "Epoch 20/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6447 - acc: 0.6083 - val_loss: 0.6480 - val_acc: 0.5889\n",
      "Epoch 21/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6447 - acc: 0.6114 - val_loss: 0.6458 - val_acc: 0.5907\n",
      "Epoch 22/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6436 - acc: 0.6099 - val_loss: 0.6511 - val_acc: 0.5943\n",
      "Epoch 23/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6404 - acc: 0.6137 - val_loss: 0.6531 - val_acc: 0.5943\n",
      "Epoch 24/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6396 - acc: 0.6153 - val_loss: 0.6485 - val_acc: 0.6050\n",
      "Epoch 25/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6385 - acc: 0.6207 - val_loss: 0.6475 - val_acc: 0.6068\n",
      "Epoch 26/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6395 - acc: 0.6145 - val_loss: 0.6477 - val_acc: 0.6068\n",
      "Epoch 27/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6368 - acc: 0.6114 - val_loss: 0.6538 - val_acc: 0.6032\n",
      "Epoch 28/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6361 - acc: 0.6176 - val_loss: 0.6527 - val_acc: 0.5907\n",
      "Epoch 29/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6339 - acc: 0.6230 - val_loss: 0.6574 - val_acc: 0.5943\n",
      "Epoch 30/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6351 - acc: 0.6191 - val_loss: 0.6536 - val_acc: 0.6014\n",
      "Epoch 31/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6323 - acc: 0.6176 - val_loss: 0.6468 - val_acc: 0.6086\n",
      "Epoch 32/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6342 - acc: 0.6237 - val_loss: 0.6508 - val_acc: 0.6050\n",
      "Epoch 33/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6313 - acc: 0.6322 - val_loss: 0.6460 - val_acc: 0.6104\n",
      "Epoch 34/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6305 - acc: 0.6284 - val_loss: 0.6540 - val_acc: 0.6014\n",
      "Epoch 35/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6291 - acc: 0.6261 - val_loss: 0.6504 - val_acc: 0.6014\n",
      "Epoch 36/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6267 - acc: 0.6291 - val_loss: 0.6451 - val_acc: 0.5996\n",
      "Epoch 37/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6268 - acc: 0.6369 - val_loss: 0.6549 - val_acc: 0.5961\n",
      "Epoch 38/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6249 - acc: 0.6353 - val_loss: 0.6589 - val_acc: 0.5943\n",
      "Epoch 39/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6242 - acc: 0.6268 - val_loss: 0.6443 - val_acc: 0.5978\n",
      "Epoch 40/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6250 - acc: 0.6322 - val_loss: 0.6575 - val_acc: 0.5996\n",
      "Epoch 41/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6250 - acc: 0.6315 - val_loss: 0.6487 - val_acc: 0.6050\n",
      "Epoch 42/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6207 - acc: 0.6307 - val_loss: 0.6448 - val_acc: 0.5835\n",
      "Epoch 43/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6242 - acc: 0.6430 - val_loss: 0.6447 - val_acc: 0.5996\n",
      "Epoch 44/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6224 - acc: 0.6345 - val_loss: 0.6452 - val_acc: 0.6050\n",
      "Epoch 45/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6198 - acc: 0.6376 - val_loss: 0.6469 - val_acc: 0.6086\n",
      "Epoch 46/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6189 - acc: 0.6430 - val_loss: 0.6460 - val_acc: 0.6104\n",
      "Epoch 47/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6165 - acc: 0.6384 - val_loss: 0.6567 - val_acc: 0.5961\n",
      "Epoch 48/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6173 - acc: 0.6392 - val_loss: 0.6592 - val_acc: 0.5996\n",
      "Epoch 49/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6139 - acc: 0.6415 - val_loss: 0.6540 - val_acc: 0.6104\n",
      "Epoch 50/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6135 - acc: 0.6438 - val_loss: 0.6452 - val_acc: 0.6104\n",
      "Epoch 51/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6134 - acc: 0.6415 - val_loss: 0.6441 - val_acc: 0.6104\n",
      "Epoch 52/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6124 - acc: 0.6476 - val_loss: 0.6581 - val_acc: 0.6122\n",
      "Epoch 53/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6124 - acc: 0.6446 - val_loss: 0.6511 - val_acc: 0.6050\n",
      "Epoch 54/1200\n",
      "1297/1297 [==============================] - 3s 3ms/step - loss: 0.6103 - acc: 0.6492 - val_loss: 0.6428 - val_acc: 0.5978\n",
      "Epoch 55/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6134 - acc: 0.6476 - val_loss: 0.6523 - val_acc: 0.6068\n",
      "Epoch 56/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6089 - acc: 0.6476 - val_loss: 0.6393 - val_acc: 0.6122\n",
      "Epoch 57/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6079 - acc: 0.6507 - val_loss: 0.6476 - val_acc: 0.6140\n",
      "Epoch 58/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6083 - acc: 0.6469 - val_loss: 0.6611 - val_acc: 0.6068\n",
      "Epoch 59/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6051 - acc: 0.6600 - val_loss: 0.6430 - val_acc: 0.6122\n",
      "Epoch 60/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6044 - acc: 0.6592 - val_loss: 0.6439 - val_acc: 0.6194\n",
      "Epoch 61/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6024 - acc: 0.6608 - val_loss: 0.6430 - val_acc: 0.6140\n",
      "Epoch 62/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6006 - acc: 0.6646 - val_loss: 0.6611 - val_acc: 0.5961\n",
      "Epoch 63/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6015 - acc: 0.6600 - val_loss: 0.6409 - val_acc: 0.6158\n",
      "Epoch 64/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5991 - acc: 0.6623 - val_loss: 0.6471 - val_acc: 0.6104\n",
      "Epoch 65/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5988 - acc: 0.6584 - val_loss: 0.6423 - val_acc: 0.6122\n",
      "Epoch 66/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5969 - acc: 0.6669 - val_loss: 0.6478 - val_acc: 0.6158\n",
      "Epoch 67/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5948 - acc: 0.6654 - val_loss: 0.6402 - val_acc: 0.5871\n",
      "Epoch 68/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5982 - acc: 0.6631 - val_loss: 0.6392 - val_acc: 0.6122\n",
      "Epoch 69/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5924 - acc: 0.6685 - val_loss: 0.6562 - val_acc: 0.6068\n",
      "Epoch 70/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5926 - acc: 0.6662 - val_loss: 0.6583 - val_acc: 0.5961\n",
      "Epoch 71/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5941 - acc: 0.6715 - val_loss: 0.6602 - val_acc: 0.5925\n",
      "Epoch 72/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5930 - acc: 0.6677 - val_loss: 0.6454 - val_acc: 0.6050\n",
      "Epoch 73/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5927 - acc: 0.6677 - val_loss: 0.6492 - val_acc: 0.6068\n",
      "Epoch 74/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5872 - acc: 0.6646 - val_loss: 0.6390 - val_acc: 0.6050\n",
      "Epoch 75/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5885 - acc: 0.6669 - val_loss: 0.6353 - val_acc: 0.5961\n",
      "Epoch 76/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5949 - acc: 0.6700 - val_loss: 0.6408 - val_acc: 0.6086\n",
      "Epoch 77/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5848 - acc: 0.6746 - val_loss: 0.6502 - val_acc: 0.6086\n",
      "Epoch 78/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5837 - acc: 0.6731 - val_loss: 0.6482 - val_acc: 0.5978\n",
      "Epoch 79/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5843 - acc: 0.6715 - val_loss: 0.6436 - val_acc: 0.6068\n",
      "Epoch 80/1200\n",
      " 352/1297 [=======>......................] - ETA: 1s - loss: 0.5720 - acc: 0.6676"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-d89ccd224b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.00001)\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.00001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_9 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=1200,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
