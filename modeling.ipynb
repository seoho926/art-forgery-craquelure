{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 17.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.11.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz (289kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 26.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (2.8.0)\n",
      "Building wheels for collected packages: keras-applications\n",
      "  Running setup.py bdist_wheel for keras-applications ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/dd/f2/5d/2689b5547f32c4e258c3b7ccbe7f1d0f2afbb84fb01e830792\n",
      "Successfully built keras-applications\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-19.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 463 images belonging to 2 classes.\n",
      "Found 1854 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'data/Cracks/train'\n",
    "test_data_dir = 'data/Cracks/test'\n",
    "\n",
    "# Get all the data in the directory data/validation, and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(256, 256), batch_size=463, color_mode='grayscale')\n",
    "\n",
    "# Get all the data in the directory data/train, and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(256, 256), batch_size=1854, color_mode='grayscale')\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7FE036149780>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing an image\n",
    "array_to_img(train_images[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1854, 256, 256, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (1854, 256, 256, 1) (1854, 2)\n",
      "test data shape: (463, 256, 256, 1) (463, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking shape of data\n",
    "print('train data shape:', np.shape(train_images), np.shape(train_labels))\n",
    "print('test data shape:', np.shape(test_images), np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img: (1854, 65536)\n",
      "test_img: (463, 65536)\n"
     ]
    }
   ],
   "source": [
    "# Unrowing/reshaping\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "print('train_img:', np.shape(train_img))\n",
    "\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "print('test_img:', np.shape(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the labels\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dutch': 0, 'Flemish': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels final: (1854, 1)\n",
      "test labels final: (463, 1)\n"
     ]
    }
   ],
   "source": [
    "# Transposing the labels\n",
    "train_y = np.reshape(train_labels[:,0], (1854,1))\n",
    "print('train labels final:', np.shape(train_y))\n",
    "\n",
    "test_y = np.reshape(test_labels[:,0], (463,1))\n",
    "print('test labels final:', np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(65536,))) #2 hidden layers\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 1s 580us/step - loss: 7.6516 - accuracy: 0.5112 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 0s 377us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 0s 374us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 4/5\n",
      "1297/1297 [==============================] - 0s 372us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n",
      "Epoch 5/5\n",
      "1297/1297 [==============================] - 0s 370us/step - loss: 7.0800 - accuracy: 0.5559 - val_loss: 6.8120 - val_accuracy: 0.5727\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First CNN\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(100, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 673s 519ms/step - loss: 8.6901 - accuracy: 0.4549 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 668s 515ms/step - loss: 8.9600 - accuracy: 0.4441 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 664s 512ms/step - loss: 8.9600 - accuracy: 0.4441 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 4/5\n",
      " 900/1297 [===================>..........] - ETA: 3:01 - loss: 9.1157 - accuracy: 0.4344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b2a4256263c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 8.5945 - accuracy: 0.4549 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 8.9600 - accuracy: 0.4441 - val_loss: 9.2310 - val_accuracy: 0.4273\n",
      "Epoch 3/5\n",
      " 350/1297 [=======>......................] - ETA: 1:25 - loss: 8.8880 - accuracy: 0.4486"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3df4d6f24b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 133s 103ms/step - loss: 0.7820 - accuracy: 0.4965 - val_loss: 0.6893 - val_accuracy: 0.5727\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6865 - accuracy: 0.5559 - val_loss: 0.6751 - val_accuracy: 0.5727\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 133s 102ms/step - loss: 0.6688 - accuracy: 0.5559 - val_loss: 0.6672 - val_accuracy: 0.5727\n",
      "Epoch 4/5\n",
      "1297/1297 [==============================] - 133s 103ms/step - loss: 0.6643 - accuracy: 0.5659 - val_loss: 0.6906 - val_accuracy: 0.5566\n",
      "Epoch 5/5\n",
      "1297/1297 [==============================] - 132s 102ms/step - loss: 0.6893 - accuracy: 0.5389 - val_loss: 0.6850 - val_accuracy: 0.5727\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(150, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.7362 - accuracy: 0.4811 - val_loss: 0.6913 - val_accuracy: 0.5637\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6900 - accuracy: 0.5598 - val_loss: 0.6872 - val_accuracy: 0.5637\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6883 - accuracy: 0.5598 - val_loss: 0.6815 - val_accuracy: 0.5637\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6872 - accuracy: 0.5598 - val_loss: 0.6840 - val_accuracy: 0.5637\n",
      "Epoch 5/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6876 - accuracy: 0.5598 - val_loss: 0.6818 - val_accuracy: 0.5637\n",
      "Epoch 6/10\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 0.6865 - accuracy: 0.5598 - val_loss: 0.6857 - val_accuracy: 0.5637\n",
      "Epoch 7/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6863 - accuracy: 0.5598 - val_loss: 0.6840 - val_accuracy: 0.5637\n",
      "Epoch 8/10\n",
      "1297/1297 [==============================] - 134s 103ms/step - loss: 0.6825 - accuracy: 0.5598 - val_loss: 0.6756 - val_accuracy: 0.5637\n",
      "Epoch 9/10\n",
      "1297/1297 [==============================] - 135s 104ms/step - loss: 0.6717 - accuracy: 0.5598 - val_loss: 0.6869 - val_accuracy: 0.5637\n",
      "Epoch 10/10\n",
      "1297/1297 [==============================] - 134s 104ms/step - loss: 0.6845 - accuracy: 0.5598 - val_loss: 0.6769 - val_accuracy: 0.5637\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(100, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(50, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(250, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 231s 178ms/step - loss: 0.8093 - accuracy: 0.5544 - val_loss: 0.6850 - val_accuracy: 0.5566\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 229s 176ms/step - loss: 0.6949 - accuracy: 0.5628 - val_loss: 0.6839 - val_accuracy: 0.5566\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 228s 176ms/step - loss: 0.6953 - accuracy: 0.5305 - val_loss: 0.6844 - val_accuracy: 0.5566\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 228s 176ms/step - loss: 0.6849 - accuracy: 0.5628 - val_loss: 0.6793 - val_accuracy: 0.5566\n",
      "Epoch 5/10\n",
      "1297/1297 [==============================] - 229s 177ms/step - loss: 0.6785 - accuracy: 0.5628 - val_loss: 0.6784 - val_accuracy: 0.5566\n",
      "Epoch 6/10\n",
      "1297/1297 [==============================] - 228s 175ms/step - loss: 0.6769 - accuracy: 0.5628 - val_loss: 0.6636 - val_accuracy: 0.5566\n",
      "Epoch 7/10\n",
      " 100/1297 [=>............................] - ETA: 3:04 - loss: 0.6396 - accuracy: 0.6500"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_4 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=3, kernel_size=128, strides=(3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=128, strides=(3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=64, strides=(3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=32, strides=(3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=3, kernel_size=1, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/10\n",
      "1297/1297 [==============================] - 241s 186ms/step - loss: 0.9748 - accuracy: 0.4796 - val_loss: 0.6925 - val_accuracy: 0.5530\n",
      "Epoch 2/10\n",
      "1297/1297 [==============================] - 239s 184ms/step - loss: 0.6914 - accuracy: 0.5644 - val_loss: 0.6905 - val_accuracy: 0.5530\n",
      "Epoch 3/10\n",
      "1297/1297 [==============================] - 239s 185ms/step - loss: 0.6888 - accuracy: 0.5644 - val_loss: 0.6886 - val_accuracy: 0.5530\n",
      "Epoch 4/10\n",
      "1297/1297 [==============================] - 240s 185ms/step - loss: 0.6870 - accuracy: 0.5644 - val_loss: 0.6876 - val_accuracy: 0.5530\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1956eb95c245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_5 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=(3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=20, kernel_size=5, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=40, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=80, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=160, kernel_size=1, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6833 - accuracy: 0.5659 - val_loss: 0.6885 - val_accuracy: 0.5530\n",
      "Epoch 2/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6822 - accuracy: 0.5652 - val_loss: 0.7032 - val_accuracy: 0.5530\n",
      "Epoch 3/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6802 - accuracy: 0.5644 - val_loss: 0.6854 - val_accuracy: 0.5530\n",
      "Epoch 4/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6641 - accuracy: 0.5644 - val_loss: 0.6800 - val_accuracy: 0.5530\n",
      "Epoch 5/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6601 - accuracy: 0.5590 - val_loss: 0.6719 - val_accuracy: 0.5314\n",
      "Epoch 6/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6547 - accuracy: 0.5520 - val_loss: 0.6764 - val_accuracy: 0.5278\n",
      "Epoch 7/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6471 - accuracy: 0.5821 - val_loss: 0.6755 - val_accuracy: 0.5206\n",
      "Epoch 8/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6351 - accuracy: 0.5682 - val_loss: 0.6731 - val_accuracy: 0.5566\n",
      "Epoch 9/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6454 - accuracy: 0.6060 - val_loss: 0.6812 - val_accuracy: 0.5278\n",
      "Epoch 10/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5891 - val_loss: 0.6932 - val_accuracy: 0.5296\n",
      "Epoch 11/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6849 - accuracy: 0.5428 - val_loss: 0.6910 - val_accuracy: 0.4847\n",
      "Epoch 12/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6832 - accuracy: 0.5405 - val_loss: 0.6900 - val_accuracy: 0.5332\n",
      "Epoch 13/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6808 - accuracy: 0.5636 - val_loss: 0.6890 - val_accuracy: 0.5224\n",
      "Epoch 14/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6806 - accuracy: 0.5636 - val_loss: 0.6870 - val_accuracy: 0.5530\n",
      "Epoch 15/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5644 - val_loss: 0.6723 - val_accuracy: 0.5422\n",
      "Epoch 16/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6554 - accuracy: 0.5736 - val_loss: 0.6744 - val_accuracy: 0.5135\n",
      "Epoch 17/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6589 - accuracy: 0.5883 - val_loss: 0.6828 - val_accuracy: 0.5458\n",
      "Epoch 18/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6478 - accuracy: 0.5790 - val_loss: 0.6735 - val_accuracy: 0.5206\n",
      "Epoch 19/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6805 - accuracy: 0.5297 - val_loss: 0.6908 - val_accuracy: 0.4973\n",
      "Epoch 20/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6865 - accuracy: 0.5289 - val_loss: 0.6896 - val_accuracy: 0.5278\n",
      "Epoch 21/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6820 - accuracy: 0.5690 - val_loss: 0.6742 - val_accuracy: 0.5332\n",
      "Epoch 22/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6791 - accuracy: 0.5374 - val_loss: 0.7106 - val_accuracy: 0.5458\n",
      "Epoch 23/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5536 - val_loss: 0.6886 - val_accuracy: 0.5530\n",
      "Epoch 24/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6809 - accuracy: 0.5644 - val_loss: 0.6955 - val_accuracy: 0.5530\n",
      "Epoch 25/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6703 - accuracy: 0.5644 - val_loss: 0.6765 - val_accuracy: 0.5530\n",
      "Epoch 26/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6600 - accuracy: 0.5644 - val_loss: 0.6871 - val_accuracy: 0.5530\n",
      "Epoch 27/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6826 - accuracy: 0.5644 - val_loss: 0.6864 - val_accuracy: 0.5530\n",
      "Epoch 28/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6617 - accuracy: 0.5644 - val_loss: 0.6846 - val_accuracy: 0.5530\n",
      "Epoch 29/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6748 - accuracy: 0.5644 - val_loss: 0.6838 - val_accuracy: 0.5530\n",
      "Epoch 30/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6666 - accuracy: 0.5644 - val_loss: 0.6986 - val_accuracy: 0.5530\n",
      "Epoch 31/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6651 - accuracy: 0.5644 - val_loss: 0.6797 - val_accuracy: 0.5530\n",
      "Epoch 32/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6397 - accuracy: 0.5744 - val_loss: 0.6988 - val_accuracy: 0.5458\n",
      "Epoch 33/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6391 - accuracy: 0.5983 - val_loss: 0.6813 - val_accuracy: 0.5673\n",
      "Epoch 34/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.6170 - accuracy: 0.6191 - val_loss: 0.7396 - val_accuracy: 0.5332\n",
      "Epoch 35/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6071 - accuracy: 0.6345 - val_loss: 0.7588 - val_accuracy: 0.5476\n",
      "Epoch 36/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6010 - accuracy: 0.6523 - val_loss: 0.9549 - val_accuracy: 0.5583\n",
      "Epoch 37/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6282 - accuracy: 0.6176 - val_loss: 0.8407 - val_accuracy: 0.5512\n",
      "Epoch 38/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6126 - accuracy: 0.6415 - val_loss: 0.7106 - val_accuracy: 0.5637\n",
      "Epoch 39/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6049 - accuracy: 0.6554 - val_loss: 0.7641 - val_accuracy: 0.5512\n",
      "Epoch 40/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5889 - accuracy: 0.6484 - val_loss: 1.1228 - val_accuracy: 0.5242\n",
      "Epoch 41/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5837 - val_loss: 0.6947 - val_accuracy: 0.5117\n",
      "Epoch 42/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6683 - accuracy: 0.5821 - val_loss: 0.6876 - val_accuracy: 0.5224\n",
      "Epoch 43/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6292 - accuracy: 0.6160 - val_loss: 0.8359 - val_accuracy: 0.5458\n",
      "Epoch 44/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6168 - accuracy: 0.6307 - val_loss: 0.8044 - val_accuracy: 0.5171\n",
      "Epoch 45/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6060 - accuracy: 0.6430 - val_loss: 0.8263 - val_accuracy: 0.5260\n",
      "Epoch 46/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6013 - accuracy: 0.6469 - val_loss: 0.7822 - val_accuracy: 0.5673\n",
      "Epoch 47/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5962 - accuracy: 0.6638 - val_loss: 0.8260 - val_accuracy: 0.5512\n",
      "Epoch 48/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6029 - accuracy: 0.6500 - val_loss: 0.8352 - val_accuracy: 0.5619\n",
      "Epoch 49/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6063 - accuracy: 0.6500 - val_loss: 0.7191 - val_accuracy: 0.5781\n",
      "Epoch 50/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.5967 - accuracy: 0.6631 - val_loss: 0.7523 - val_accuracy: 0.5619\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_6 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((6, 6)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 1.2859 - accuracy: 0.4603 - val_loss: 0.7118 - val_accuracy: 0.4057\n",
      "Epoch 2/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7160 - accuracy: 0.4534 - val_loss: 1.0765 - val_accuracy: 0.5907\n",
      "Epoch 3/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 1.0607 - accuracy: 0.5359 - val_loss: 0.8590 - val_accuracy: 0.4093\n",
      "Epoch 4/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.7960 - accuracy: 0.4518 - val_loss: 0.6941 - val_accuracy: 0.4811\n",
      "Epoch 5/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6934 - accuracy: 0.4904 - val_loss: 0.6943 - val_accuracy: 0.4758\n",
      "Epoch 6/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6921 - accuracy: 0.4927 - val_loss: 0.6756 - val_accuracy: 0.5907\n",
      "Epoch 7/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6833 - accuracy: 0.5482 - val_loss: 0.6894 - val_accuracy: 0.5099\n",
      "Epoch 8/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6841 - accuracy: 0.5582 - val_loss: 0.6727 - val_accuracy: 0.5907\n",
      "Epoch 9/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6838 - accuracy: 0.5482 - val_loss: 0.6749 - val_accuracy: 0.5907\n",
      "Epoch 10/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6858 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 11/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6866 - accuracy: 0.5482 - val_loss: 0.6766 - val_accuracy: 0.5907\n",
      "Epoch 12/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6868 - accuracy: 0.5482 - val_loss: 0.6771 - val_accuracy: 0.5907\n",
      "Epoch 13/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6859 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 14/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6847 - accuracy: 0.5482 - val_loss: 0.6744 - val_accuracy: 0.5907\n",
      "Epoch 15/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6829 - accuracy: 0.5482 - val_loss: 0.6716 - val_accuracy: 0.5907\n",
      "Epoch 16/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6807 - accuracy: 0.5482 - val_loss: 0.6690 - val_accuracy: 0.5907\n",
      "Epoch 17/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6780 - accuracy: 0.5482 - val_loss: 0.6659 - val_accuracy: 0.5907\n",
      "Epoch 18/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6749 - accuracy: 0.5482 - val_loss: 0.6629 - val_accuracy: 0.5907\n",
      "Epoch 19/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6716 - accuracy: 0.5482 - val_loss: 0.6634 - val_accuracy: 0.5907\n",
      "Epoch 20/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6703 - accuracy: 0.5482 - val_loss: 0.6609 - val_accuracy: 0.5889\n",
      "Epoch 21/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6683 - accuracy: 0.5490 - val_loss: 0.6499 - val_accuracy: 0.5907\n",
      "Epoch 22/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6638 - accuracy: 0.5490 - val_loss: 0.6509 - val_accuracy: 0.6140\n",
      "Epoch 23/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6652 - accuracy: 0.5251 - val_loss: 0.6436 - val_accuracy: 0.6086\n",
      "Epoch 24/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6635 - accuracy: 0.5520 - val_loss: 0.6392 - val_accuracy: 0.5943\n",
      "Epoch 25/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6604 - accuracy: 0.5536 - val_loss: 0.6513 - val_accuracy: 0.6014\n",
      "Epoch 26/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.5628 - val_loss: 0.6539 - val_accuracy: 0.5763\n",
      "Epoch 27/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6603 - accuracy: 0.5790 - val_loss: 0.6477 - val_accuracy: 0.5943\n",
      "Epoch 28/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6572 - accuracy: 0.5644 - val_loss: 0.6409 - val_accuracy: 0.5853\n",
      "Epoch 29/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6552 - accuracy: 0.5667 - val_loss: 0.6370 - val_accuracy: 0.6230\n",
      "Epoch 30/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6553 - accuracy: 0.5821 - val_loss: 0.6361 - val_accuracy: 0.5996\n",
      "Epoch 31/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6526 - accuracy: 0.5705 - val_loss: 0.6355 - val_accuracy: 0.6104\n",
      "Epoch 32/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6499 - accuracy: 0.5806 - val_loss: 0.6353 - val_accuracy: 0.6140\n",
      "Epoch 33/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6476 - accuracy: 0.5883 - val_loss: 0.6302 - val_accuracy: 0.6050\n",
      "Epoch 34/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6452 - accuracy: 0.5906 - val_loss: 0.6398 - val_accuracy: 0.6176\n",
      "Epoch 35/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6456 - accuracy: 0.6191 - val_loss: 0.6208 - val_accuracy: 0.6230\n",
      "Epoch 36/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6412 - accuracy: 0.5921 - val_loss: 0.6208 - val_accuracy: 0.6320\n",
      "Epoch 37/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6354 - accuracy: 0.6122 - val_loss: 0.6372 - val_accuracy: 0.5691\n",
      "Epoch 38/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6397 - accuracy: 0.5952 - val_loss: 0.6204 - val_accuracy: 0.6320\n",
      "Epoch 39/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6319 - accuracy: 0.6137 - val_loss: 0.6205 - val_accuracy: 0.6355\n",
      "Epoch 40/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6275 - accuracy: 0.6153 - val_loss: 0.6112 - val_accuracy: 0.6427\n",
      "Epoch 41/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6199 - accuracy: 0.6207 - val_loss: 0.6143 - val_accuracy: 0.6409\n",
      "Epoch 42/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6158 - accuracy: 0.6145 - val_loss: 0.6235 - val_accuracy: 0.5907\n",
      "Epoch 43/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6155 - accuracy: 0.6307 - val_loss: 0.6262 - val_accuracy: 0.6320\n",
      "Epoch 44/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6316 - accuracy: 0.6222 - val_loss: 0.7848 - val_accuracy: 0.4722\n",
      "Epoch 45/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7072 - accuracy: 0.5420 - val_loss: 0.6337 - val_accuracy: 0.6517\n",
      "Epoch 46/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6332 - accuracy: 0.6130 - val_loss: 0.6596 - val_accuracy: 0.5889\n",
      "Epoch 47/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6627 - accuracy: 0.5490 - val_loss: 0.6579 - val_accuracy: 0.5907\n",
      "Epoch 48/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6575 - accuracy: 0.5482 - val_loss: 0.6586 - val_accuracy: 0.5907\n",
      "Epoch 49/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6558 - accuracy: 0.5482 - val_loss: 0.6560 - val_accuracy: 0.5907\n",
      "Epoch 50/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6533 - accuracy: 0.5482 - val_loss: 0.6495 - val_accuracy: 0.5907\n",
      "Epoch 51/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6485 - accuracy: 0.5482 - val_loss: 0.6437 - val_accuracy: 0.5907\n",
      "Epoch 52/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6439 - accuracy: 0.5497 - val_loss: 0.6386 - val_accuracy: 0.6014\n",
      "Epoch 53/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6370 - accuracy: 0.5613 - val_loss: 0.6350 - val_accuracy: 0.6463\n",
      "Epoch 54/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6302 - accuracy: 0.6145 - val_loss: 0.6258 - val_accuracy: 0.6697\n",
      "Epoch 55/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6217 - accuracy: 0.6438 - val_loss: 0.6234 - val_accuracy: 0.6840\n",
      "Epoch 56/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6103 - accuracy: 0.6777 - val_loss: 0.6171 - val_accuracy: 0.6750\n",
      "Epoch 57/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5983 - accuracy: 0.6692 - val_loss: 0.6173 - val_accuracy: 0.6373\n",
      "Epoch 58/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5822 - accuracy: 0.6731 - val_loss: 0.6380 - val_accuracy: 0.6014\n",
      "Epoch 59/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5952 - accuracy: 0.6739 - val_loss: 0.7106 - val_accuracy: 0.4955\n",
      "Epoch 60/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6650 - accuracy: 0.5906 - val_loss: 0.6576 - val_accuracy: 0.6553\n",
      "Epoch 61/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.6507 - val_loss: 0.6570 - val_accuracy: 0.6445\n",
      "Epoch 62/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6430 - accuracy: 0.6315 - val_loss: 0.6276 - val_accuracy: 0.6194\n",
      "Epoch 63/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6075 - accuracy: 0.6369 - val_loss: 0.6378 - val_accuracy: 0.6068\n",
      "Epoch 64/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6107 - accuracy: 0.6261 - val_loss: 0.6196 - val_accuracy: 0.6499\n",
      "Epoch 65/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6041 - accuracy: 0.6554 - val_loss: 0.6248 - val_accuracy: 0.6535\n",
      "Epoch 66/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6072 - accuracy: 0.6500 - val_loss: 0.6215 - val_accuracy: 0.6176\n",
      "Epoch 67/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5951 - accuracy: 0.6677 - val_loss: 0.6263 - val_accuracy: 0.6176\n",
      "Epoch 68/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5890 - accuracy: 0.6677 - val_loss: 0.5969 - val_accuracy: 0.6697\n",
      "Epoch 69/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5739 - accuracy: 0.6746 - val_loss: 0.6498 - val_accuracy: 0.5871\n",
      "Epoch 70/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5736 - accuracy: 0.6847 - val_loss: 0.6041 - val_accuracy: 0.6804\n",
      "Epoch 71/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5836 - accuracy: 0.6608 - val_loss: 0.5980 - val_accuracy: 0.6894\n",
      "Epoch 72/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5632 - accuracy: 0.6901 - val_loss: 0.6024 - val_accuracy: 0.6517\n",
      "Epoch 73/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5423 - accuracy: 0.7101 - val_loss: 0.6210 - val_accuracy: 0.6553\n",
      "Epoch 74/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5698 - accuracy: 0.6715 - val_loss: 0.5848 - val_accuracy: 0.6804\n",
      "Epoch 75/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5447 - accuracy: 0.6893 - val_loss: 0.6066 - val_accuracy: 0.6715\n",
      "Epoch 76/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5553 - accuracy: 0.6862 - val_loss: 0.6095 - val_accuracy: 0.6732\n",
      "Epoch 77/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5486 - accuracy: 0.6931 - val_loss: 0.6334 - val_accuracy: 0.6750\n",
      "Epoch 78/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5488 - accuracy: 0.6870 - val_loss: 0.6385 - val_accuracy: 0.6427\n",
      "Epoch 79/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5333 - accuracy: 0.6870 - val_loss: 0.6291 - val_accuracy: 0.6697\n",
      "Epoch 80/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5164 - accuracy: 0.7093 - val_loss: 0.6236 - val_accuracy: 0.6553\n",
      "Epoch 81/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5032 - accuracy: 0.7155 - val_loss: 0.6364 - val_accuracy: 0.6445\n",
      "Epoch 82/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4938 - accuracy: 0.7247 - val_loss: 0.6467 - val_accuracy: 0.6463\n",
      "Epoch 83/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4965 - accuracy: 0.7294 - val_loss: 0.6474 - val_accuracy: 0.6050\n",
      "Epoch 84/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4819 - accuracy: 0.7294 - val_loss: 0.6352 - val_accuracy: 0.6589\n",
      "Epoch 85/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4732 - accuracy: 0.7386 - val_loss: 0.6344 - val_accuracy: 0.6786\n",
      "Epoch 86/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4626 - accuracy: 0.7448 - val_loss: 0.6572 - val_accuracy: 0.6661\n",
      "Epoch 87/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4486 - accuracy: 0.7625 - val_loss: 0.6715 - val_accuracy: 0.6643\n",
      "Epoch 88/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4360 - accuracy: 0.7641 - val_loss: 0.7322 - val_accuracy: 0.6571\n",
      "Epoch 89/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4441 - accuracy: 0.7679 - val_loss: 0.6906 - val_accuracy: 0.6535\n",
      "Epoch 90/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4262 - accuracy: 0.7918 - val_loss: 0.6937 - val_accuracy: 0.6284\n",
      "Epoch 91/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4567 - accuracy: 0.7641 - val_loss: 0.6842 - val_accuracy: 0.6571\n",
      "Epoch 92/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4473 - accuracy: 0.7502 - val_loss: 0.6850 - val_accuracy: 0.6248\n",
      "Epoch 93/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4393 - accuracy: 0.7564 - val_loss: 0.6552 - val_accuracy: 0.6625\n",
      "Epoch 94/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4129 - accuracy: 0.7918 - val_loss: 0.6953 - val_accuracy: 0.6481\n",
      "Epoch 95/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4211 - accuracy: 0.7795 - val_loss: 0.6442 - val_accuracy: 0.6517\n",
      "Epoch 96/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4090 - accuracy: 0.7926 - val_loss: 0.7113 - val_accuracy: 0.6230\n",
      "Epoch 97/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4137 - accuracy: 0.7857 - val_loss: 0.8536 - val_accuracy: 0.6230\n",
      "Epoch 98/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3917 - accuracy: 0.7826 - val_loss: 0.6926 - val_accuracy: 0.6535\n",
      "Epoch 99/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4027 - accuracy: 0.8011 - val_loss: 0.7286 - val_accuracy: 0.6553\n",
      "Epoch 100/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3983 - accuracy: 0.8026 - val_loss: 0.7429 - val_accuracy: 0.6230\n",
      "Epoch 101/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.3960 - accuracy: 0.8134 - val_loss: 0.7510 - val_accuracy: 0.6122\n",
      "Epoch 102/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4043 - accuracy: 0.7911 - val_loss: 0.7057 - val_accuracy: 0.6643\n",
      "Epoch 103/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3677 - accuracy: 0.8126 - val_loss: 0.7889 - val_accuracy: 0.6355\n",
      "Epoch 104/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3734 - accuracy: 0.8196 - val_loss: 0.7482 - val_accuracy: 0.6427\n",
      "Epoch 105/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3632 - accuracy: 0.8227 - val_loss: 0.7024 - val_accuracy: 0.6661\n",
      "Epoch 106/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3462 - accuracy: 0.8443 - val_loss: 0.7406 - val_accuracy: 0.6661\n",
      "Epoch 107/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3321 - accuracy: 0.8396 - val_loss: 0.7909 - val_accuracy: 0.6607\n",
      "Epoch 108/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3103 - accuracy: 0.8527 - val_loss: 0.8074 - val_accuracy: 0.6571\n",
      "Epoch 109/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3073 - accuracy: 0.8589 - val_loss: 0.8451 - val_accuracy: 0.6535\n",
      "Epoch 110/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3063 - accuracy: 0.8581 - val_loss: 0.9177 - val_accuracy: 0.6589\n",
      "Epoch 111/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2832 - accuracy: 0.8720 - val_loss: 1.1454 - val_accuracy: 0.6427\n",
      "Epoch 112/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5090 - accuracy: 0.7926 - val_loss: 1.1000 - val_accuracy: 0.6409\n",
      "Epoch 113/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6093 - accuracy: 0.7556 - val_loss: 0.7613 - val_accuracy: 0.6463\n",
      "Epoch 114/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4474 - accuracy: 0.7764 - val_loss: 0.7598 - val_accuracy: 0.6302\n",
      "Epoch 115/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4723 - accuracy: 0.7672 - val_loss: 0.7355 - val_accuracy: 0.5763\n",
      "Epoch 116/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5355 - accuracy: 0.7224 - val_loss: 0.7415 - val_accuracy: 0.6050\n",
      "Epoch 117/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4771 - accuracy: 0.7672 - val_loss: 0.7024 - val_accuracy: 0.6194\n",
      "Epoch 118/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4131 - accuracy: 0.8150 - val_loss: 0.6951 - val_accuracy: 0.6409\n",
      "Epoch 119/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3914 - accuracy: 0.8165 - val_loss: 0.6674 - val_accuracy: 0.6320\n",
      "Epoch 120/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3733 - accuracy: 0.8304 - val_loss: 0.6813 - val_accuracy: 0.6373\n",
      "Epoch 121/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3541 - accuracy: 0.8489 - val_loss: 0.7130 - val_accuracy: 0.6463\n",
      "Epoch 122/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3334 - accuracy: 0.8358 - val_loss: 0.7456 - val_accuracy: 0.6517\n",
      "Epoch 123/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3003 - accuracy: 0.8674 - val_loss: 0.8520 - val_accuracy: 0.6607\n",
      "Epoch 124/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2935 - accuracy: 0.8736 - val_loss: 0.9049 - val_accuracy: 0.6409\n",
      "Epoch 125/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2728 - accuracy: 0.8813 - val_loss: 0.9159 - val_accuracy: 0.6409\n",
      "Epoch 126/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2628 - accuracy: 0.8805 - val_loss: 0.9145 - val_accuracy: 0.6373\n",
      "Epoch 127/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2610 - accuracy: 0.8890 - val_loss: 0.8690 - val_accuracy: 0.6571\n",
      "Epoch 128/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2620 - accuracy: 0.8843 - val_loss: 0.8782 - val_accuracy: 0.6571\n",
      "Epoch 129/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2462 - accuracy: 0.8913 - val_loss: 0.9131 - val_accuracy: 0.6571\n",
      "Epoch 130/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2302 - accuracy: 0.9052 - val_loss: 0.9133 - val_accuracy: 0.6643\n",
      "Epoch 131/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.2284 - accuracy: 0.8998 - val_loss: 0.9936 - val_accuracy: 0.6625\n",
      "Epoch 132/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2246 - accuracy: 0.9082 - val_loss: 1.0289 - val_accuracy: 0.6553\n",
      "Epoch 133/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2070 - accuracy: 0.9129 - val_loss: 1.0721 - val_accuracy: 0.6553\n",
      "Epoch 134/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2064 - accuracy: 0.9152 - val_loss: 1.0562 - val_accuracy: 0.6732\n",
      "Epoch 135/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.1948 - accuracy: 0.9229 - val_loss: 0.9783 - val_accuracy: 0.6607\n",
      "Epoch 136/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2023 - accuracy: 0.9183 - val_loss: 0.9592 - val_accuracy: 0.6535\n",
      "Epoch 137/200\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_7 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=1000,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/500\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0542 - acc: 0.9800 - val_loss: 4.8865 - val_acc: 0.5673\n",
      "Epoch 2/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0526 - acc: 0.9830 - val_loss: 3.8052 - val_acc: 0.6122\n",
      "Epoch 3/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0112 - acc: 0.9931 - val_loss: 4.2008 - val_acc: 0.5978\n",
      "Epoch 4/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9946 - val_loss: 4.0361 - val_acc: 0.6302\n",
      "Epoch 5/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0066 - acc: 0.9977 - val_loss: 4.1366 - val_acc: 0.6230\n",
      "Epoch 6/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0841 - acc: 0.9738 - val_loss: 4.3061 - val_acc: 0.5763\n",
      "Epoch 7/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1218 - acc: 0.9653 - val_loss: 3.3528 - val_acc: 0.6104\n",
      "Epoch 8/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0365 - acc: 0.9884 - val_loss: 3.3635 - val_acc: 0.6032\n",
      "Epoch 9/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0114 - acc: 0.9954 - val_loss: 3.3668 - val_acc: 0.6122\n",
      "Epoch 10/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 3.4501 - val_acc: 0.6140\n",
      "Epoch 11/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0100 - acc: 0.9946 - val_loss: 3.5490 - val_acc: 0.6122\n",
      "Epoch 12/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0294 - acc: 0.9861 - val_loss: 3.3413 - val_acc: 0.6140\n",
      "Epoch 13/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0271 - acc: 0.9830 - val_loss: 3.4524 - val_acc: 0.5925\n",
      "Epoch 14/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0129 - acc: 0.9931 - val_loss: 3.6805 - val_acc: 0.6014\n",
      "Epoch 15/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0100 - acc: 0.9954 - val_loss: 3.5620 - val_acc: 0.6050\n",
      "Epoch 16/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 3.5593 - val_acc: 0.6104\n",
      "Epoch 17/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 3.7795 - val_acc: 0.6194\n",
      "Epoch 18/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 3.8217 - val_acc: 0.6086\n",
      "Epoch 19/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.2594 - acc: 0.9044 - val_loss: 1.3718 - val_acc: 0.5440\n",
      "Epoch 20/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1091 - acc: 0.9491 - val_loss: 2.5084 - val_acc: 0.5925\n",
      "Epoch 21/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 3.1336 - val_acc: 0.5961\n",
      "Epoch 22/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0090 - acc: 0.9961 - val_loss: 3.3260 - val_acc: 0.5996\n",
      "Epoch 23/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0109 - acc: 0.9954 - val_loss: 3.4304 - val_acc: 0.5978\n",
      "Epoch 24/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0098 - acc: 0.9961 - val_loss: 3.6061 - val_acc: 0.6050\n",
      "Epoch 25/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 3.6194 - val_acc: 0.6014\n",
      "Epoch 26/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0952 - acc: 0.9692 - val_loss: 2.7855 - val_acc: 0.6050\n",
      "Epoch 27/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0720 - acc: 0.9776 - val_loss: 2.5212 - val_acc: 0.6230\n",
      "Epoch 28/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9907 - val_loss: 2.8383 - val_acc: 0.6176\n",
      "Epoch 29/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 3.0252 - val_acc: 0.6158\n",
      "Epoch 30/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0039 - acc: 0.9992 - val_loss: 3.1664 - val_acc: 0.6068\n",
      "Epoch 31/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 3.2672 - val_acc: 0.6032\n",
      "Epoch 32/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 3.3670 - val_acc: 0.6050\n",
      "Epoch 33/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 3.4478 - val_acc: 0.6032\n",
      "Epoch 34/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0468 - acc: 0.9900 - val_loss: 3.4187 - val_acc: 0.5961\n",
      "Epoch 35/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3658 - acc: 0.9067 - val_loss: 2.0230 - val_acc: 0.5925\n",
      "Epoch 36/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0486 - acc: 0.9823 - val_loss: 2.8499 - val_acc: 0.5799\n",
      "Epoch 37/500\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 3.0220 - val_acc: 0.6122\n",
      "Epoch 38/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0088 - acc: 0.9969 - val_loss: 3.1904 - val_acc: 0.5925\n",
      "Epoch 39/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3246 - acc: 0.8975 - val_loss: 2.0007 - val_acc: 0.5943\n",
      "Epoch 40/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0669 - acc: 0.9815 - val_loss: 2.5389 - val_acc: 0.5817\n",
      "Epoch 41/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9846 - val_loss: 2.4448 - val_acc: 0.6086\n",
      "Epoch 42/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0288 - acc: 0.9892 - val_loss: 2.6544 - val_acc: 0.5925\n",
      "Epoch 43/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0257 - acc: 0.9900 - val_loss: 2.8005 - val_acc: 0.5978\n",
      "Epoch 44/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0178 - acc: 0.9884 - val_loss: 2.9891 - val_acc: 0.5943\n",
      "Epoch 45/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9931 - val_loss: 3.1611 - val_acc: 0.5925\n",
      "Epoch 46/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 3.2269 - val_acc: 0.5996\n",
      "Epoch 47/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 3.2916 - val_acc: 0.5996\n",
      "Epoch 48/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0102 - acc: 0.9938 - val_loss: 3.1307 - val_acc: 0.5907\n",
      "Epoch 49/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0987 - acc: 0.9522 - val_loss: 2.6610 - val_acc: 0.5601\n",
      "Epoch 50/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9815 - val_loss: 2.7463 - val_acc: 0.5907\n",
      "Epoch 51/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9907 - val_loss: 3.0980 - val_acc: 0.5943\n",
      "Epoch 52/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9946 - val_loss: 3.2145 - val_acc: 0.6068\n",
      "Epoch 53/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0576 - acc: 0.9738 - val_loss: 3.0086 - val_acc: 0.5548\n",
      "Epoch 54/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0582 - acc: 0.9738 - val_loss: 3.0022 - val_acc: 0.6068\n",
      "Epoch 55/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 3.0723 - val_acc: 0.6140\n",
      "Epoch 56/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0122 - acc: 0.9977 - val_loss: 3.0839 - val_acc: 0.6104\n",
      "Epoch 57/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0101 - acc: 0.9961 - val_loss: 3.2881 - val_acc: 0.6212\n",
      "Epoch 58/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0450 - acc: 0.9807 - val_loss: 2.6459 - val_acc: 0.5727\n",
      "Epoch 59/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0814 - acc: 0.9630 - val_loss: 2.8003 - val_acc: 0.6068\n",
      "Epoch 60/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0084 - acc: 0.9961 - val_loss: 3.0562 - val_acc: 0.6068\n",
      "Epoch 61/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0150 - acc: 0.9900 - val_loss: 3.0624 - val_acc: 0.6104\n",
      "Epoch 62/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0166 - acc: 0.9884 - val_loss: 3.3788 - val_acc: 0.6104\n",
      "Epoch 63/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 3.3620 - val_acc: 0.6284\n",
      "Epoch 64/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0077 - acc: 0.9961 - val_loss: 3.4234 - val_acc: 0.6302\n",
      "Epoch 65/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0209 - acc: 0.9938 - val_loss: 3.2064 - val_acc: 0.5907\n",
      "Epoch 66/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.9869 - val_loss: 3.2074 - val_acc: 0.6086\n",
      "Epoch 67/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0869 - acc: 0.9668 - val_loss: 2.8276 - val_acc: 0.5619\n",
      "Epoch 68/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0555 - acc: 0.9807 - val_loss: 2.6582 - val_acc: 0.5853\n",
      "Epoch 69/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0174 - acc: 0.9900 - val_loss: 2.9639 - val_acc: 0.6104\n",
      "Epoch 70/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0115 - acc: 0.9931 - val_loss: 2.8999 - val_acc: 0.6194\n",
      "Epoch 71/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 2.9881 - val_acc: 0.6176\n",
      "Epoch 72/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0628 - acc: 0.9707 - val_loss: 2.9394 - val_acc: 0.5619\n",
      "Epoch 73/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0514 - acc: 0.9800 - val_loss: 3.0135 - val_acc: 0.5889\n",
      "Epoch 74/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0300 - acc: 0.9854 - val_loss: 2.9444 - val_acc: 0.6212\n",
      "Epoch 75/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 3.1245 - val_acc: 0.6266\n",
      "Epoch 76/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0108 - acc: 0.9954 - val_loss: 3.2596 - val_acc: 0.6122\n",
      "Epoch 77/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9638 - val_loss: 2.8438 - val_acc: 0.5889\n",
      "Epoch 78/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0296 - acc: 0.9869 - val_loss: 3.0837 - val_acc: 0.5853\n",
      "Epoch 79/500\n",
      "1024/1297 [======================>.......] - ETA: 0s - loss: 0.1132 - acc: 0.9443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-dc19821f9d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_8 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=500,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/1200\n",
      "1297/1297 [==============================] - 8s 6ms/step - loss: 0.8574 - acc: 0.5505 - val_loss: 0.7647 - val_acc: 0.5368\n",
      "Epoch 2/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7391 - acc: 0.5412 - val_loss: 0.7295 - val_acc: 0.5494\n",
      "Epoch 3/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7188 - acc: 0.5451 - val_loss: 0.7054 - val_acc: 0.5655\n",
      "Epoch 4/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7076 - acc: 0.5582 - val_loss: 0.6957 - val_acc: 0.5673\n",
      "Epoch 5/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.7036 - acc: 0.5698 - val_loss: 0.6803 - val_acc: 0.5889\n",
      "Epoch 6/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6925 - acc: 0.5675 - val_loss: 0.6824 - val_acc: 0.5961\n",
      "Epoch 7/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6842 - acc: 0.5790 - val_loss: 0.6792 - val_acc: 0.5799\n",
      "Epoch 8/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6759 - acc: 0.5790 - val_loss: 0.6763 - val_acc: 0.5943\n",
      "Epoch 9/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6714 - acc: 0.5813 - val_loss: 0.6835 - val_acc: 0.5835\n",
      "Epoch 10/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6698 - acc: 0.5860 - val_loss: 0.6817 - val_acc: 0.5763\n",
      "Epoch 11/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6674 - acc: 0.5837 - val_loss: 0.6655 - val_acc: 0.5996\n",
      "Epoch 12/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6613 - acc: 0.5906 - val_loss: 0.6573 - val_acc: 0.5996\n",
      "Epoch 13/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6590 - acc: 0.5991 - val_loss: 0.6558 - val_acc: 0.5943\n",
      "Epoch 14/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6578 - acc: 0.5906 - val_loss: 0.6551 - val_acc: 0.5978\n",
      "Epoch 15/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6554 - acc: 0.6037 - val_loss: 0.6632 - val_acc: 0.5907\n",
      "Epoch 16/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6532 - acc: 0.5998 - val_loss: 0.6578 - val_acc: 0.6014\n",
      "Epoch 17/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6515 - acc: 0.5983 - val_loss: 0.6501 - val_acc: 0.5943\n",
      "Epoch 18/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6492 - acc: 0.5991 - val_loss: 0.6505 - val_acc: 0.5943\n",
      "Epoch 19/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6458 - acc: 0.6091 - val_loss: 0.6543 - val_acc: 0.5996\n",
      "Epoch 20/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6447 - acc: 0.6083 - val_loss: 0.6480 - val_acc: 0.5889\n",
      "Epoch 21/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6447 - acc: 0.6114 - val_loss: 0.6458 - val_acc: 0.5907\n",
      "Epoch 22/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6436 - acc: 0.6099 - val_loss: 0.6511 - val_acc: 0.5943\n",
      "Epoch 23/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6404 - acc: 0.6137 - val_loss: 0.6531 - val_acc: 0.5943\n",
      "Epoch 24/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6396 - acc: 0.6153 - val_loss: 0.6485 - val_acc: 0.6050\n",
      "Epoch 25/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6385 - acc: 0.6207 - val_loss: 0.6475 - val_acc: 0.6068\n",
      "Epoch 26/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6395 - acc: 0.6145 - val_loss: 0.6477 - val_acc: 0.6068\n",
      "Epoch 27/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6368 - acc: 0.6114 - val_loss: 0.6538 - val_acc: 0.6032\n",
      "Epoch 28/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6361 - acc: 0.6176 - val_loss: 0.6527 - val_acc: 0.5907\n",
      "Epoch 29/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6339 - acc: 0.6230 - val_loss: 0.6574 - val_acc: 0.5943\n",
      "Epoch 30/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6351 - acc: 0.6191 - val_loss: 0.6536 - val_acc: 0.6014\n",
      "Epoch 31/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6323 - acc: 0.6176 - val_loss: 0.6468 - val_acc: 0.6086\n",
      "Epoch 32/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6342 - acc: 0.6237 - val_loss: 0.6508 - val_acc: 0.6050\n",
      "Epoch 33/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6313 - acc: 0.6322 - val_loss: 0.6460 - val_acc: 0.6104\n",
      "Epoch 34/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6305 - acc: 0.6284 - val_loss: 0.6540 - val_acc: 0.6014\n",
      "Epoch 35/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6291 - acc: 0.6261 - val_loss: 0.6504 - val_acc: 0.6014\n",
      "Epoch 36/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6267 - acc: 0.6291 - val_loss: 0.6451 - val_acc: 0.5996\n",
      "Epoch 37/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6268 - acc: 0.6369 - val_loss: 0.6549 - val_acc: 0.5961\n",
      "Epoch 38/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6249 - acc: 0.6353 - val_loss: 0.6589 - val_acc: 0.5943\n",
      "Epoch 39/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6242 - acc: 0.6268 - val_loss: 0.6443 - val_acc: 0.5978\n",
      "Epoch 40/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6250 - acc: 0.6322 - val_loss: 0.6575 - val_acc: 0.5996\n",
      "Epoch 41/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6250 - acc: 0.6315 - val_loss: 0.6487 - val_acc: 0.6050\n",
      "Epoch 42/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6207 - acc: 0.6307 - val_loss: 0.6448 - val_acc: 0.5835\n",
      "Epoch 43/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6242 - acc: 0.6430 - val_loss: 0.6447 - val_acc: 0.5996\n",
      "Epoch 44/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6224 - acc: 0.6345 - val_loss: 0.6452 - val_acc: 0.6050\n",
      "Epoch 45/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6198 - acc: 0.6376 - val_loss: 0.6469 - val_acc: 0.6086\n",
      "Epoch 46/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6189 - acc: 0.6430 - val_loss: 0.6460 - val_acc: 0.6104\n",
      "Epoch 47/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6165 - acc: 0.6384 - val_loss: 0.6567 - val_acc: 0.5961\n",
      "Epoch 48/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6173 - acc: 0.6392 - val_loss: 0.6592 - val_acc: 0.5996\n",
      "Epoch 49/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6139 - acc: 0.6415 - val_loss: 0.6540 - val_acc: 0.6104\n",
      "Epoch 50/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6135 - acc: 0.6438 - val_loss: 0.6452 - val_acc: 0.6104\n",
      "Epoch 51/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6134 - acc: 0.6415 - val_loss: 0.6441 - val_acc: 0.6104\n",
      "Epoch 52/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6124 - acc: 0.6476 - val_loss: 0.6581 - val_acc: 0.6122\n",
      "Epoch 53/1200\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.6124 - acc: 0.6446 - val_loss: 0.6511 - val_acc: 0.6050\n",
      "Epoch 54/1200\n",
      "1297/1297 [==============================] - 3s 3ms/step - loss: 0.6103 - acc: 0.6492 - val_loss: 0.6428 - val_acc: 0.5978\n",
      "Epoch 55/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6134 - acc: 0.6476 - val_loss: 0.6523 - val_acc: 0.6068\n",
      "Epoch 56/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6089 - acc: 0.6476 - val_loss: 0.6393 - val_acc: 0.6122\n",
      "Epoch 57/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6079 - acc: 0.6507 - val_loss: 0.6476 - val_acc: 0.6140\n",
      "Epoch 58/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6083 - acc: 0.6469 - val_loss: 0.6611 - val_acc: 0.6068\n",
      "Epoch 59/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6051 - acc: 0.6600 - val_loss: 0.6430 - val_acc: 0.6122\n",
      "Epoch 60/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6044 - acc: 0.6592 - val_loss: 0.6439 - val_acc: 0.6194\n",
      "Epoch 61/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6024 - acc: 0.6608 - val_loss: 0.6430 - val_acc: 0.6140\n",
      "Epoch 62/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6006 - acc: 0.6646 - val_loss: 0.6611 - val_acc: 0.5961\n",
      "Epoch 63/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.6015 - acc: 0.6600 - val_loss: 0.6409 - val_acc: 0.6158\n",
      "Epoch 64/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5991 - acc: 0.6623 - val_loss: 0.6471 - val_acc: 0.6104\n",
      "Epoch 65/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5988 - acc: 0.6584 - val_loss: 0.6423 - val_acc: 0.6122\n",
      "Epoch 66/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5969 - acc: 0.6669 - val_loss: 0.6478 - val_acc: 0.6158\n",
      "Epoch 67/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5948 - acc: 0.6654 - val_loss: 0.6402 - val_acc: 0.5871\n",
      "Epoch 68/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5982 - acc: 0.6631 - val_loss: 0.6392 - val_acc: 0.6122\n",
      "Epoch 69/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5924 - acc: 0.6685 - val_loss: 0.6562 - val_acc: 0.6068\n",
      "Epoch 70/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5926 - acc: 0.6662 - val_loss: 0.6583 - val_acc: 0.5961\n",
      "Epoch 71/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5941 - acc: 0.6715 - val_loss: 0.6602 - val_acc: 0.5925\n",
      "Epoch 72/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5930 - acc: 0.6677 - val_loss: 0.6454 - val_acc: 0.6050\n",
      "Epoch 73/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5927 - acc: 0.6677 - val_loss: 0.6492 - val_acc: 0.6068\n",
      "Epoch 74/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5872 - acc: 0.6646 - val_loss: 0.6390 - val_acc: 0.6050\n",
      "Epoch 75/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5885 - acc: 0.6669 - val_loss: 0.6353 - val_acc: 0.5961\n",
      "Epoch 76/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5949 - acc: 0.6700 - val_loss: 0.6408 - val_acc: 0.6086\n",
      "Epoch 77/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5848 - acc: 0.6746 - val_loss: 0.6502 - val_acc: 0.6086\n",
      "Epoch 78/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5837 - acc: 0.6731 - val_loss: 0.6482 - val_acc: 0.5978\n",
      "Epoch 79/1200\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.5843 - acc: 0.6715 - val_loss: 0.6436 - val_acc: 0.6068\n",
      "Epoch 80/1200\n",
      " 352/1297 [=======>......................] - ETA: 1s - loss: 0.5720 - acc: 0.6676"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-d89ccd224b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.00001)\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.00001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_9 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=1200,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
