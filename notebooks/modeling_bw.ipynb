{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras) (3.12)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/36/67f809c135c17ec9b8276466cc57f35b98c240f55c780689ea29fa32f512/pip-20.0.1-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 23.8MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-20.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras\n",
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 1806 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "train_data_dir = '../data/bwcracks/train'\n",
    "test_data_dir = '../data/bwcracks/test'\n",
    "\n",
    "# Get all the data in the directory data/validation, and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(256, 256), batch_size=463)\n",
    "\n",
    "# Get all the data in the directory data/train, and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(256, 256), batch_size=1814)\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAIAAADTED8xAAAWC0lEQVR4nO1d2XblqA71yer//+VzH3zjIoxCE1uY/dLVic2gWUI4n+/3eyX4fD7ZTzr4fD73P+ivpC/OvqWF1h6He3/2e2PJ+tk0Z09nOpGWJKTjVNfcmugn+3/KUj6/uB9mrP555R5n9vX+wobPDFfVefH7C+J00eEg/Vp4ltpZczmjrX47w8g6dqxU+avU/KiYt2yQ6ozyWZZAhV+U7Xcm+o898XvQJ2722/R/tTx7fzERRf8amf9UZDthmNyH/JcOxCMl+13ncJaxkuEKh95WZWvL6WOBTryePnC1t0+X/luLqr/KcwA2EKLhak4yFak/6U064FogrMEI7HwsfeZJyYYP14NYlYBV6ATAeTxbGXts2yWObomvT2ksCM09rUxny/88gGQdvMIIgtMggrjUSpFBsEc6RzIrRkHnyU8B4phTYMub7nr+hEByXZwaQVH1b6Is1yiKO7aTJ2Iw8Dxf/XlqmP1PACRVbOYyWkcG1wovaX3swp4dJGxwAJ378piZ/TpjrlYVWy0JVsFa6V81tQNmIxlJWpnNyx4/G4fHoP5b3++3cg6QRfNvMHs33rPTFtStwNQRigXGKkqJBZUXFRMWBGGYGNMoEdDkWUfFzRCIUVigYNaXuUUmw4VZsIExpuTAkTI4mvRbT+GaAzD2A8UPC+Bs0K7iOQu3StTV7wXqHCDzgMPsEqvKlw5AJnsJLToTYyesKhAyEMSoKhw4llsLvOaf4bFd9bcDBUhP9dnAYU+VBLBpydTs8lU5nHxRFtlZA71BqPVwGdSMPYCQLiBntDei92bayagDg0wVjOIbn+a59BmnEEhr5/LulNsGZHQhLk/FH85iOF2Vr5iwIx2bCO/NAXYKnVWk34ca1jrQ/0kJcwXQdXy6di6E1bxoLWLbKLMuhiz+udrxk8mKxJBrVKCYIYWplDtU3K0litksFE4OlmNty2oLmKvKoNVqMTtOhzgTIRCan5Wsx7Ow60A0eanNk7NLqgitSakKQF80WpFE/cWpKaBMhgqEJTh2rMUr3A1BVYDW0ktyuDniZz1QJ1kLEyoJ5fHDJ/YK+9rC/y6QVjznD5Uep1ZYySvGCRGRC2x8ks8OlCczVVL0+iPWdrcrzntDJTEizvgqsQPBw+tWMNJRgOqvdjgIM22RR4Aw3Y+12Q460n81Qp1H9J9fTfcCldMflLTOiNNpTZklo5DsDgX+EtZHFuyHy1XN5QDDsMG6nTDV43QuSVj/GAl2YDOsQgorJ+x3N4OcFKWcaH4c15lVtw58ul9prxap0h9mD/C20HKvwmFfgqFV7Uc+s8h9AgJviFksfuqJv0IHTBEhs2LVoW4YUdX18+gt0hADmJcLVhTMsmltbrmgCvRsOE2VJGeEB3FBCV+JgtFSpL6CrSyDHok/uPQ+njUMnqtghkC8YHd7cQffoE/HqDwR0s16+9jhIEwLa8+MrGeXd4w6Q0v6TXqBwE1dOICXj6aWJ9yFMyn28QCBbFsJ8HTIeXkqKkR9GJnuCPCJm33gGVuvwiy/vL8NesJcFfAo2ak5LoeWbMzu7qc/q4XI+t9HkUC9XZzyWJ/s+3UWLUyB/rtYXp4XGLROfJeEGa1jdrvFKJY1VMZBwPLsfxAUtta3fN1CVJvklqzkzUDISdTKoDgqQVkJwjoPLgBG/PQrXMI2DK3nGdgpId5gF9UtLJf+606CjTJdBLYhkFiO6LvIbjKtXUyGH4tLBs9PYC+IgOjn3qiG+PR7AiZrKqB2DtAKliQ74b1LMTbPahlTHOUhYomZm2XNPwWwZiplfGfB4tV/LwAP1scGKsqmcGr+SCKXGkIVvnbq61pT0NcALqk7IWjPiP6iWwrAHoo3yNEBN4QmtX4vUGn1tUY7IMI5/sHkETEEMrkUf87818KZboD5Bj12aHoA3UTK6LThAAerrJXwiK2pAEb7OTqggmNNHrQElSjAgxxAi8rpKYEn504Q5QDw62wlUgkMWbqiI2htDhC7UnLNrnal5sEU/E8Vy4rtsi/DAR4MQ80OCPXEY5URTOcdl0GXX9cSjiM/VD9IoSgPun1ivK+2AN1FtJvoiLIK/JtZ0sJJZ14Jo0UKAB7KL1GAbFJwEslhtEEL3lUVeKxY/QfAuRuieVMR+BxZiCpxeknwsL4bhdaPOdk7r11yCzT6kZxCFchn/0uoHJ27Bx3cnI30bdBZWWQXCijzUu9b+B57l07bVIdjudbqp0wUukGdU0z6pVLJt1vu11tPpowfJlGecfmqnCdKMJzh+/26/o0wCb6TfwhVyJKgyU/r6wR200VPu2OvPsXbCj4I2IDmg4/jRsESTpwUeQPofBdoOYgdubpXfLSGCgoQ8y9kRKQqUBXE/atzK1wTvAUQKCBcQ2wFoGv/sJ7DA4IErMIee98nCT64ARKZIIBSoVpzH+AE0KZwPplB5uZwbT/E53SxpX3CEQWHZaTdmpjcJBLh50oOLG1X9AsceuEUhRRXAiuRS0AKgXTphWMIh9AtCt3/YOw9CrkCgU7SPzmACicWWqC+7lnLGUMH7gUbUczOEi3puzZC7DJohr4kvTMwkIsprKD3NZxoVsI0w4XArI45dKpd4nbUsr+6+nMcTGnsVh7gAjZXKvj8gvi8JDNhv+WGvo2fqAJdwNp8wEZ2IsaQ5tBSQb03kj63wSHiBlsABz6Fp1ZYCYHAHV8fz8dIVi9kW2CeM7A5XlEA9e35HzMDcugKdUISDlmkRxcADw+wXByzHR1B3BizwrZbFaiKhRpYapq17u2n3rPbmWL3S88B3FSiOpHpRfKFx/DZGkrB5a3NdEd/PICwbBwFq0Skmpw8Z1U70by1HcA9vtQDENEqpdNViJKTPcOaegZrSFZe9R4+pAhMcQaEx/hGCqAC/A4FTBwPMAGGbPmLY2g3MouhfRlSI68CrYrSfILg7y/UR1ZZfEqEKkFaP7ySBOObfEJvs9SihdYeKW3bE9bC1MniH7D3Ua5fYolb1JhiwRuCIrnYiL4ge2AHeSTzhlhILqvUg7A3eFIcqFDb4qYrlBioWOp/CjDcG9r+eQi0iyjrDI1/CvBoUjVN3MyZAsqW1rkpZWQ2oMRAZTH6l+LXYpDyo+aF2bIVl6fFU8weW/mS8gsxlDtmOITYNc8DrEPgkLo8Npbg35fh6KYCylFALWYz6IrapZ3c64dAxIlTABYHDtgoWanIWV0h0XJHsVshQJzyQugGS9k4uuQFzOmv7KsQwyWWrQTpi7rWYjYkU/dCITzbbG6KvyNdDJlYKYPOIpX+ha1EFsOu9TAWmxK2wS7H7Er6BuLz+XCuRFYXQaQsDlOthw3hQIhACzWr/TuMKs73+0WpbZUwKgW6VRglVWPAijMI1Nmndil+G2uHgyP9JdTP49QUQJ1bwsS69SLmiWYKO1NyjFQJ6M+iSIR1uZQTC2tuONJfxX8X5MH7m4GZ0++Kn2MYjPASwkbf5o/w2h4acIqPvPhNsbXEhw7RHQs/B1A5Uhl2L4NIMwNrV24xu+6YIMz972p3ubV+JUTWWFvts31mZ5z8yVcox3LWGtFBsSkahFM/a9s5h3HCwgNmNuSL2a8FAxbNEEgSwlIe6z8wOzvlYfradNvW2VholZbMuwT/2qHxj9+n/G/5MPFdyfYRCsqKUUoG3Tsx1bjXh3TpGv57plSZntJQvXF1ArOBPgQ83V1KWIV2aMn0DyiBx+wKl4QQnpOWJTU3I8rDnzbM4jsAS1au2QpB531rq4rSs+R+AqMjNwN+q5IcUE0iiw1GarF0A+hUwkBofQCIlc1wVSOtZbMfoT/SL8csU57nQU67OljfDWonoLFEH1ZQGMFkan3AuaCvAFMna9adSJLbWIwXhUI8OwLbMDsDVrcvXg6gVWroNEFcYe23XKWJh3rpw9ZEAy8uScDxAIq0KG1DmhMjWw51fH8xfLIl/abYlRdOOUBJvg5BHzkIZHWyWpYdgnpIWCz4MhyxQBmOwdaH3C3RD0coKDh5gCqTkDmH5vGP4TfCgjJoP9jdoFKhO1TVYXomSAgdfnbYeW8SgHC9Zfg7y7Oo2FDG7FNMSM+ycYg3zlXexxIOBwgVCYgScoAo6o0O5eXrVNlp6U6B6rtDwaWQQEtwoQSrA3xFVVmhyjFL9d013aBVUO4SOLOZcdTaeYUSuPNoKNf24col4yOgRaKfyyyjsk7UquMPlcRuSfKRGV03l4btLxOMVvI9CwQH1afnJz1NdLuQJiQo+/x/apsMmgxf8aGzYsapkk1pBe6Szq6eByiftoNimFQtp/bdDjuI4tlmN+g625Sw8mEZFkQRw9nzHMCaxwwR1HLHDPypl9n3OAinSK2dCpU8e41akAdRfWr8+RthpphicPpwdQMOXMm8zbU0kO2jf7YoHFl9zBZUgqWWYLR+9a8XiN3K0tdRifHuU6Qa6ZYR0TAnJq5qKtNoPawiTyoHHRfZuNLP4OygzqMHf0IgdSuiVRgpQTTJwgdMCzKpTZryjVNLUh+nIyTpmIzxW35eK5zzPgfIYpipbVAertILJE+lLKNcP3HXukZKcbRnKK2agVFcl4KvAPTshCeXGTUd4K88ZZrhObW1eNkF9MMX6Q/reIAqNeXc1a2gMQhqKh+rSlvW6KShPguYIqbH3weQc5dOO8lciqXDIaakwTS00x28FRdUg6LOvG6pdn4jTKvCcPmGLmm8ZFqB8QdIVkPEFPEROJJ7AIuUSDgI+zhmlehYxNaUAXFqAEJ47sL2RpiiKHTGSUuiC9NKOogM5h2CLtEBC93zYZ/C2RuInJVRo0ocOVXskk9XHRaEwh3IGxZWQeoBomzYoZOH/sP0/GtYM4lC4aBY8FmUWbBP7BknCWxzO5vkERP3KFBszXAmxfqP42ohk3KtZMD6wGiPmpViDuCcwwTwAERM+QfGY1r2qaqZSwKeJRbXGUPvGsADQHFo1j5RTOOSDe5RMKWgz4IACnD9xiESngn5bS0uUErOgJxBq0BNvywStVgumBGl8DboQxaLWQAZOlwS1QNY7EoluaSUGjtP9sdJMbva22RASQM+dH0IZbTwBbgq5P6qNcLUudiWtKWAt3f1SgBlwPcyiQc5k4SK0bFqIKyUBELqQVTHkP2/xyzrHQAh4hR2bawv0ffpIHvHyQSq1ipb3p9zAIRFS7Cqnmhn7TIWhmCQSl5nVHEpZ4EugxLPFxeKhSRpG7Z5h6sq9lubsl/1m6Dke09HqNqa+39xT4JDsF+oe2tr5xaGFqSzo+Vdy59Ae4BZrNUZXj/M8J5D/xkhQliZKdxcoB/M4d4HmM2llvcPSxawJHFU513EIorCfQAjKxL0FEmxmzqFBZFv3imOHIhfz65FCqBLPiGWU1+osSrdrDzgMNEC1frP8++xAgxPXhhRykELujZlOJqum3Xg7+cX9Ff6qfBYAXQtkymNljuBoNCim3pM1ZlIawTQMqikj/LgwX4NS+qrdVWAWLQ+YCAci7c6B7gR1w/EXfkDqLoIBfp/aoHYmtZ3vjgNVc6IFZN82p/eaO1iyFln1jM9QFXRs6LQcJNDUxHLlrwHGfumrH6n7pSO4+ZJmBcXrDv+2KeqsSxoBn+/J5zxobbFyjMZMDrpX3knWH1Gt24IO0l1prNkI87q2oo4pMPSD+HXWtbhMogxqOJi4roaLdzqaqq0GanVudwsg8bisXq82GdqFLJYw8fT2s34+XyaSTBaL9r3F27TVX9+8vIHIKEBD/+y7fs/EfeQwtpU0NcQnZJ0WO/XNNG6//EFvxJJR0qmJSJ4PIMuPl5fVdpEAR7MNqj2oV6NPnpCgZxKnREex3ILyX97uGy7SznEkYlk3IPaDpAcTUz91sMDhOsPuYJneHEhj/spIUD6W9xz07fllCVeSAH/89bdcoCD0FhQuxNOaaSyLzR+fZyQjIhZQkkvxbNfXJsYhMtJdKtbBw9EN8LY/MherLoRepce/fnUsYTrG62uNtwu0ACRA7ClXzLjNnITzptBwe9OMDGsN43+HYT+BOuxoKwA8gsWs6/gyNkSS3xanjLQzy5v9NqheZuEJY0KquxHaMU7uFjuV9kD9Hvoh6qp3u2tLojlLogfAUCACkHA9ziLU0OQAjwkSOF5ac4CQwUuPcD4Ff+bvvc/wlG/hY0LkeXWwLWdsby5MqjW6VW5xNC1vNCLb6G6qewDDVDgKeecAtzl83T/U7To3HKANSpEYMqEEIHsFNsPcw7CtA6AYyFiU7cEnmcmC0eTVoH+tFZjB4hybLw1InQpgEBPzVaINLx57KVD35tkcPq7LW4hcPHlkFRWrHqB3JptWhJMl2yhcr4qLlIBFMX8muEwnYC8rGGk5xunHFCNXuYK0FmWIoP9+0mzuezUwGLYKHDYvocHeOQjywconaFDQ6hVmcYUtZNgDPkiZJxfCPTwEo2paOu5sdONBTaqROic0DHgfSGms5/M3vubZEwncNCHxEx8Pp/1fyWyU150O1h4p60Nem6jm+8B/ZXIzsb2a6EDwaEnxJ3gElnu+x4+eYZhe1BVWMJeHwJNodrRTvweBD6/n7Nz/KVuAywF+Pz+yZ3yV8NbiH2sFamg0bYzGJovd5hYIRB9/1tWCekObUswNi6nlbcCnFJjH+GkH6FaLeqGxKT4m2OGN++dASG5sEKgFOEuZKgAcEl7A/HPX7+86q++fXZZKQojMicw1SvhXQUCJ+WW2JjmmYpWq+T94jJiCLQxwyiAqgWBLKOFlFbZyWnafJnVDNMnERXgBjjpTQGydyhV7GOqb+CPMoTY3sFBFWW4PyvPJh5gj+t8G2xhe8jPQ3FDoIMXgmd0nlCNoQwnBNoHaaEjSgUzg38jILQHOEEIHU+x74pMN44JF37VJpaFOOhAy3xG6cVIe4fZq8Vqhz6QAF9k1SHXeegQiA3FGMAznAAJXWK1muuHQIHyp6ml+idYgSgZESrkrXiAiNwaJn/Rs8MDI9RDIF0naHcuRv/YVtkQckABsslQ6dQgRQXD4CFK3UAIh5Dm3IhvwUjGqFWgl4j4chwKlzC1O9N/JE99BRtAlyyUiPE9jLD2usfhTqC8fmFBvVM7SmEdenAOwl7LofKbRQtD9pdwwTr5FP2VyPc44gflVSOLKe5/vJC8l/uupa0QJzluWWIfymxJebpfXfZhrCqz34lVTqB6DXwDKPpVSjmB3wtkeq4U605ZlRQOtlk+BSydiauSV8xEzXC3q7LQhG1ObdkSRswE9qCSESjEESmAoqtSGUcXy62jtXCjnTZMfdmBiKElRWmHdqP15xfW61HZkakOUHppMG1TijX3AXTpUs3nPn+hOJ0Dyr2whyoPHxTRkR5/mi8J5zgKYNFa/OiAD92tu0d1e2mvReK4TSbWAf8cwKHCbXHYSex+lU/68vOsKEDJAUrM3vYyXg4fQju6vQ1ei2kFcItHZxlvEZKB4FahiLkQPvQ9gIRPmbGkS+GUvA6XByX9N47oG2FaAaxzo1R/ZrlOfB5QvocYrvmF/kGlPGDyXaCIErYQxJy7/4AnzdMFL2wIH6K8v3EVxYn/AZvIEDcR3b1VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F758B0E0D30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing an image\n",
    "array_to_img(train_images[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1806, 256, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (1806, 256, 256, 3) (1806, 2)\n",
      "test data shape: (0, 256, 256, 3) (0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Checking shape of data\n",
    "print('train data shape:', np.shape(train_images), np.shape(train_labels))\n",
    "print('test data shape:', np.shape(test_images), np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img: (1806, 196608)\n"
     ]
    }
   ],
   "source": [
    "# Unrowing/reshaping\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "print('train_img:', np.shape(train_img))\n",
    "\n",
    "# test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "# print('test_img:', np.shape(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the labels\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dutch': 0, 'Flemish': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels final: (1806, 1)\n"
     ]
    }
   ],
   "source": [
    "# Transposing the labels\n",
    "train_y = np.reshape(train_labels[:,0], (1806,1))\n",
    "print('train labels final:', np.shape(train_y))\n",
    "\n",
    "# test_y = np.reshape(test_labels[:,0], (463,1))\n",
    "# print('test labels final:', np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(123)\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(20, activation='relu', input_shape=(65536,))) #2 hidden layers\n",
    "# model.add(layers.Dense(10, activation='relu'))\n",
    "# model.add(layers.Dense(5, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# histoire = model.fit(train_img,\n",
    "#                     train_y,\n",
    "#                     epochs=5,\n",
    "#                     batch_size=100,\n",
    "#                     validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  3)))\n",
    "model1.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model1.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model1.add(layers.Dense(20, activation='relu'))\n",
    "model1.add(layers.Dense(100, activation='relu'))\n",
    "model1.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "model1.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1264 samples, validate on 542 samples\n",
      "Epoch 1/500\n",
      "1264/1264 [==============================] - 31s 24ms/step - loss: 3.8518 - accuracy: 0.5380 - val_loss: 3.2001 - val_accuracy: 0.5480\n",
      "Epoch 2/500\n",
      "1264/1264 [==============================] - 27s 22ms/step - loss: 2.9787 - accuracy: 0.5443 - val_loss: 2.7918 - val_accuracy: 0.5554\n",
      "Epoch 3/500\n",
      "1264/1264 [==============================] - 28s 22ms/step - loss: 2.4934 - accuracy: 0.5403 - val_loss: 2.4106 - val_accuracy: 0.5517\n",
      "Epoch 4/500\n",
      "1264/1264 [==============================] - 27s 22ms/step - loss: 2.1398 - accuracy: 0.5554 - val_loss: 2.1256 - val_accuracy: 0.5535\n",
      "Epoch 5/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 1.8345 - accuracy: 0.5641 - val_loss: 1.9416 - val_accuracy: 0.5701\n",
      "Epoch 6/500\n",
      "1264/1264 [==============================] - 27s 22ms/step - loss: 1.5744 - accuracy: 0.5578 - val_loss: 1.6700 - val_accuracy: 0.5590\n",
      "Epoch 7/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 1.3762 - accuracy: 0.5728 - val_loss: 1.4343 - val_accuracy: 0.5554\n",
      "Epoch 8/500\n",
      "1264/1264 [==============================] - 26s 21ms/step - loss: 1.2089 - accuracy: 0.5680 - val_loss: 1.2753 - val_accuracy: 0.5720\n",
      "Epoch 9/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 1.0880 - accuracy: 0.5633 - val_loss: 1.1633 - val_accuracy: 0.5683\n",
      "Epoch 10/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 1.0080 - accuracy: 0.5720 - val_loss: 1.0902 - val_accuracy: 0.5535\n",
      "Epoch 11/500\n",
      "1264/1264 [==============================] - 26s 21ms/step - loss: 0.9383 - accuracy: 0.5720 - val_loss: 1.0796 - val_accuracy: 0.5627\n",
      "Epoch 12/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 0.9267 - accuracy: 0.5759 - val_loss: 0.9961 - val_accuracy: 0.5554\n",
      "Epoch 13/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 0.8440 - accuracy: 0.5704 - val_loss: 0.9982 - val_accuracy: 0.5332\n",
      "Epoch 14/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 0.8447 - accuracy: 0.5696 - val_loss: 0.9752 - val_accuracy: 0.5664\n",
      "Epoch 15/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 0.8316 - accuracy: 0.5783 - val_loss: 1.0839 - val_accuracy: 0.5314\n",
      "Epoch 16/500\n",
      "1264/1264 [==============================] - 26s 21ms/step - loss: 0.8226 - accuracy: 0.5902 - val_loss: 0.9389 - val_accuracy: 0.5664\n",
      "Epoch 17/500\n",
      "1264/1264 [==============================] - 27s 22ms/step - loss: 0.8177 - accuracy: 0.5775 - val_loss: 0.9862 - val_accuracy: 0.5646\n",
      "Epoch 18/500\n",
      "1264/1264 [==============================] - 32s 25ms/step - loss: 0.7863 - accuracy: 0.5934 - val_loss: 0.9181 - val_accuracy: 0.5554\n",
      "Epoch 19/500\n",
      "1264/1264 [==============================] - 30s 24ms/step - loss: 0.7708 - accuracy: 0.5894 - val_loss: 0.9251 - val_accuracy: 0.5332\n",
      "Epoch 20/500\n",
      "1264/1264 [==============================] - 31s 25ms/step - loss: 0.7567 - accuracy: 0.6044 - val_loss: 0.8975 - val_accuracy: 0.5627\n",
      "Epoch 21/500\n",
      "1264/1264 [==============================] - 33s 26ms/step - loss: 0.7393 - accuracy: 0.6052 - val_loss: 0.9491 - val_accuracy: 0.5554\n",
      "Epoch 22/500\n",
      "1264/1264 [==============================] - 33s 26ms/step - loss: 0.7502 - accuracy: 0.5918 - val_loss: 0.8797 - val_accuracy: 0.5590\n",
      "Epoch 23/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.7325 - accuracy: 0.6005 - val_loss: 0.8997 - val_accuracy: 0.5535\n",
      "Epoch 24/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.7323 - accuracy: 0.6076 - val_loss: 0.8542 - val_accuracy: 0.5572\n",
      "Epoch 25/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.7321 - accuracy: 0.6028 - val_loss: 0.8738 - val_accuracy: 0.5369\n",
      "Epoch 26/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.7091 - accuracy: 0.6195 - val_loss: 0.8608 - val_accuracy: 0.5461\n",
      "Epoch 27/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.6957 - accuracy: 0.6163 - val_loss: 0.8543 - val_accuracy: 0.5443\n",
      "Epoch 28/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.6938 - accuracy: 0.6195 - val_loss: 0.8473 - val_accuracy: 0.5609\n",
      "Epoch 29/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.6930 - accuracy: 0.6305 - val_loss: 0.8511 - val_accuracy: 0.5554\n",
      "Epoch 30/500\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.6923 - accuracy: 0.6305 - val_loss: 0.8281 - val_accuracy: 0.5683\n",
      "Epoch 31/500\n",
      "1264/1264 [==============================] - 30s 24ms/step - loss: 0.6708 - accuracy: 0.6440 - val_loss: 0.8451 - val_accuracy: 0.5756\n",
      "Epoch 32/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6562 - accuracy: 0.6282 - val_loss: 0.9251 - val_accuracy: 0.5720\n",
      "Epoch 33/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6756 - accuracy: 0.6274 - val_loss: 0.8206 - val_accuracy: 0.5609\n",
      "Epoch 34/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6666 - accuracy: 0.6400 - val_loss: 1.0603 - val_accuracy: 0.5609\n",
      "Epoch 35/500\n",
      "1264/1264 [==============================] - 27s 21ms/step - loss: 0.6623 - accuracy: 0.6369 - val_loss: 0.8273 - val_accuracy: 0.5720\n",
      "Epoch 36/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6477 - accuracy: 0.6353 - val_loss: 0.8161 - val_accuracy: 0.5683\n",
      "Epoch 37/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6504 - accuracy: 0.6495 - val_loss: 0.8266 - val_accuracy: 0.5480\n",
      "Epoch 38/500\n",
      "1264/1264 [==============================] - 26s 20ms/step - loss: 0.6504 - accuracy: 0.6582 - val_loss: 0.8185 - val_accuracy: 0.5498\n",
      "Epoch 39/500\n",
      "1264/1264 [==============================] - 26s 20ms/step - loss: 0.6268 - accuracy: 0.6551 - val_loss: 0.9218 - val_accuracy: 0.5572\n",
      "Epoch 40/500\n",
      "1264/1264 [==============================] - 26s 20ms/step - loss: 0.6170 - accuracy: 0.6638 - val_loss: 0.8787 - val_accuracy: 0.5664\n",
      "Epoch 41/500\n",
      "1264/1264 [==============================] - 25s 20ms/step - loss: 0.6138 - accuracy: 0.6614 - val_loss: 0.9486 - val_accuracy: 0.5664\n",
      "Epoch 42/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6134 - accuracy: 0.6693 - val_loss: 0.8069 - val_accuracy: 0.5572\n",
      "Epoch 43/500\n",
      "1264/1264 [==============================] - 25s 20ms/step - loss: 0.6127 - accuracy: 0.6693 - val_loss: 0.8193 - val_accuracy: 0.5756\n",
      "Epoch 44/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6060 - accuracy: 0.6733 - val_loss: 0.9612 - val_accuracy: 0.5609\n",
      "Epoch 45/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.6155 - accuracy: 0.6606 - val_loss: 0.8216 - val_accuracy: 0.5720\n",
      "Epoch 46/500\n",
      "1264/1264 [==============================] - 23s 19ms/step - loss: 0.5817 - accuracy: 0.6859 - val_loss: 0.8133 - val_accuracy: 0.5535\n",
      "Epoch 47/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5808 - accuracy: 0.6804 - val_loss: 0.8346 - val_accuracy: 0.5701\n",
      "Epoch 48/500\n",
      "1264/1264 [==============================] - 25s 19ms/step - loss: 0.5848 - accuracy: 0.6946 - val_loss: 0.8032 - val_accuracy: 0.5720\n",
      "Epoch 49/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5807 - accuracy: 0.6748 - val_loss: 0.8290 - val_accuracy: 0.5775\n",
      "Epoch 50/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5733 - accuracy: 0.7025 - val_loss: 0.8054 - val_accuracy: 0.5775\n",
      "Epoch 51/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5659 - accuracy: 0.6994 - val_loss: 0.8485 - val_accuracy: 0.5627\n",
      "Epoch 52/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5736 - accuracy: 0.6867 - val_loss: 0.8134 - val_accuracy: 0.5867\n",
      "Epoch 53/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5637 - accuracy: 0.6930 - val_loss: 0.8477 - val_accuracy: 0.5590\n",
      "Epoch 54/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5734 - accuracy: 0.6954 - val_loss: 0.8070 - val_accuracy: 0.5923\n",
      "Epoch 55/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5753 - accuracy: 0.7002 - val_loss: 0.8495 - val_accuracy: 0.5627\n",
      "Epoch 56/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5441 - accuracy: 0.7104 - val_loss: 0.8472 - val_accuracy: 0.5646\n",
      "Epoch 57/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5462 - accuracy: 0.7009 - val_loss: 0.8310 - val_accuracy: 0.5867\n",
      "Epoch 58/500\n",
      "1264/1264 [==============================] - 25s 20ms/step - loss: 0.5420 - accuracy: 0.7176 - val_loss: 0.8285 - val_accuracy: 0.5830\n",
      "Epoch 59/500\n",
      "1264/1264 [==============================] - 25s 19ms/step - loss: 0.5456 - accuracy: 0.7073 - val_loss: 0.8574 - val_accuracy: 0.5720\n",
      "Epoch 60/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5440 - accuracy: 0.7184 - val_loss: 0.8207 - val_accuracy: 0.5369\n",
      "Epoch 61/500\n",
      "1264/1264 [==============================] - 24s 19ms/step - loss: 0.5388 - accuracy: 0.7041 - val_loss: 0.8174 - val_accuracy: 0.5701\n",
      "Epoch 62/500\n",
      "1264/1264 [==============================] - 25s 19ms/step - loss: 0.5308 - accuracy: 0.7191 - val_loss: 0.8813 - val_accuracy: 0.5646\n",
      "Epoch 63/500\n",
      "1264/1264 [==============================] - 33s 26ms/step - loss: 0.5402 - accuracy: 0.7247 - val_loss: 0.8002 - val_accuracy: 0.5959\n",
      "Epoch 64/500\n",
      "1264/1264 [==============================] - 23s 18ms/step - loss: 0.5206 - accuracy: 0.7294 - val_loss: 0.8144 - val_accuracy: 0.5461\n",
      "Epoch 65/500\n",
      "1264/1264 [==============================] - 16s 13ms/step - loss: 0.5095 - accuracy: 0.7389 - val_loss: 0.7999 - val_accuracy: 0.5923\n",
      "Epoch 66/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.5228 - accuracy: 0.7334 - val_loss: 0.9071 - val_accuracy: 0.5498\n",
      "Epoch 67/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.5254 - accuracy: 0.7239 - val_loss: 0.8683 - val_accuracy: 0.5627\n",
      "Epoch 68/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.5179 - accuracy: 0.7136 - val_loss: 0.8163 - val_accuracy: 0.5830\n",
      "Epoch 69/500\n",
      "1264/1264 [==============================] - 16s 13ms/step - loss: 0.5062 - accuracy: 0.7310 - val_loss: 0.8281 - val_accuracy: 0.5756\n",
      "Epoch 70/500\n",
      "1264/1264 [==============================] - 16s 13ms/step - loss: 0.5062 - accuracy: 0.7358 - val_loss: 0.8149 - val_accuracy: 0.5812\n",
      "Epoch 71/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.4977 - accuracy: 0.7405 - val_loss: 0.8120 - val_accuracy: 0.5535\n",
      "Epoch 72/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.5070 - accuracy: 0.7294 - val_loss: 0.8091 - val_accuracy: 0.5590\n",
      "Epoch 73/500\n",
      "1264/1264 [==============================] - 16s 13ms/step - loss: 0.4830 - accuracy: 0.7547 - val_loss: 0.9092 - val_accuracy: 0.5535\n",
      "Epoch 74/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4907 - accuracy: 0.7500 - val_loss: 0.8252 - val_accuracy: 0.5923\n",
      "Epoch 75/500\n",
      "1264/1264 [==============================] - 16s 13ms/step - loss: 0.4824 - accuracy: 0.7579 - val_loss: 0.8150 - val_accuracy: 0.5941\n",
      "Epoch 76/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.4798 - accuracy: 0.7682 - val_loss: 0.8214 - val_accuracy: 0.5886\n",
      "Epoch 77/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4862 - accuracy: 0.7587 - val_loss: 0.8126 - val_accuracy: 0.5738\n",
      "Epoch 78/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.4915 - accuracy: 0.7468 - val_loss: 0.8234 - val_accuracy: 0.5867\n",
      "Epoch 79/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4735 - accuracy: 0.7571 - val_loss: 0.8281 - val_accuracy: 0.5923\n",
      "Epoch 80/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4924 - accuracy: 0.7445 - val_loss: 0.8552 - val_accuracy: 0.5683\n",
      "Epoch 81/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4705 - accuracy: 0.7753 - val_loss: 0.8594 - val_accuracy: 0.5904\n",
      "Epoch 82/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4685 - accuracy: 0.7690 - val_loss: 0.8472 - val_accuracy: 0.5793\n",
      "Epoch 83/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4920 - accuracy: 0.7634 - val_loss: 0.9073 - val_accuracy: 0.5572\n",
      "Epoch 84/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4776 - accuracy: 0.7524 - val_loss: 0.8224 - val_accuracy: 0.5627\n",
      "Epoch 85/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.4596 - accuracy: 0.7745 - val_loss: 0.8430 - val_accuracy: 0.5793\n",
      "Epoch 86/500\n",
      "1264/1264 [==============================] - 16s 13ms/step - loss: 0.4695 - accuracy: 0.7722 - val_loss: 0.8188 - val_accuracy: 0.5923\n",
      "Epoch 87/500\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.9186 - val_accuracy: 0.5664\n",
      "Epoch 88/500\n",
      "1264/1264 [==============================] - 16s 12ms/step - loss: 0.4473 - accuracy: 0.7729 - val_loss: 0.8190 - val_accuracy: 0.5849\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.00001)\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.00001)\n",
    "from keras.callbacks import callbacks\n",
    "stopping = callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=25)\n",
    "\n",
    "model1.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_9 = model1.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=500,\n",
    "                    batch_size=16,\n",
    "                    callbacks=[stopping],\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('../models/bw_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806/1806 [==============================] - 23s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5505943077875266, 0.7347729802131653]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "bw_model_1 = load_model('../models/bw_model_1.h5')\n",
    "\n",
    "bw_model_1.evaluate(x=train_images, y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
