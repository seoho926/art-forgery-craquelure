{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 17.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (1.11.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz (289kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 26.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from keras) (2.8.0)\n",
      "Building wheels for collected packages: keras-applications\n",
      "  Running setup.py bdist_wheel for keras-applications ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/dd/f2/5d/2689b5547f32c4e258c3b7ccbe7f1d0f2afbb84fb01e830792\n",
      "Successfully built keras-applications\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-19.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 463 images belonging to 2 classes.\n",
      "Found 1806 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "train_data_dir = '../data/Cracks/train'\n",
    "test_data_dir = '../data/Cracks/test'\n",
    "\n",
    "# Get all the data in the directory data/validation, and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(256, 256), batch_size=463, color_mode='grayscale')\n",
    "\n",
    "# Get all the data in the directory data/train, and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(256, 256), batch_size=1806, color_mode='grayscale')\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7F667BAE5400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing an image\n",
    "array_to_img(train_images[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1806, 256, 256, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (1806, 256, 256, 1) (1806, 2)\n",
      "test data shape: (463, 256, 256, 1) (463, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking shape of data\n",
    "print('train data shape:', np.shape(train_images), np.shape(train_labels))\n",
    "print('test data shape:', np.shape(test_images), np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img: (1806, 65536)\n",
      "test_img: (463, 65536)\n"
     ]
    }
   ],
   "source": [
    "# Unrowing/reshaping\n",
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "print('train_img:', np.shape(train_img))\n",
    "\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "print('test_img:', np.shape(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the labels\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dutch': 0, 'Flemish': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing the labels\n",
    "train_y = np.reshape(train_labels[:,0], (1806,1))\n",
    "print('train labels final:', np.shape(train_y))\n",
    "\n",
    "test_y = np.reshape(test_labels[:,0], (463,1))\n",
    "print('test labels final:', np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(123)\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(20, activation='relu', input_shape=(65536,))) #2 hidden layers\n",
    "# model.add(layers.Dense(10, activation='relu'))\n",
    "# model.add(layers.Dense(5, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1287 samples, validate on 552 samples\n",
      "Epoch 1/5\n",
      "1287/1287 [==============================] - 2s 1ms/step - loss: 8.9437 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 2/5\n",
      "1287/1287 [==============================] - 1s 439us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 3/5\n",
      "1287/1287 [==============================] - 1s 431us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 4/5\n",
      "1287/1287 [==============================] - 1s 432us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n",
      "Epoch 5/5\n",
      "1287/1287 [==============================] - 1s 436us/step - loss: 9.0923 - acc: 0.4359 - val_loss: 9.1102 - val_acc: 0.4348\n"
     ]
    }
   ],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# histoire = model.fit(train_img,\n",
    "#                     train_y,\n",
    "#                     epochs=5,\n",
    "#                     batch_size=100,\n",
    "#                     validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=(3, 3), activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=20, kernel_size=5, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=40, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=80, kernel_size=3, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=160, kernel_size=1, strides=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6833 - accuracy: 0.5659 - val_loss: 0.6885 - val_accuracy: 0.5530\n",
      "Epoch 2/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6822 - accuracy: 0.5652 - val_loss: 0.7032 - val_accuracy: 0.5530\n",
      "Epoch 3/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6802 - accuracy: 0.5644 - val_loss: 0.6854 - val_accuracy: 0.5530\n",
      "Epoch 4/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6641 - accuracy: 0.5644 - val_loss: 0.6800 - val_accuracy: 0.5530\n",
      "Epoch 5/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6601 - accuracy: 0.5590 - val_loss: 0.6719 - val_accuracy: 0.5314\n",
      "Epoch 6/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6547 - accuracy: 0.5520 - val_loss: 0.6764 - val_accuracy: 0.5278\n",
      "Epoch 7/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6471 - accuracy: 0.5821 - val_loss: 0.6755 - val_accuracy: 0.5206\n",
      "Epoch 8/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6351 - accuracy: 0.5682 - val_loss: 0.6731 - val_accuracy: 0.5566\n",
      "Epoch 9/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6454 - accuracy: 0.6060 - val_loss: 0.6812 - val_accuracy: 0.5278\n",
      "Epoch 10/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5891 - val_loss: 0.6932 - val_accuracy: 0.5296\n",
      "Epoch 11/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6849 - accuracy: 0.5428 - val_loss: 0.6910 - val_accuracy: 0.4847\n",
      "Epoch 12/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6832 - accuracy: 0.5405 - val_loss: 0.6900 - val_accuracy: 0.5332\n",
      "Epoch 13/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6808 - accuracy: 0.5636 - val_loss: 0.6890 - val_accuracy: 0.5224\n",
      "Epoch 14/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6806 - accuracy: 0.5636 - val_loss: 0.6870 - val_accuracy: 0.5530\n",
      "Epoch 15/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6696 - accuracy: 0.5644 - val_loss: 0.6723 - val_accuracy: 0.5422\n",
      "Epoch 16/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6554 - accuracy: 0.5736 - val_loss: 0.6744 - val_accuracy: 0.5135\n",
      "Epoch 17/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6589 - accuracy: 0.5883 - val_loss: 0.6828 - val_accuracy: 0.5458\n",
      "Epoch 18/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6478 - accuracy: 0.5790 - val_loss: 0.6735 - val_accuracy: 0.5206\n",
      "Epoch 19/50\n",
      "1297/1297 [==============================] - 13s 10ms/step - loss: 0.6805 - accuracy: 0.5297 - val_loss: 0.6908 - val_accuracy: 0.4973\n",
      "Epoch 20/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6865 - accuracy: 0.5289 - val_loss: 0.6896 - val_accuracy: 0.5278\n",
      "Epoch 21/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6820 - accuracy: 0.5690 - val_loss: 0.6742 - val_accuracy: 0.5332\n",
      "Epoch 22/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6791 - accuracy: 0.5374 - val_loss: 0.7106 - val_accuracy: 0.5458\n",
      "Epoch 23/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5536 - val_loss: 0.6886 - val_accuracy: 0.5530\n",
      "Epoch 24/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6809 - accuracy: 0.5644 - val_loss: 0.6955 - val_accuracy: 0.5530\n",
      "Epoch 25/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6703 - accuracy: 0.5644 - val_loss: 0.6765 - val_accuracy: 0.5530\n",
      "Epoch 26/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6600 - accuracy: 0.5644 - val_loss: 0.6871 - val_accuracy: 0.5530\n",
      "Epoch 27/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6826 - accuracy: 0.5644 - val_loss: 0.6864 - val_accuracy: 0.5530\n",
      "Epoch 28/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6617 - accuracy: 0.5644 - val_loss: 0.6846 - val_accuracy: 0.5530\n",
      "Epoch 29/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6748 - accuracy: 0.5644 - val_loss: 0.6838 - val_accuracy: 0.5530\n",
      "Epoch 30/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6666 - accuracy: 0.5644 - val_loss: 0.6986 - val_accuracy: 0.5530\n",
      "Epoch 31/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6651 - accuracy: 0.5644 - val_loss: 0.6797 - val_accuracy: 0.5530\n",
      "Epoch 32/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6397 - accuracy: 0.5744 - val_loss: 0.6988 - val_accuracy: 0.5458\n",
      "Epoch 33/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6391 - accuracy: 0.5983 - val_loss: 0.6813 - val_accuracy: 0.5673\n",
      "Epoch 34/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.6170 - accuracy: 0.6191 - val_loss: 0.7396 - val_accuracy: 0.5332\n",
      "Epoch 35/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6071 - accuracy: 0.6345 - val_loss: 0.7588 - val_accuracy: 0.5476\n",
      "Epoch 36/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6010 - accuracy: 0.6523 - val_loss: 0.9549 - val_accuracy: 0.5583\n",
      "Epoch 37/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6282 - accuracy: 0.6176 - val_loss: 0.8407 - val_accuracy: 0.5512\n",
      "Epoch 38/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6126 - accuracy: 0.6415 - val_loss: 0.7106 - val_accuracy: 0.5637\n",
      "Epoch 39/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6049 - accuracy: 0.6554 - val_loss: 0.7641 - val_accuracy: 0.5512\n",
      "Epoch 40/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5889 - accuracy: 0.6484 - val_loss: 1.1228 - val_accuracy: 0.5242\n",
      "Epoch 41/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6858 - accuracy: 0.5837 - val_loss: 0.6947 - val_accuracy: 0.5117\n",
      "Epoch 42/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6683 - accuracy: 0.5821 - val_loss: 0.6876 - val_accuracy: 0.5224\n",
      "Epoch 43/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6292 - accuracy: 0.6160 - val_loss: 0.8359 - val_accuracy: 0.5458\n",
      "Epoch 44/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6168 - accuracy: 0.6307 - val_loss: 0.8044 - val_accuracy: 0.5171\n",
      "Epoch 45/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6060 - accuracy: 0.6430 - val_loss: 0.8263 - val_accuracy: 0.5260\n",
      "Epoch 46/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6013 - accuracy: 0.6469 - val_loss: 0.7822 - val_accuracy: 0.5673\n",
      "Epoch 47/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.5962 - accuracy: 0.6638 - val_loss: 0.8260 - val_accuracy: 0.5512\n",
      "Epoch 48/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6029 - accuracy: 0.6500 - val_loss: 0.8352 - val_accuracy: 0.5619\n",
      "Epoch 49/50\n",
      "1297/1297 [==============================] - 12s 9ms/step - loss: 0.6063 - accuracy: 0.6500 - val_loss: 0.7191 - val_accuracy: 0.5781\n",
      "Epoch 50/50\n",
      "1297/1297 [==============================] - 12s 10ms/step - loss: 0.5967 - accuracy: 0.6631 - val_loss: 0.7523 - val_accuracy: 0.5619\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_6 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.AveragePooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((6, 6)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 1.2859 - accuracy: 0.4603 - val_loss: 0.7118 - val_accuracy: 0.4057\n",
      "Epoch 2/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7160 - accuracy: 0.4534 - val_loss: 1.0765 - val_accuracy: 0.5907\n",
      "Epoch 3/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 1.0607 - accuracy: 0.5359 - val_loss: 0.8590 - val_accuracy: 0.4093\n",
      "Epoch 4/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.7960 - accuracy: 0.4518 - val_loss: 0.6941 - val_accuracy: 0.4811\n",
      "Epoch 5/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6934 - accuracy: 0.4904 - val_loss: 0.6943 - val_accuracy: 0.4758\n",
      "Epoch 6/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6921 - accuracy: 0.4927 - val_loss: 0.6756 - val_accuracy: 0.5907\n",
      "Epoch 7/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6833 - accuracy: 0.5482 - val_loss: 0.6894 - val_accuracy: 0.5099\n",
      "Epoch 8/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6841 - accuracy: 0.5582 - val_loss: 0.6727 - val_accuracy: 0.5907\n",
      "Epoch 9/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6838 - accuracy: 0.5482 - val_loss: 0.6749 - val_accuracy: 0.5907\n",
      "Epoch 10/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6858 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 11/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6866 - accuracy: 0.5482 - val_loss: 0.6766 - val_accuracy: 0.5907\n",
      "Epoch 12/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6868 - accuracy: 0.5482 - val_loss: 0.6771 - val_accuracy: 0.5907\n",
      "Epoch 13/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6859 - accuracy: 0.5482 - val_loss: 0.6761 - val_accuracy: 0.5907\n",
      "Epoch 14/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6847 - accuracy: 0.5482 - val_loss: 0.6744 - val_accuracy: 0.5907\n",
      "Epoch 15/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6829 - accuracy: 0.5482 - val_loss: 0.6716 - val_accuracy: 0.5907\n",
      "Epoch 16/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6807 - accuracy: 0.5482 - val_loss: 0.6690 - val_accuracy: 0.5907\n",
      "Epoch 17/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6780 - accuracy: 0.5482 - val_loss: 0.6659 - val_accuracy: 0.5907\n",
      "Epoch 18/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6749 - accuracy: 0.5482 - val_loss: 0.6629 - val_accuracy: 0.5907\n",
      "Epoch 19/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6716 - accuracy: 0.5482 - val_loss: 0.6634 - val_accuracy: 0.5907\n",
      "Epoch 20/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6703 - accuracy: 0.5482 - val_loss: 0.6609 - val_accuracy: 0.5889\n",
      "Epoch 21/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6683 - accuracy: 0.5490 - val_loss: 0.6499 - val_accuracy: 0.5907\n",
      "Epoch 22/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6638 - accuracy: 0.5490 - val_loss: 0.6509 - val_accuracy: 0.6140\n",
      "Epoch 23/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6652 - accuracy: 0.5251 - val_loss: 0.6436 - val_accuracy: 0.6086\n",
      "Epoch 24/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6635 - accuracy: 0.5520 - val_loss: 0.6392 - val_accuracy: 0.5943\n",
      "Epoch 25/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6604 - accuracy: 0.5536 - val_loss: 0.6513 - val_accuracy: 0.6014\n",
      "Epoch 26/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.5628 - val_loss: 0.6539 - val_accuracy: 0.5763\n",
      "Epoch 27/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6603 - accuracy: 0.5790 - val_loss: 0.6477 - val_accuracy: 0.5943\n",
      "Epoch 28/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6572 - accuracy: 0.5644 - val_loss: 0.6409 - val_accuracy: 0.5853\n",
      "Epoch 29/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6552 - accuracy: 0.5667 - val_loss: 0.6370 - val_accuracy: 0.6230\n",
      "Epoch 30/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6553 - accuracy: 0.5821 - val_loss: 0.6361 - val_accuracy: 0.5996\n",
      "Epoch 31/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6526 - accuracy: 0.5705 - val_loss: 0.6355 - val_accuracy: 0.6104\n",
      "Epoch 32/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6499 - accuracy: 0.5806 - val_loss: 0.6353 - val_accuracy: 0.6140\n",
      "Epoch 33/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6476 - accuracy: 0.5883 - val_loss: 0.6302 - val_accuracy: 0.6050\n",
      "Epoch 34/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6452 - accuracy: 0.5906 - val_loss: 0.6398 - val_accuracy: 0.6176\n",
      "Epoch 35/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6456 - accuracy: 0.6191 - val_loss: 0.6208 - val_accuracy: 0.6230\n",
      "Epoch 36/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6412 - accuracy: 0.5921 - val_loss: 0.6208 - val_accuracy: 0.6320\n",
      "Epoch 37/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6354 - accuracy: 0.6122 - val_loss: 0.6372 - val_accuracy: 0.5691\n",
      "Epoch 38/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6397 - accuracy: 0.5952 - val_loss: 0.6204 - val_accuracy: 0.6320\n",
      "Epoch 39/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6319 - accuracy: 0.6137 - val_loss: 0.6205 - val_accuracy: 0.6355\n",
      "Epoch 40/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6275 - accuracy: 0.6153 - val_loss: 0.6112 - val_accuracy: 0.6427\n",
      "Epoch 41/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6199 - accuracy: 0.6207 - val_loss: 0.6143 - val_accuracy: 0.6409\n",
      "Epoch 42/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6158 - accuracy: 0.6145 - val_loss: 0.6235 - val_accuracy: 0.5907\n",
      "Epoch 43/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6155 - accuracy: 0.6307 - val_loss: 0.6262 - val_accuracy: 0.6320\n",
      "Epoch 44/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6316 - accuracy: 0.6222 - val_loss: 0.7848 - val_accuracy: 0.4722\n",
      "Epoch 45/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.7072 - accuracy: 0.5420 - val_loss: 0.6337 - val_accuracy: 0.6517\n",
      "Epoch 46/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6332 - accuracy: 0.6130 - val_loss: 0.6596 - val_accuracy: 0.5889\n",
      "Epoch 47/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6627 - accuracy: 0.5490 - val_loss: 0.6579 - val_accuracy: 0.5907\n",
      "Epoch 48/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6575 - accuracy: 0.5482 - val_loss: 0.6586 - val_accuracy: 0.5907\n",
      "Epoch 49/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6558 - accuracy: 0.5482 - val_loss: 0.6560 - val_accuracy: 0.5907\n",
      "Epoch 50/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6533 - accuracy: 0.5482 - val_loss: 0.6495 - val_accuracy: 0.5907\n",
      "Epoch 51/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6485 - accuracy: 0.5482 - val_loss: 0.6437 - val_accuracy: 0.5907\n",
      "Epoch 52/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.6439 - accuracy: 0.5497 - val_loss: 0.6386 - val_accuracy: 0.6014\n",
      "Epoch 53/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6370 - accuracy: 0.5613 - val_loss: 0.6350 - val_accuracy: 0.6463\n",
      "Epoch 54/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6302 - accuracy: 0.6145 - val_loss: 0.6258 - val_accuracy: 0.6697\n",
      "Epoch 55/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6217 - accuracy: 0.6438 - val_loss: 0.6234 - val_accuracy: 0.6840\n",
      "Epoch 56/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6103 - accuracy: 0.6777 - val_loss: 0.6171 - val_accuracy: 0.6750\n",
      "Epoch 57/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5983 - accuracy: 0.6692 - val_loss: 0.6173 - val_accuracy: 0.6373\n",
      "Epoch 58/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5822 - accuracy: 0.6731 - val_loss: 0.6380 - val_accuracy: 0.6014\n",
      "Epoch 59/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5952 - accuracy: 0.6739 - val_loss: 0.7106 - val_accuracy: 0.4955\n",
      "Epoch 60/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6650 - accuracy: 0.5906 - val_loss: 0.6576 - val_accuracy: 0.6553\n",
      "Epoch 61/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6596 - accuracy: 0.6507 - val_loss: 0.6570 - val_accuracy: 0.6445\n",
      "Epoch 62/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.6430 - accuracy: 0.6315 - val_loss: 0.6276 - val_accuracy: 0.6194\n",
      "Epoch 63/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6075 - accuracy: 0.6369 - val_loss: 0.6378 - val_accuracy: 0.6068\n",
      "Epoch 64/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6107 - accuracy: 0.6261 - val_loss: 0.6196 - val_accuracy: 0.6499\n",
      "Epoch 65/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6041 - accuracy: 0.6554 - val_loss: 0.6248 - val_accuracy: 0.6535\n",
      "Epoch 66/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6072 - accuracy: 0.6500 - val_loss: 0.6215 - val_accuracy: 0.6176\n",
      "Epoch 67/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5951 - accuracy: 0.6677 - val_loss: 0.6263 - val_accuracy: 0.6176\n",
      "Epoch 68/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5890 - accuracy: 0.6677 - val_loss: 0.5969 - val_accuracy: 0.6697\n",
      "Epoch 69/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5739 - accuracy: 0.6746 - val_loss: 0.6498 - val_accuracy: 0.5871\n",
      "Epoch 70/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5736 - accuracy: 0.6847 - val_loss: 0.6041 - val_accuracy: 0.6804\n",
      "Epoch 71/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5836 - accuracy: 0.6608 - val_loss: 0.5980 - val_accuracy: 0.6894\n",
      "Epoch 72/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5632 - accuracy: 0.6901 - val_loss: 0.6024 - val_accuracy: 0.6517\n",
      "Epoch 73/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5423 - accuracy: 0.7101 - val_loss: 0.6210 - val_accuracy: 0.6553\n",
      "Epoch 74/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5698 - accuracy: 0.6715 - val_loss: 0.5848 - val_accuracy: 0.6804\n",
      "Epoch 75/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.5447 - accuracy: 0.6893 - val_loss: 0.6066 - val_accuracy: 0.6715\n",
      "Epoch 76/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5553 - accuracy: 0.6862 - val_loss: 0.6095 - val_accuracy: 0.6732\n",
      "Epoch 77/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5486 - accuracy: 0.6931 - val_loss: 0.6334 - val_accuracy: 0.6750\n",
      "Epoch 78/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5488 - accuracy: 0.6870 - val_loss: 0.6385 - val_accuracy: 0.6427\n",
      "Epoch 79/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.5333 - accuracy: 0.6870 - val_loss: 0.6291 - val_accuracy: 0.6697\n",
      "Epoch 80/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5164 - accuracy: 0.7093 - val_loss: 0.6236 - val_accuracy: 0.6553\n",
      "Epoch 81/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5032 - accuracy: 0.7155 - val_loss: 0.6364 - val_accuracy: 0.6445\n",
      "Epoch 82/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4938 - accuracy: 0.7247 - val_loss: 0.6467 - val_accuracy: 0.6463\n",
      "Epoch 83/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4965 - accuracy: 0.7294 - val_loss: 0.6474 - val_accuracy: 0.6050\n",
      "Epoch 84/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4819 - accuracy: 0.7294 - val_loss: 0.6352 - val_accuracy: 0.6589\n",
      "Epoch 85/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4732 - accuracy: 0.7386 - val_loss: 0.6344 - val_accuracy: 0.6786\n",
      "Epoch 86/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4626 - accuracy: 0.7448 - val_loss: 0.6572 - val_accuracy: 0.6661\n",
      "Epoch 87/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4486 - accuracy: 0.7625 - val_loss: 0.6715 - val_accuracy: 0.6643\n",
      "Epoch 88/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4360 - accuracy: 0.7641 - val_loss: 0.7322 - val_accuracy: 0.6571\n",
      "Epoch 89/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4441 - accuracy: 0.7679 - val_loss: 0.6906 - val_accuracy: 0.6535\n",
      "Epoch 90/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4262 - accuracy: 0.7918 - val_loss: 0.6937 - val_accuracy: 0.6284\n",
      "Epoch 91/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4567 - accuracy: 0.7641 - val_loss: 0.6842 - val_accuracy: 0.6571\n",
      "Epoch 92/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4473 - accuracy: 0.7502 - val_loss: 0.6850 - val_accuracy: 0.6248\n",
      "Epoch 93/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4393 - accuracy: 0.7564 - val_loss: 0.6552 - val_accuracy: 0.6625\n",
      "Epoch 94/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4129 - accuracy: 0.7918 - val_loss: 0.6953 - val_accuracy: 0.6481\n",
      "Epoch 95/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.4211 - accuracy: 0.7795 - val_loss: 0.6442 - val_accuracy: 0.6517\n",
      "Epoch 96/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4090 - accuracy: 0.7926 - val_loss: 0.7113 - val_accuracy: 0.6230\n",
      "Epoch 97/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4137 - accuracy: 0.7857 - val_loss: 0.8536 - val_accuracy: 0.6230\n",
      "Epoch 98/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3917 - accuracy: 0.7826 - val_loss: 0.6926 - val_accuracy: 0.6535\n",
      "Epoch 99/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4027 - accuracy: 0.8011 - val_loss: 0.7286 - val_accuracy: 0.6553\n",
      "Epoch 100/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3983 - accuracy: 0.8026 - val_loss: 0.7429 - val_accuracy: 0.6230\n",
      "Epoch 101/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.3960 - accuracy: 0.8134 - val_loss: 0.7510 - val_accuracy: 0.6122\n",
      "Epoch 102/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4043 - accuracy: 0.7911 - val_loss: 0.7057 - val_accuracy: 0.6643\n",
      "Epoch 103/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3677 - accuracy: 0.8126 - val_loss: 0.7889 - val_accuracy: 0.6355\n",
      "Epoch 104/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3734 - accuracy: 0.8196 - val_loss: 0.7482 - val_accuracy: 0.6427\n",
      "Epoch 105/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3632 - accuracy: 0.8227 - val_loss: 0.7024 - val_accuracy: 0.6661\n",
      "Epoch 106/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3462 - accuracy: 0.8443 - val_loss: 0.7406 - val_accuracy: 0.6661\n",
      "Epoch 107/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3321 - accuracy: 0.8396 - val_loss: 0.7909 - val_accuracy: 0.6607\n",
      "Epoch 108/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3103 - accuracy: 0.8527 - val_loss: 0.8074 - val_accuracy: 0.6571\n",
      "Epoch 109/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3073 - accuracy: 0.8589 - val_loss: 0.8451 - val_accuracy: 0.6535\n",
      "Epoch 110/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3063 - accuracy: 0.8581 - val_loss: 0.9177 - val_accuracy: 0.6589\n",
      "Epoch 111/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2832 - accuracy: 0.8720 - val_loss: 1.1454 - val_accuracy: 0.6427\n",
      "Epoch 112/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5090 - accuracy: 0.7926 - val_loss: 1.1000 - val_accuracy: 0.6409\n",
      "Epoch 113/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.6093 - accuracy: 0.7556 - val_loss: 0.7613 - val_accuracy: 0.6463\n",
      "Epoch 114/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4474 - accuracy: 0.7764 - val_loss: 0.7598 - val_accuracy: 0.6302\n",
      "Epoch 115/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.4723 - accuracy: 0.7672 - val_loss: 0.7355 - val_accuracy: 0.5763\n",
      "Epoch 116/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.5355 - accuracy: 0.7224 - val_loss: 0.7415 - val_accuracy: 0.6050\n",
      "Epoch 117/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4771 - accuracy: 0.7672 - val_loss: 0.7024 - val_accuracy: 0.6194\n",
      "Epoch 118/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.4131 - accuracy: 0.8150 - val_loss: 0.6951 - val_accuracy: 0.6409\n",
      "Epoch 119/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3914 - accuracy: 0.8165 - val_loss: 0.6674 - val_accuracy: 0.6320\n",
      "Epoch 120/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3733 - accuracy: 0.8304 - val_loss: 0.6813 - val_accuracy: 0.6373\n",
      "Epoch 121/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3541 - accuracy: 0.8489 - val_loss: 0.7130 - val_accuracy: 0.6463\n",
      "Epoch 122/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.3334 - accuracy: 0.8358 - val_loss: 0.7456 - val_accuracy: 0.6517\n",
      "Epoch 123/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.3003 - accuracy: 0.8674 - val_loss: 0.8520 - val_accuracy: 0.6607\n",
      "Epoch 124/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2935 - accuracy: 0.8736 - val_loss: 0.9049 - val_accuracy: 0.6409\n",
      "Epoch 125/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2728 - accuracy: 0.8813 - val_loss: 0.9159 - val_accuracy: 0.6409\n",
      "Epoch 126/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2628 - accuracy: 0.8805 - val_loss: 0.9145 - val_accuracy: 0.6373\n",
      "Epoch 127/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2610 - accuracy: 0.8890 - val_loss: 0.8690 - val_accuracy: 0.6571\n",
      "Epoch 128/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2620 - accuracy: 0.8843 - val_loss: 0.8782 - val_accuracy: 0.6571\n",
      "Epoch 129/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2462 - accuracy: 0.8913 - val_loss: 0.9131 - val_accuracy: 0.6571\n",
      "Epoch 130/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2302 - accuracy: 0.9052 - val_loss: 0.9133 - val_accuracy: 0.6643\n",
      "Epoch 131/200\n",
      "1297/1297 [==============================] - 23s 18ms/step - loss: 0.2284 - accuracy: 0.8998 - val_loss: 0.9936 - val_accuracy: 0.6625\n",
      "Epoch 132/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2246 - accuracy: 0.9082 - val_loss: 1.0289 - val_accuracy: 0.6553\n",
      "Epoch 133/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2070 - accuracy: 0.9129 - val_loss: 1.0721 - val_accuracy: 0.6553\n",
      "Epoch 134/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.2064 - accuracy: 0.9152 - val_loss: 1.0562 - val_accuracy: 0.6732\n",
      "Epoch 135/200\n",
      "1297/1297 [==============================] - 23s 17ms/step - loss: 0.1948 - accuracy: 0.9229 - val_loss: 0.9783 - val_accuracy: 0.6607\n",
      "Epoch 136/200\n",
      "1297/1297 [==============================] - 22s 17ms/step - loss: 0.2023 - accuracy: 0.9183 - val_loss: 0.9592 - val_accuracy: 0.6535\n",
      "Epoch 137/200\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_7 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=200,\n",
    "                    batch_size=1000,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1297 samples, validate on 557 samples\n",
      "Epoch 1/500\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 0.0542 - acc: 0.9800 - val_loss: 4.8865 - val_acc: 0.5673\n",
      "Epoch 2/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0526 - acc: 0.9830 - val_loss: 3.8052 - val_acc: 0.6122\n",
      "Epoch 3/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0112 - acc: 0.9931 - val_loss: 4.2008 - val_acc: 0.5978\n",
      "Epoch 4/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9946 - val_loss: 4.0361 - val_acc: 0.6302\n",
      "Epoch 5/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0066 - acc: 0.9977 - val_loss: 4.1366 - val_acc: 0.6230\n",
      "Epoch 6/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0841 - acc: 0.9738 - val_loss: 4.3061 - val_acc: 0.5763\n",
      "Epoch 7/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1218 - acc: 0.9653 - val_loss: 3.3528 - val_acc: 0.6104\n",
      "Epoch 8/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0365 - acc: 0.9884 - val_loss: 3.3635 - val_acc: 0.6032\n",
      "Epoch 9/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0114 - acc: 0.9954 - val_loss: 3.3668 - val_acc: 0.6122\n",
      "Epoch 10/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 3.4501 - val_acc: 0.6140\n",
      "Epoch 11/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0100 - acc: 0.9946 - val_loss: 3.5490 - val_acc: 0.6122\n",
      "Epoch 12/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0294 - acc: 0.9861 - val_loss: 3.3413 - val_acc: 0.6140\n",
      "Epoch 13/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0271 - acc: 0.9830 - val_loss: 3.4524 - val_acc: 0.5925\n",
      "Epoch 14/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0129 - acc: 0.9931 - val_loss: 3.6805 - val_acc: 0.6014\n",
      "Epoch 15/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0100 - acc: 0.9954 - val_loss: 3.5620 - val_acc: 0.6050\n",
      "Epoch 16/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 3.5593 - val_acc: 0.6104\n",
      "Epoch 17/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 3.7795 - val_acc: 0.6194\n",
      "Epoch 18/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 3.8217 - val_acc: 0.6086\n",
      "Epoch 19/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.2594 - acc: 0.9044 - val_loss: 1.3718 - val_acc: 0.5440\n",
      "Epoch 20/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.1091 - acc: 0.9491 - val_loss: 2.5084 - val_acc: 0.5925\n",
      "Epoch 21/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 3.1336 - val_acc: 0.5961\n",
      "Epoch 22/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0090 - acc: 0.9961 - val_loss: 3.3260 - val_acc: 0.5996\n",
      "Epoch 23/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0109 - acc: 0.9954 - val_loss: 3.4304 - val_acc: 0.5978\n",
      "Epoch 24/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0098 - acc: 0.9961 - val_loss: 3.6061 - val_acc: 0.6050\n",
      "Epoch 25/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 3.6194 - val_acc: 0.6014\n",
      "Epoch 26/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0952 - acc: 0.9692 - val_loss: 2.7855 - val_acc: 0.6050\n",
      "Epoch 27/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0720 - acc: 0.9776 - val_loss: 2.5212 - val_acc: 0.6230\n",
      "Epoch 28/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9907 - val_loss: 2.8383 - val_acc: 0.6176\n",
      "Epoch 29/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 3.0252 - val_acc: 0.6158\n",
      "Epoch 30/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0039 - acc: 0.9992 - val_loss: 3.1664 - val_acc: 0.6068\n",
      "Epoch 31/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 3.2672 - val_acc: 0.6032\n",
      "Epoch 32/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 3.3670 - val_acc: 0.6050\n",
      "Epoch 33/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 3.4478 - val_acc: 0.6032\n",
      "Epoch 34/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0468 - acc: 0.9900 - val_loss: 3.4187 - val_acc: 0.5961\n",
      "Epoch 35/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3658 - acc: 0.9067 - val_loss: 2.0230 - val_acc: 0.5925\n",
      "Epoch 36/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0486 - acc: 0.9823 - val_loss: 2.8499 - val_acc: 0.5799\n",
      "Epoch 37/500\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 3.0220 - val_acc: 0.6122\n",
      "Epoch 38/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0088 - acc: 0.9969 - val_loss: 3.1904 - val_acc: 0.5925\n",
      "Epoch 39/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.3246 - acc: 0.8975 - val_loss: 2.0007 - val_acc: 0.5943\n",
      "Epoch 40/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0669 - acc: 0.9815 - val_loss: 2.5389 - val_acc: 0.5817\n",
      "Epoch 41/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9846 - val_loss: 2.4448 - val_acc: 0.6086\n",
      "Epoch 42/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0288 - acc: 0.9892 - val_loss: 2.6544 - val_acc: 0.5925\n",
      "Epoch 43/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0257 - acc: 0.9900 - val_loss: 2.8005 - val_acc: 0.5978\n",
      "Epoch 44/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0178 - acc: 0.9884 - val_loss: 2.9891 - val_acc: 0.5943\n",
      "Epoch 45/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9931 - val_loss: 3.1611 - val_acc: 0.5925\n",
      "Epoch 46/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 3.2269 - val_acc: 0.5996\n",
      "Epoch 47/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 3.2916 - val_acc: 0.5996\n",
      "Epoch 48/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0102 - acc: 0.9938 - val_loss: 3.1307 - val_acc: 0.5907\n",
      "Epoch 49/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0987 - acc: 0.9522 - val_loss: 2.6610 - val_acc: 0.5601\n",
      "Epoch 50/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9815 - val_loss: 2.7463 - val_acc: 0.5907\n",
      "Epoch 51/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9907 - val_loss: 3.0980 - val_acc: 0.5943\n",
      "Epoch 52/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 0.9946 - val_loss: 3.2145 - val_acc: 0.6068\n",
      "Epoch 53/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0576 - acc: 0.9738 - val_loss: 3.0086 - val_acc: 0.5548\n",
      "Epoch 54/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0582 - acc: 0.9738 - val_loss: 3.0022 - val_acc: 0.6068\n",
      "Epoch 55/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 3.0723 - val_acc: 0.6140\n",
      "Epoch 56/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0122 - acc: 0.9977 - val_loss: 3.0839 - val_acc: 0.6104\n",
      "Epoch 57/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0101 - acc: 0.9961 - val_loss: 3.2881 - val_acc: 0.6212\n",
      "Epoch 58/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0450 - acc: 0.9807 - val_loss: 2.6459 - val_acc: 0.5727\n",
      "Epoch 59/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0814 - acc: 0.9630 - val_loss: 2.8003 - val_acc: 0.6068\n",
      "Epoch 60/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0084 - acc: 0.9961 - val_loss: 3.0562 - val_acc: 0.6068\n",
      "Epoch 61/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0150 - acc: 0.9900 - val_loss: 3.0624 - val_acc: 0.6104\n",
      "Epoch 62/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0166 - acc: 0.9884 - val_loss: 3.3788 - val_acc: 0.6104\n",
      "Epoch 63/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 3.3620 - val_acc: 0.6284\n",
      "Epoch 64/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0077 - acc: 0.9961 - val_loss: 3.4234 - val_acc: 0.6302\n",
      "Epoch 65/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0209 - acc: 0.9938 - val_loss: 3.2064 - val_acc: 0.5907\n",
      "Epoch 66/500\n",
      "1297/1297 [==============================] - 2s 2ms/step - loss: 0.0218 - acc: 0.9869 - val_loss: 3.2074 - val_acc: 0.6086\n",
      "Epoch 67/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0869 - acc: 0.9668 - val_loss: 2.8276 - val_acc: 0.5619\n",
      "Epoch 68/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0555 - acc: 0.9807 - val_loss: 2.6582 - val_acc: 0.5853\n",
      "Epoch 69/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0174 - acc: 0.9900 - val_loss: 2.9639 - val_acc: 0.6104\n",
      "Epoch 70/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0115 - acc: 0.9931 - val_loss: 2.8999 - val_acc: 0.6194\n",
      "Epoch 71/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0052 - acc: 0.9992 - val_loss: 2.9881 - val_acc: 0.6176\n",
      "Epoch 72/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0628 - acc: 0.9707 - val_loss: 2.9394 - val_acc: 0.5619\n",
      "Epoch 73/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0514 - acc: 0.9800 - val_loss: 3.0135 - val_acc: 0.5889\n",
      "Epoch 74/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0300 - acc: 0.9854 - val_loss: 2.9444 - val_acc: 0.6212\n",
      "Epoch 75/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 3.1245 - val_acc: 0.6266\n",
      "Epoch 76/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0108 - acc: 0.9954 - val_loss: 3.2596 - val_acc: 0.6122\n",
      "Epoch 77/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9638 - val_loss: 2.8438 - val_acc: 0.5889\n",
      "Epoch 78/500\n",
      "1297/1297 [==============================] - 3s 2ms/step - loss: 0.0296 - acc: 0.9869 - val_loss: 3.0837 - val_acc: 0.5853\n",
      "Epoch 79/500\n",
      "1024/1297 [======================>.......] - ETA: 0s - loss: 0.1132 - acc: 0.9443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-dc19821f9d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_8 = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=500,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model1.add(layers.MaxPooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "\n",
    "model1.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model1.add(layers.Dense(20, activation='relu'))\n",
    "model1.add(layers.Dense(100, activation='relu'))\n",
    "model1.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "# model.add(layers.Dense(200, activation='relu'))\n",
    "model1.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 1287 samples, validate on 552 samples\n",
      "Epoch 1/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.8998 - acc: 0.5237 - val_loss: 0.7195 - val_acc: 0.5996\n",
      "Epoch 2/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.7514 - acc: 0.5346 - val_loss: 0.7020 - val_acc: 0.5725\n",
      "Epoch 3/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.7234 - acc: 0.5509 - val_loss: 0.6960 - val_acc: 0.5652\n",
      "Epoch 4/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6999 - acc: 0.5470 - val_loss: 0.6923 - val_acc: 0.5888\n",
      "Epoch 5/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6910 - acc: 0.5548 - val_loss: 0.6902 - val_acc: 0.5634\n",
      "Epoch 6/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6849 - acc: 0.5641 - val_loss: 0.6871 - val_acc: 0.5652\n",
      "Epoch 7/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6770 - acc: 0.5750 - val_loss: 0.6993 - val_acc: 0.5580\n",
      "Epoch 8/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6743 - acc: 0.5851 - val_loss: 0.6924 - val_acc: 0.5543\n",
      "Epoch 9/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6680 - acc: 0.5828 - val_loss: 0.7028 - val_acc: 0.5362\n",
      "Epoch 10/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6641 - acc: 0.5913 - val_loss: 0.6760 - val_acc: 0.5562\n",
      "Epoch 11/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6662 - acc: 0.5851 - val_loss: 0.6756 - val_acc: 0.5743\n",
      "Epoch 12/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6573 - acc: 0.5952 - val_loss: 0.6808 - val_acc: 0.5598\n",
      "Epoch 13/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6568 - acc: 0.5967 - val_loss: 0.6776 - val_acc: 0.5598\n",
      "Epoch 14/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6537 - acc: 0.6037 - val_loss: 0.6999 - val_acc: 0.5399\n",
      "Epoch 15/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.6490 - acc: 0.6006 - val_loss: 0.6677 - val_acc: 0.5779\n",
      "Epoch 16/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.6503 - acc: 0.6099 - val_loss: 0.6649 - val_acc: 0.5779\n",
      "Epoch 17/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6469 - acc: 0.6154 - val_loss: 0.6647 - val_acc: 0.5743\n",
      "Epoch 18/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6486 - acc: 0.6061 - val_loss: 0.6622 - val_acc: 0.5833\n",
      "Epoch 19/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6421 - acc: 0.6092 - val_loss: 0.6672 - val_acc: 0.5870\n",
      "Epoch 20/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6405 - acc: 0.6068 - val_loss: 0.6643 - val_acc: 0.5797\n",
      "Epoch 21/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6381 - acc: 0.6239 - val_loss: 0.6675 - val_acc: 0.5906\n",
      "Epoch 22/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6403 - acc: 0.6146 - val_loss: 0.6631 - val_acc: 0.5707\n",
      "Epoch 23/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6384 - acc: 0.6216 - val_loss: 0.6615 - val_acc: 0.5707\n",
      "Epoch 24/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6337 - acc: 0.6255 - val_loss: 0.6630 - val_acc: 0.5996\n",
      "Epoch 25/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6315 - acc: 0.6247 - val_loss: 0.6621 - val_acc: 0.5924\n",
      "Epoch 26/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6312 - acc: 0.6364 - val_loss: 0.6603 - val_acc: 0.5815\n",
      "Epoch 27/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6295 - acc: 0.6224 - val_loss: 0.6662 - val_acc: 0.5906\n",
      "Epoch 28/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6303 - acc: 0.6232 - val_loss: 0.6597 - val_acc: 0.5870\n",
      "Epoch 29/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6257 - acc: 0.6333 - val_loss: 0.6690 - val_acc: 0.5779\n",
      "Epoch 30/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6275 - acc: 0.6364 - val_loss: 0.6616 - val_acc: 0.5924\n",
      "Epoch 31/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6245 - acc: 0.6270 - val_loss: 0.6594 - val_acc: 0.5815\n",
      "Epoch 32/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6256 - acc: 0.6317 - val_loss: 0.6625 - val_acc: 0.5978\n",
      "Epoch 33/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6228 - acc: 0.6426 - val_loss: 0.6584 - val_acc: 0.5942\n",
      "Epoch 34/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6208 - acc: 0.6348 - val_loss: 0.6797 - val_acc: 0.5580\n",
      "Epoch 35/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6197 - acc: 0.6387 - val_loss: 0.6585 - val_acc: 0.6014\n",
      "Epoch 36/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6167 - acc: 0.6418 - val_loss: 0.6576 - val_acc: 0.5960\n",
      "Epoch 37/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6225 - acc: 0.6371 - val_loss: 0.6562 - val_acc: 0.5960\n",
      "Epoch 38/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6162 - acc: 0.6434 - val_loss: 0.6591 - val_acc: 0.5906\n",
      "Epoch 39/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6120 - acc: 0.6402 - val_loss: 0.6580 - val_acc: 0.5870\n",
      "Epoch 40/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6199 - acc: 0.6418 - val_loss: 0.6617 - val_acc: 0.6014\n",
      "Epoch 41/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6113 - acc: 0.6480 - val_loss: 0.6568 - val_acc: 0.6014\n",
      "Epoch 42/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6097 - acc: 0.6519 - val_loss: 0.6576 - val_acc: 0.6051\n",
      "Epoch 43/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6117 - acc: 0.6371 - val_loss: 0.6563 - val_acc: 0.5960\n",
      "Epoch 44/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6092 - acc: 0.6511 - val_loss: 0.6599 - val_acc: 0.6069\n",
      "Epoch 45/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6096 - acc: 0.6465 - val_loss: 0.6572 - val_acc: 0.5996\n",
      "Epoch 46/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6087 - acc: 0.6434 - val_loss: 0.6624 - val_acc: 0.6014\n",
      "Epoch 47/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6056 - acc: 0.6503 - val_loss: 0.6562 - val_acc: 0.6087\n",
      "Epoch 48/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6087 - acc: 0.6395 - val_loss: 0.6542 - val_acc: 0.6087\n",
      "Epoch 49/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6064 - acc: 0.6449 - val_loss: 0.6576 - val_acc: 0.6033\n",
      "Epoch 50/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6015 - acc: 0.6542 - val_loss: 0.6609 - val_acc: 0.5996\n",
      "Epoch 51/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6025 - acc: 0.6589 - val_loss: 0.6565 - val_acc: 0.6051\n",
      "Epoch 52/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6001 - acc: 0.6636 - val_loss: 0.6567 - val_acc: 0.6033\n",
      "Epoch 53/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5988 - acc: 0.6628 - val_loss: 0.6564 - val_acc: 0.6141\n",
      "Epoch 54/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5979 - acc: 0.6667 - val_loss: 0.6544 - val_acc: 0.6087\n",
      "Epoch 55/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5985 - acc: 0.6566 - val_loss: 0.6542 - val_acc: 0.6087\n",
      "Epoch 56/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5997 - acc: 0.6597 - val_loss: 0.6538 - val_acc: 0.6051\n",
      "Epoch 57/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.6011 - acc: 0.6550 - val_loss: 0.6593 - val_acc: 0.5996\n",
      "Epoch 58/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5949 - acc: 0.6713 - val_loss: 0.6550 - val_acc: 0.6033\n",
      "Epoch 59/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5949 - acc: 0.6581 - val_loss: 0.6596 - val_acc: 0.5906\n",
      "Epoch 60/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5944 - acc: 0.6636 - val_loss: 0.6529 - val_acc: 0.6141\n",
      "Epoch 61/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5949 - acc: 0.6597 - val_loss: 0.6523 - val_acc: 0.6123\n",
      "Epoch 62/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5894 - acc: 0.6791 - val_loss: 0.6549 - val_acc: 0.6141\n",
      "Epoch 63/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5927 - acc: 0.6667 - val_loss: 0.6526 - val_acc: 0.6214\n",
      "Epoch 64/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5948 - acc: 0.6550 - val_loss: 0.6522 - val_acc: 0.6141\n",
      "Epoch 65/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5861 - acc: 0.6744 - val_loss: 0.6661 - val_acc: 0.5688\n",
      "Epoch 66/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5872 - acc: 0.6752 - val_loss: 0.6579 - val_acc: 0.5978\n",
      "Epoch 67/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5856 - acc: 0.6791 - val_loss: 0.6545 - val_acc: 0.6159\n",
      "Epoch 68/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5847 - acc: 0.6768 - val_loss: 0.6570 - val_acc: 0.6069\n",
      "Epoch 69/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5844 - acc: 0.6791 - val_loss: 0.6560 - val_acc: 0.6141\n",
      "Epoch 70/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5832 - acc: 0.6760 - val_loss: 0.6506 - val_acc: 0.6159\n",
      "Epoch 71/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5828 - acc: 0.6690 - val_loss: 0.6603 - val_acc: 0.5942\n",
      "Epoch 72/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5877 - acc: 0.6729 - val_loss: 0.6619 - val_acc: 0.5924\n",
      "Epoch 73/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5813 - acc: 0.6775 - val_loss: 0.6546 - val_acc: 0.6087\n",
      "Epoch 74/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5796 - acc: 0.6884 - val_loss: 0.6678 - val_acc: 0.5725\n",
      "Epoch 75/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5785 - acc: 0.6876 - val_loss: 0.6539 - val_acc: 0.6123\n",
      "Epoch 76/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5774 - acc: 0.6807 - val_loss: 0.6562 - val_acc: 0.6014\n",
      "Epoch 77/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5748 - acc: 0.6869 - val_loss: 0.6554 - val_acc: 0.6141\n",
      "Epoch 78/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5742 - acc: 0.6931 - val_loss: 0.6709 - val_acc: 0.5580\n",
      "Epoch 79/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5749 - acc: 0.6876 - val_loss: 0.6545 - val_acc: 0.6123\n",
      "Epoch 80/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5721 - acc: 0.6908 - val_loss: 0.6522 - val_acc: 0.6178\n",
      "Epoch 81/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5736 - acc: 0.6954 - val_loss: 0.6539 - val_acc: 0.6196\n",
      "Epoch 82/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.5705 - acc: 0.6923 - val_loss: 0.6617 - val_acc: 0.5888\n",
      "Epoch 83/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5697 - acc: 0.6892 - val_loss: 0.6537 - val_acc: 0.6178\n",
      "Epoch 84/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5684 - acc: 0.6985 - val_loss: 0.6587 - val_acc: 0.5960\n",
      "Epoch 85/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5693 - acc: 0.6830 - val_loss: 0.6640 - val_acc: 0.5833\n",
      "Epoch 86/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5673 - acc: 0.6853 - val_loss: 0.6669 - val_acc: 0.5815\n",
      "Epoch 87/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5668 - acc: 0.6946 - val_loss: 0.6499 - val_acc: 0.6196\n",
      "Epoch 88/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5700 - acc: 0.6923 - val_loss: 0.6504 - val_acc: 0.6232\n",
      "Epoch 89/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5707 - acc: 0.6869 - val_loss: 0.6523 - val_acc: 0.6178\n",
      "Epoch 90/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5624 - acc: 0.6939 - val_loss: 0.6549 - val_acc: 0.6105\n",
      "Epoch 91/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5620 - acc: 0.6970 - val_loss: 0.6593 - val_acc: 0.5996\n",
      "Epoch 92/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5609 - acc: 0.6923 - val_loss: 0.6529 - val_acc: 0.6196\n",
      "Epoch 93/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5615 - acc: 0.6931 - val_loss: 0.6544 - val_acc: 0.6105\n",
      "Epoch 94/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5560 - acc: 0.7024 - val_loss: 0.6552 - val_acc: 0.6250\n",
      "Epoch 95/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5565 - acc: 0.6993 - val_loss: 0.6528 - val_acc: 0.6196\n",
      "Epoch 96/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5559 - acc: 0.6993 - val_loss: 0.6526 - val_acc: 0.6395\n",
      "Epoch 97/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5554 - acc: 0.6993 - val_loss: 0.6594 - val_acc: 0.5996\n",
      "Epoch 98/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5536 - acc: 0.7071 - val_loss: 0.6548 - val_acc: 0.6159\n",
      "Epoch 99/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5542 - acc: 0.7078 - val_loss: 0.6603 - val_acc: 0.5960\n",
      "Epoch 100/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5515 - acc: 0.7078 - val_loss: 0.6543 - val_acc: 0.6123\n",
      "Epoch 101/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5542 - acc: 0.6962 - val_loss: 0.6579 - val_acc: 0.6087\n",
      "Epoch 102/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5483 - acc: 0.7211 - val_loss: 0.6592 - val_acc: 0.5942\n",
      "Epoch 103/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5516 - acc: 0.6970 - val_loss: 0.6691 - val_acc: 0.5833\n",
      "Epoch 104/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5472 - acc: 0.7148 - val_loss: 0.6544 - val_acc: 0.6159\n",
      "Epoch 105/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5487 - acc: 0.7071 - val_loss: 0.6577 - val_acc: 0.6033\n",
      "Epoch 106/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5465 - acc: 0.7078 - val_loss: 0.6583 - val_acc: 0.6069\n",
      "Epoch 107/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5447 - acc: 0.7063 - val_loss: 0.6584 - val_acc: 0.6087\n",
      "Epoch 108/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5423 - acc: 0.7172 - val_loss: 0.6574 - val_acc: 0.6141\n",
      "Epoch 109/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5492 - acc: 0.7032 - val_loss: 0.6654 - val_acc: 0.5833\n",
      "Epoch 110/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5399 - acc: 0.7125 - val_loss: 0.6585 - val_acc: 0.6123\n",
      "Epoch 111/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5409 - acc: 0.7133 - val_loss: 0.6597 - val_acc: 0.6087\n",
      "Epoch 112/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5373 - acc: 0.7187 - val_loss: 0.6662 - val_acc: 0.5797\n",
      "Epoch 113/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5375 - acc: 0.7211 - val_loss: 0.6646 - val_acc: 0.5851\n",
      "Epoch 114/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5424 - acc: 0.7055 - val_loss: 0.6608 - val_acc: 0.6322\n",
      "Epoch 115/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5400 - acc: 0.6977 - val_loss: 0.6691 - val_acc: 0.5725\n",
      "Epoch 116/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5358 - acc: 0.7164 - val_loss: 0.6580 - val_acc: 0.6250\n",
      "Epoch 117/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5344 - acc: 0.7164 - val_loss: 0.6598 - val_acc: 0.6286\n",
      "Epoch 118/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5360 - acc: 0.7187 - val_loss: 0.6700 - val_acc: 0.5851\n",
      "Epoch 119/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5296 - acc: 0.7304 - val_loss: 0.6654 - val_acc: 0.6123\n",
      "Epoch 120/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5293 - acc: 0.7288 - val_loss: 0.6651 - val_acc: 0.6341\n",
      "Epoch 121/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5287 - acc: 0.7257 - val_loss: 0.6644 - val_acc: 0.6069\n",
      "Epoch 122/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5341 - acc: 0.7156 - val_loss: 0.6740 - val_acc: 0.5761\n",
      "Epoch 123/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5259 - acc: 0.7257 - val_loss: 0.6797 - val_acc: 0.5743\n",
      "Epoch 124/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5244 - acc: 0.7296 - val_loss: 0.6663 - val_acc: 0.6069\n",
      "Epoch 125/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5244 - acc: 0.7350 - val_loss: 0.6855 - val_acc: 0.5725\n",
      "Epoch 126/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5211 - acc: 0.7405 - val_loss: 0.6716 - val_acc: 0.5924\n",
      "Epoch 127/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5222 - acc: 0.7296 - val_loss: 0.6675 - val_acc: 0.6105\n",
      "Epoch 128/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5213 - acc: 0.7335 - val_loss: 0.6674 - val_acc: 0.6178\n",
      "Epoch 129/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5182 - acc: 0.7420 - val_loss: 0.6796 - val_acc: 0.5815\n",
      "Epoch 130/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5192 - acc: 0.7374 - val_loss: 0.6713 - val_acc: 0.5960\n",
      "Epoch 131/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5193 - acc: 0.7366 - val_loss: 0.6706 - val_acc: 0.5996\n",
      "Epoch 132/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5155 - acc: 0.7389 - val_loss: 0.6786 - val_acc: 0.5851\n",
      "Epoch 133/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5163 - acc: 0.7436 - val_loss: 0.6694 - val_acc: 0.6014\n",
      "Epoch 134/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5129 - acc: 0.7420 - val_loss: 0.6745 - val_acc: 0.5906\n",
      "Epoch 135/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5112 - acc: 0.7498 - val_loss: 0.6689 - val_acc: 0.6051\n",
      "Epoch 136/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5142 - acc: 0.7249 - val_loss: 0.6665 - val_acc: 0.6250\n",
      "Epoch 137/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5104 - acc: 0.7436 - val_loss: 0.6707 - val_acc: 0.5996\n",
      "Epoch 138/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5096 - acc: 0.7514 - val_loss: 0.6757 - val_acc: 0.5833\n",
      "Epoch 139/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5163 - acc: 0.7350 - val_loss: 0.6684 - val_acc: 0.6359\n",
      "Epoch 140/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5073 - acc: 0.7568 - val_loss: 0.6682 - val_acc: 0.6141\n",
      "Epoch 141/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5090 - acc: 0.7382 - val_loss: 0.6700 - val_acc: 0.6322\n",
      "Epoch 142/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5018 - acc: 0.7599 - val_loss: 0.6763 - val_acc: 0.6033\n",
      "Epoch 143/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5019 - acc: 0.7529 - val_loss: 0.6729 - val_acc: 0.5978\n",
      "Epoch 144/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.5010 - acc: 0.7599 - val_loss: 0.6761 - val_acc: 0.6105\n",
      "Epoch 145/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4982 - acc: 0.7584 - val_loss: 0.6805 - val_acc: 0.5779\n",
      "Epoch 146/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4982 - acc: 0.7607 - val_loss: 0.6810 - val_acc: 0.5870\n",
      "Epoch 147/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4959 - acc: 0.7591 - val_loss: 0.6755 - val_acc: 0.6014\n",
      "Epoch 148/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.4939 - acc: 0.7630 - val_loss: 0.6730 - val_acc: 0.6214\n",
      "Epoch 149/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.4975 - acc: 0.7490 - val_loss: 0.6833 - val_acc: 0.5815\n",
      "Epoch 150/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4958 - acc: 0.7529 - val_loss: 0.6764 - val_acc: 0.6123\n",
      "Epoch 151/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4914 - acc: 0.7638 - val_loss: 0.6806 - val_acc: 0.6232\n",
      "Epoch 152/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4906 - acc: 0.7622 - val_loss: 0.6796 - val_acc: 0.6105\n",
      "Epoch 153/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4868 - acc: 0.7677 - val_loss: 0.6856 - val_acc: 0.6069\n",
      "Epoch 154/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4889 - acc: 0.7669 - val_loss: 0.6822 - val_acc: 0.6268\n",
      "Epoch 155/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4921 - acc: 0.7646 - val_loss: 0.6865 - val_acc: 0.6395\n",
      "Epoch 156/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4971 - acc: 0.7490 - val_loss: 0.6759 - val_acc: 0.6087\n",
      "Epoch 157/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4849 - acc: 0.7638 - val_loss: 0.6804 - val_acc: 0.5960\n",
      "Epoch 158/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4828 - acc: 0.7692 - val_loss: 0.6808 - val_acc: 0.5960\n",
      "Epoch 159/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4815 - acc: 0.7723 - val_loss: 0.6870 - val_acc: 0.5942\n",
      "Epoch 160/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4803 - acc: 0.7669 - val_loss: 0.6887 - val_acc: 0.6413\n",
      "Epoch 161/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4827 - acc: 0.7646 - val_loss: 0.6924 - val_acc: 0.5870\n",
      "Epoch 162/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4792 - acc: 0.7677 - val_loss: 0.6910 - val_acc: 0.5888\n",
      "Epoch 163/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4762 - acc: 0.7716 - val_loss: 0.6801 - val_acc: 0.6069\n",
      "Epoch 164/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4788 - acc: 0.7692 - val_loss: 0.6928 - val_acc: 0.6304\n",
      "Epoch 165/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4742 - acc: 0.7669 - val_loss: 0.6903 - val_acc: 0.5924\n",
      "Epoch 166/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4739 - acc: 0.7677 - val_loss: 0.7002 - val_acc: 0.5960\n",
      "Epoch 167/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4709 - acc: 0.7778 - val_loss: 0.6865 - val_acc: 0.5942\n",
      "Epoch 168/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4690 - acc: 0.7863 - val_loss: 0.6957 - val_acc: 0.6413\n",
      "Epoch 169/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4704 - acc: 0.7661 - val_loss: 0.6910 - val_acc: 0.6069\n",
      "Epoch 170/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4669 - acc: 0.7824 - val_loss: 0.6918 - val_acc: 0.6214\n",
      "Epoch 171/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4691 - acc: 0.7793 - val_loss: 0.6890 - val_acc: 0.6141\n",
      "Epoch 172/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4668 - acc: 0.7754 - val_loss: 0.6950 - val_acc: 0.6250\n",
      "Epoch 173/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4707 - acc: 0.7739 - val_loss: 0.7004 - val_acc: 0.5870\n",
      "Epoch 174/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4640 - acc: 0.7770 - val_loss: 0.6900 - val_acc: 0.6214\n",
      "Epoch 175/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4624 - acc: 0.7793 - val_loss: 0.6972 - val_acc: 0.6051\n",
      "Epoch 176/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4598 - acc: 0.7910 - val_loss: 0.7008 - val_acc: 0.5942\n",
      "Epoch 177/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4589 - acc: 0.7817 - val_loss: 0.6968 - val_acc: 0.5924\n",
      "Epoch 178/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4604 - acc: 0.7824 - val_loss: 0.7025 - val_acc: 0.5851\n",
      "Epoch 179/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4586 - acc: 0.7817 - val_loss: 0.7042 - val_acc: 0.5978\n",
      "Epoch 180/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4548 - acc: 0.7918 - val_loss: 0.7029 - val_acc: 0.5960\n",
      "Epoch 181/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4585 - acc: 0.7855 - val_loss: 0.7109 - val_acc: 0.5833\n",
      "Epoch 182/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4586 - acc: 0.7832 - val_loss: 0.6944 - val_acc: 0.6431\n",
      "Epoch 183/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4567 - acc: 0.7786 - val_loss: 0.6989 - val_acc: 0.5978\n",
      "Epoch 184/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4526 - acc: 0.7809 - val_loss: 0.7009 - val_acc: 0.5888\n",
      "Epoch 185/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4546 - acc: 0.7824 - val_loss: 0.7079 - val_acc: 0.5960\n",
      "Epoch 186/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4528 - acc: 0.7840 - val_loss: 0.7044 - val_acc: 0.5833\n",
      "Epoch 187/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4487 - acc: 0.7910 - val_loss: 0.7003 - val_acc: 0.6105\n",
      "Epoch 188/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4491 - acc: 0.7918 - val_loss: 0.7079 - val_acc: 0.6395\n",
      "Epoch 189/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4475 - acc: 0.7925 - val_loss: 0.7009 - val_acc: 0.5996\n",
      "Epoch 190/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4445 - acc: 0.7941 - val_loss: 0.7054 - val_acc: 0.6214\n",
      "Epoch 191/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4419 - acc: 0.7918 - val_loss: 0.7158 - val_acc: 0.5815\n",
      "Epoch 192/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4470 - acc: 0.7956 - val_loss: 0.7085 - val_acc: 0.5978\n",
      "Epoch 193/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4438 - acc: 0.7894 - val_loss: 0.7097 - val_acc: 0.6105\n",
      "Epoch 194/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4393 - acc: 0.7949 - val_loss: 0.7074 - val_acc: 0.6105\n",
      "Epoch 195/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4380 - acc: 0.7980 - val_loss: 0.7162 - val_acc: 0.6087\n",
      "Epoch 196/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4368 - acc: 0.7988 - val_loss: 0.7144 - val_acc: 0.5906\n",
      "Epoch 197/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4347 - acc: 0.8003 - val_loss: 0.7220 - val_acc: 0.6069\n",
      "Epoch 198/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4337 - acc: 0.8026 - val_loss: 0.7138 - val_acc: 0.5996\n",
      "Epoch 199/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4322 - acc: 0.8050 - val_loss: 0.7210 - val_acc: 0.6304\n",
      "Epoch 200/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4329 - acc: 0.7949 - val_loss: 0.7169 - val_acc: 0.5978\n",
      "Epoch 201/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4291 - acc: 0.8034 - val_loss: 0.7173 - val_acc: 0.6159\n",
      "Epoch 202/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4364 - acc: 0.7995 - val_loss: 0.7319 - val_acc: 0.5797\n",
      "Epoch 203/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4294 - acc: 0.8019 - val_loss: 0.7180 - val_acc: 0.5924\n",
      "Epoch 204/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4270 - acc: 0.8159 - val_loss: 0.7259 - val_acc: 0.6196\n",
      "Epoch 205/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4296 - acc: 0.7995 - val_loss: 0.7166 - val_acc: 0.6123\n",
      "Epoch 206/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4351 - acc: 0.7894 - val_loss: 0.7338 - val_acc: 0.5870\n",
      "Epoch 207/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4314 - acc: 0.7995 - val_loss: 0.7255 - val_acc: 0.5924\n",
      "Epoch 208/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4265 - acc: 0.8034 - val_loss: 0.7239 - val_acc: 0.5942\n",
      "Epoch 209/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4230 - acc: 0.8042 - val_loss: 0.7219 - val_acc: 0.6014\n",
      "Epoch 210/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4223 - acc: 0.8135 - val_loss: 0.7305 - val_acc: 0.5797\n",
      "Epoch 211/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4212 - acc: 0.8089 - val_loss: 0.7207 - val_acc: 0.5942\n",
      "Epoch 212/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4179 - acc: 0.8104 - val_loss: 0.7445 - val_acc: 0.5833\n",
      "Epoch 213/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4170 - acc: 0.8104 - val_loss: 0.7372 - val_acc: 0.6141\n",
      "Epoch 214/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.4171 - acc: 0.8057 - val_loss: 0.7392 - val_acc: 0.5779\n",
      "Epoch 215/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.4169 - acc: 0.8127 - val_loss: 0.7354 - val_acc: 0.6051\n",
      "Epoch 216/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4123 - acc: 0.8135 - val_loss: 0.7431 - val_acc: 0.5978\n",
      "Epoch 217/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4110 - acc: 0.8197 - val_loss: 0.7277 - val_acc: 0.6069\n",
      "Epoch 218/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4121 - acc: 0.8112 - val_loss: 0.7361 - val_acc: 0.5888\n",
      "Epoch 219/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4105 - acc: 0.8182 - val_loss: 0.7406 - val_acc: 0.5906\n",
      "Epoch 220/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4118 - acc: 0.8182 - val_loss: 0.7414 - val_acc: 0.6268\n",
      "Epoch 221/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4110 - acc: 0.8120 - val_loss: 0.7513 - val_acc: 0.5833\n",
      "Epoch 222/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4122 - acc: 0.8065 - val_loss: 0.7443 - val_acc: 0.6159\n",
      "Epoch 223/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4073 - acc: 0.8174 - val_loss: 0.7220 - val_acc: 0.6087\n",
      "Epoch 224/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4040 - acc: 0.8197 - val_loss: 0.7413 - val_acc: 0.5978\n",
      "Epoch 225/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4026 - acc: 0.8221 - val_loss: 0.7359 - val_acc: 0.5942\n",
      "Epoch 226/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4021 - acc: 0.8275 - val_loss: 0.7381 - val_acc: 0.6033\n",
      "Epoch 227/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4019 - acc: 0.8151 - val_loss: 0.7431 - val_acc: 0.6069\n",
      "Epoch 228/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4011 - acc: 0.8127 - val_loss: 0.7487 - val_acc: 0.5797\n",
      "Epoch 229/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4011 - acc: 0.8190 - val_loss: 0.7459 - val_acc: 0.5960\n",
      "Epoch 230/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4065 - acc: 0.7980 - val_loss: 0.7625 - val_acc: 0.5815\n",
      "Epoch 231/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.4019 - acc: 0.8096 - val_loss: 0.7470 - val_acc: 0.6159\n",
      "Epoch 232/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3991 - acc: 0.8127 - val_loss: 0.7484 - val_acc: 0.5888\n",
      "Epoch 233/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3960 - acc: 0.8244 - val_loss: 0.7570 - val_acc: 0.5888\n",
      "Epoch 234/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3923 - acc: 0.8221 - val_loss: 0.7510 - val_acc: 0.6105\n",
      "Epoch 235/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3938 - acc: 0.8283 - val_loss: 0.7667 - val_acc: 0.5906\n",
      "Epoch 236/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3883 - acc: 0.8322 - val_loss: 0.7582 - val_acc: 0.5924\n",
      "Epoch 237/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3918 - acc: 0.8197 - val_loss: 0.7587 - val_acc: 0.5870\n",
      "Epoch 238/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3860 - acc: 0.8329 - val_loss: 0.7666 - val_acc: 0.6051\n",
      "Epoch 239/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3856 - acc: 0.8291 - val_loss: 0.7590 - val_acc: 0.6105\n",
      "Epoch 240/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3849 - acc: 0.8236 - val_loss: 0.7671 - val_acc: 0.6051\n",
      "Epoch 241/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3858 - acc: 0.8314 - val_loss: 0.7679 - val_acc: 0.5942\n",
      "Epoch 242/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3826 - acc: 0.8368 - val_loss: 0.7805 - val_acc: 0.6014\n",
      "Epoch 243/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3822 - acc: 0.8329 - val_loss: 0.7730 - val_acc: 0.6123\n",
      "Epoch 244/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3787 - acc: 0.8353 - val_loss: 0.7759 - val_acc: 0.5996\n",
      "Epoch 245/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3820 - acc: 0.8314 - val_loss: 0.7787 - val_acc: 0.5906\n",
      "Epoch 246/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3767 - acc: 0.8368 - val_loss: 0.7870 - val_acc: 0.6141\n",
      "Epoch 247/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3773 - acc: 0.8314 - val_loss: 0.7695 - val_acc: 0.5870\n",
      "Epoch 248/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3803 - acc: 0.8275 - val_loss: 0.7913 - val_acc: 0.5888\n",
      "Epoch 249/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3800 - acc: 0.8291 - val_loss: 0.7684 - val_acc: 0.6033\n",
      "Epoch 250/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3751 - acc: 0.8306 - val_loss: 0.7734 - val_acc: 0.6286\n",
      "Epoch 251/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3730 - acc: 0.8329 - val_loss: 0.7875 - val_acc: 0.6033\n",
      "Epoch 252/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3721 - acc: 0.8384 - val_loss: 0.7838 - val_acc: 0.5888\n",
      "Epoch 253/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3708 - acc: 0.8430 - val_loss: 0.7796 - val_acc: 0.6123\n",
      "Epoch 254/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3702 - acc: 0.8353 - val_loss: 0.7880 - val_acc: 0.5924\n",
      "Epoch 255/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3693 - acc: 0.8415 - val_loss: 0.7904 - val_acc: 0.6105\n",
      "Epoch 256/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3689 - acc: 0.8298 - val_loss: 0.7960 - val_acc: 0.5888\n",
      "Epoch 257/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3686 - acc: 0.8430 - val_loss: 0.7932 - val_acc: 0.5833\n",
      "Epoch 258/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3678 - acc: 0.8345 - val_loss: 0.7949 - val_acc: 0.6214\n",
      "Epoch 259/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3680 - acc: 0.8329 - val_loss: 0.7895 - val_acc: 0.5960\n",
      "Epoch 260/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3630 - acc: 0.8446 - val_loss: 0.8009 - val_acc: 0.5960\n",
      "Epoch 261/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3618 - acc: 0.8407 - val_loss: 0.7864 - val_acc: 0.6123\n",
      "Epoch 262/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3614 - acc: 0.8392 - val_loss: 0.8021 - val_acc: 0.6051\n",
      "Epoch 263/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3593 - acc: 0.8516 - val_loss: 0.8035 - val_acc: 0.6069\n",
      "Epoch 264/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3617 - acc: 0.8376 - val_loss: 0.7896 - val_acc: 0.5906\n",
      "Epoch 265/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3545 - acc: 0.8485 - val_loss: 0.8084 - val_acc: 0.6123\n",
      "Epoch 266/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3554 - acc: 0.8500 - val_loss: 0.7940 - val_acc: 0.6250\n",
      "Epoch 267/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3578 - acc: 0.8407 - val_loss: 0.7942 - val_acc: 0.6069\n",
      "Epoch 268/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3543 - acc: 0.8477 - val_loss: 0.8041 - val_acc: 0.6123\n",
      "Epoch 269/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3531 - acc: 0.8415 - val_loss: 0.8089 - val_acc: 0.5870\n",
      "Epoch 270/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3506 - acc: 0.8469 - val_loss: 0.8034 - val_acc: 0.5924\n",
      "Epoch 271/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3574 - acc: 0.8423 - val_loss: 0.7977 - val_acc: 0.5924\n",
      "Epoch 272/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3502 - acc: 0.8500 - val_loss: 0.8177 - val_acc: 0.5851\n",
      "Epoch 273/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3523 - acc: 0.8430 - val_loss: 0.8161 - val_acc: 0.5924\n",
      "Epoch 274/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3472 - acc: 0.8563 - val_loss: 0.8200 - val_acc: 0.6105\n",
      "Epoch 275/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3469 - acc: 0.8516 - val_loss: 0.8192 - val_acc: 0.5942\n",
      "Epoch 276/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3436 - acc: 0.8485 - val_loss: 0.8240 - val_acc: 0.6105\n",
      "Epoch 277/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3433 - acc: 0.8446 - val_loss: 0.8276 - val_acc: 0.6105\n",
      "Epoch 278/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3498 - acc: 0.8353 - val_loss: 0.8093 - val_acc: 0.5888\n",
      "Epoch 279/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3419 - acc: 0.8578 - val_loss: 0.8355 - val_acc: 0.5851\n",
      "Epoch 280/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.3417 - acc: 0.8531 - val_loss: 0.8327 - val_acc: 0.6141\n",
      "Epoch 281/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.3403 - acc: 0.8469 - val_loss: 0.8272 - val_acc: 0.6123\n",
      "Epoch 282/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3418 - acc: 0.8493 - val_loss: 0.8292 - val_acc: 0.6105\n",
      "Epoch 283/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3373 - acc: 0.8539 - val_loss: 0.8377 - val_acc: 0.5942\n",
      "Epoch 284/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3364 - acc: 0.8563 - val_loss: 0.8292 - val_acc: 0.5996\n",
      "Epoch 285/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3354 - acc: 0.8539 - val_loss: 0.8530 - val_acc: 0.5978\n",
      "Epoch 286/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3371 - acc: 0.8594 - val_loss: 0.8423 - val_acc: 0.6159\n",
      "Epoch 287/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3334 - acc: 0.8586 - val_loss: 0.8590 - val_acc: 0.6141\n",
      "Epoch 288/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3341 - acc: 0.8555 - val_loss: 0.8456 - val_acc: 0.6123\n",
      "Epoch 289/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3301 - acc: 0.8632 - val_loss: 0.8553 - val_acc: 0.5924\n",
      "Epoch 290/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3304 - acc: 0.8570 - val_loss: 0.8569 - val_acc: 0.6105\n",
      "Epoch 291/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3286 - acc: 0.8648 - val_loss: 0.8511 - val_acc: 0.5978\n",
      "Epoch 292/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3262 - acc: 0.8687 - val_loss: 0.8570 - val_acc: 0.5924\n",
      "Epoch 293/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3256 - acc: 0.8594 - val_loss: 0.8614 - val_acc: 0.5906\n",
      "Epoch 294/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3234 - acc: 0.8578 - val_loss: 0.8740 - val_acc: 0.6304\n",
      "Epoch 295/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3254 - acc: 0.8640 - val_loss: 0.8518 - val_acc: 0.6087\n",
      "Epoch 296/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3267 - acc: 0.8555 - val_loss: 0.8673 - val_acc: 0.5906\n",
      "Epoch 297/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3237 - acc: 0.8656 - val_loss: 0.8768 - val_acc: 0.5960\n",
      "Epoch 298/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3242 - acc: 0.8656 - val_loss: 0.8701 - val_acc: 0.5924\n",
      "Epoch 299/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3191 - acc: 0.8617 - val_loss: 0.8681 - val_acc: 0.5942\n",
      "Epoch 300/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3184 - acc: 0.8671 - val_loss: 0.8693 - val_acc: 0.6069\n",
      "Epoch 301/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3178 - acc: 0.8671 - val_loss: 0.8668 - val_acc: 0.5996\n",
      "Epoch 302/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3156 - acc: 0.8687 - val_loss: 0.8739 - val_acc: 0.5888\n",
      "Epoch 303/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3200 - acc: 0.8594 - val_loss: 0.8676 - val_acc: 0.6105\n",
      "Epoch 304/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3129 - acc: 0.8640 - val_loss: 0.8815 - val_acc: 0.6159\n",
      "Epoch 305/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3130 - acc: 0.8679 - val_loss: 0.8969 - val_acc: 0.5996\n",
      "Epoch 306/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3153 - acc: 0.8695 - val_loss: 0.8942 - val_acc: 0.5924\n",
      "Epoch 307/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3127 - acc: 0.8687 - val_loss: 0.8806 - val_acc: 0.6033\n",
      "Epoch 308/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3100 - acc: 0.8648 - val_loss: 0.8697 - val_acc: 0.6014\n",
      "Epoch 309/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3092 - acc: 0.8710 - val_loss: 0.8722 - val_acc: 0.5960\n",
      "Epoch 310/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3080 - acc: 0.8679 - val_loss: 0.8804 - val_acc: 0.5924\n",
      "Epoch 311/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3059 - acc: 0.8726 - val_loss: 0.8871 - val_acc: 0.6087\n",
      "Epoch 312/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3077 - acc: 0.8695 - val_loss: 0.9019 - val_acc: 0.6051\n",
      "Epoch 313/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3078 - acc: 0.8733 - val_loss: 0.8977 - val_acc: 0.5978\n",
      "Epoch 314/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3016 - acc: 0.8726 - val_loss: 0.8902 - val_acc: 0.5942\n",
      "Epoch 315/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3009 - acc: 0.8679 - val_loss: 0.9220 - val_acc: 0.5942\n",
      "Epoch 316/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3033 - acc: 0.8656 - val_loss: 0.9190 - val_acc: 0.5851\n",
      "Epoch 317/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3023 - acc: 0.8757 - val_loss: 0.8890 - val_acc: 0.6141\n",
      "Epoch 318/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3036 - acc: 0.8733 - val_loss: 0.9455 - val_acc: 0.6159\n",
      "Epoch 319/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3025 - acc: 0.8710 - val_loss: 0.9168 - val_acc: 0.5978\n",
      "Epoch 320/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.3007 - acc: 0.8733 - val_loss: 0.9166 - val_acc: 0.6051\n",
      "Epoch 321/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2929 - acc: 0.8796 - val_loss: 0.8988 - val_acc: 0.5906\n",
      "Epoch 322/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2998 - acc: 0.8733 - val_loss: 0.9371 - val_acc: 0.5851\n",
      "Epoch 323/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2922 - acc: 0.8788 - val_loss: 0.9170 - val_acc: 0.6014\n",
      "Epoch 324/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2934 - acc: 0.8827 - val_loss: 0.9129 - val_acc: 0.6087\n",
      "Epoch 325/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2900 - acc: 0.8772 - val_loss: 0.9378 - val_acc: 0.5851\n",
      "Epoch 326/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2923 - acc: 0.8780 - val_loss: 0.9175 - val_acc: 0.5924\n",
      "Epoch 327/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2891 - acc: 0.8796 - val_loss: 0.9270 - val_acc: 0.5924\n",
      "Epoch 328/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2868 - acc: 0.8796 - val_loss: 0.9395 - val_acc: 0.6069\n",
      "Epoch 329/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2846 - acc: 0.8796 - val_loss: 0.9348 - val_acc: 0.6051\n",
      "Epoch 330/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2866 - acc: 0.8834 - val_loss: 0.9351 - val_acc: 0.6033\n",
      "Epoch 331/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2899 - acc: 0.8765 - val_loss: 0.9436 - val_acc: 0.5960\n",
      "Epoch 332/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2849 - acc: 0.8873 - val_loss: 0.9510 - val_acc: 0.6105\n",
      "Epoch 333/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2816 - acc: 0.8811 - val_loss: 0.9503 - val_acc: 0.6087\n",
      "Epoch 334/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2796 - acc: 0.8881 - val_loss: 0.9363 - val_acc: 0.6051\n",
      "Epoch 335/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2843 - acc: 0.8780 - val_loss: 0.9649 - val_acc: 0.5888\n",
      "Epoch 336/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2834 - acc: 0.8765 - val_loss: 0.9422 - val_acc: 0.6087\n",
      "Epoch 337/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2828 - acc: 0.8710 - val_loss: 0.9385 - val_acc: 0.5906\n",
      "Epoch 338/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2792 - acc: 0.8780 - val_loss: 0.9728 - val_acc: 0.6051\n",
      "Epoch 339/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2761 - acc: 0.8873 - val_loss: 0.9440 - val_acc: 0.5888\n",
      "Epoch 340/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2781 - acc: 0.8811 - val_loss: 0.9833 - val_acc: 0.6014\n",
      "Epoch 341/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2808 - acc: 0.8842 - val_loss: 0.9679 - val_acc: 0.6014\n",
      "Epoch 342/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2752 - acc: 0.8928 - val_loss: 0.9724 - val_acc: 0.5996\n",
      "Epoch 343/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2700 - acc: 0.8889 - val_loss: 0.9620 - val_acc: 0.5996\n",
      "Epoch 344/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2773 - acc: 0.8765 - val_loss: 0.9747 - val_acc: 0.6105\n",
      "Epoch 345/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2776 - acc: 0.8780 - val_loss: 0.9836 - val_acc: 0.5996\n",
      "Epoch 346/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.2716 - acc: 0.8834 - val_loss: 0.9578 - val_acc: 0.5960\n",
      "Epoch 347/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.2689 - acc: 0.8858 - val_loss: 0.9948 - val_acc: 0.6051\n",
      "Epoch 348/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2718 - acc: 0.8842 - val_loss: 0.9751 - val_acc: 0.5960\n",
      "Epoch 349/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2686 - acc: 0.8889 - val_loss: 0.9878 - val_acc: 0.5924\n",
      "Epoch 350/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2712 - acc: 0.8858 - val_loss: 0.9806 - val_acc: 0.6123\n",
      "Epoch 351/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2655 - acc: 0.8881 - val_loss: 0.9809 - val_acc: 0.5906\n",
      "Epoch 352/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2614 - acc: 0.8998 - val_loss: 0.9868 - val_acc: 0.5942\n",
      "Epoch 353/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2634 - acc: 0.8912 - val_loss: 0.9715 - val_acc: 0.5924\n",
      "Epoch 354/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2637 - acc: 0.8904 - val_loss: 0.9683 - val_acc: 0.6014\n",
      "Epoch 355/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2604 - acc: 0.8943 - val_loss: 0.9946 - val_acc: 0.5942\n",
      "Epoch 356/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2557 - acc: 0.8974 - val_loss: 0.9992 - val_acc: 0.5978\n",
      "Epoch 357/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2577 - acc: 0.8974 - val_loss: 1.0027 - val_acc: 0.6033\n",
      "Epoch 358/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2552 - acc: 0.9005 - val_loss: 1.0137 - val_acc: 0.6051\n",
      "Epoch 359/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2572 - acc: 0.8897 - val_loss: 1.0121 - val_acc: 0.6141\n",
      "Epoch 360/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2576 - acc: 0.8920 - val_loss: 1.0125 - val_acc: 0.5924\n",
      "Epoch 361/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2533 - acc: 0.8982 - val_loss: 1.0032 - val_acc: 0.6014\n",
      "Epoch 362/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2540 - acc: 0.8951 - val_loss: 1.0109 - val_acc: 0.6141\n",
      "Epoch 363/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2535 - acc: 0.8928 - val_loss: 1.0308 - val_acc: 0.6051\n",
      "Epoch 364/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2513 - acc: 0.9005 - val_loss: 1.0284 - val_acc: 0.5888\n",
      "Epoch 365/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2505 - acc: 0.8967 - val_loss: 1.0153 - val_acc: 0.6033\n",
      "Epoch 366/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2508 - acc: 0.8990 - val_loss: 1.0211 - val_acc: 0.6033\n",
      "Epoch 367/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2551 - acc: 0.8951 - val_loss: 1.0315 - val_acc: 0.5978\n",
      "Epoch 368/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2517 - acc: 0.8951 - val_loss: 1.0205 - val_acc: 0.6033\n",
      "Epoch 369/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2492 - acc: 0.8990 - val_loss: 1.0347 - val_acc: 0.5960\n",
      "Epoch 370/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2512 - acc: 0.8990 - val_loss: 1.0348 - val_acc: 0.6051\n",
      "Epoch 371/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2503 - acc: 0.8967 - val_loss: 1.0303 - val_acc: 0.5978\n",
      "Epoch 372/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2433 - acc: 0.9013 - val_loss: 1.0464 - val_acc: 0.6051\n",
      "Epoch 373/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2465 - acc: 0.8943 - val_loss: 1.0344 - val_acc: 0.6069\n",
      "Epoch 374/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2442 - acc: 0.8928 - val_loss: 1.0398 - val_acc: 0.5942\n",
      "Epoch 375/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2424 - acc: 0.8943 - val_loss: 1.0640 - val_acc: 0.6014\n",
      "Epoch 376/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2369 - acc: 0.9013 - val_loss: 1.0429 - val_acc: 0.5978\n",
      "Epoch 377/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2374 - acc: 0.9060 - val_loss: 1.0570 - val_acc: 0.5960\n",
      "Epoch 378/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2369 - acc: 0.9044 - val_loss: 1.0381 - val_acc: 0.5960\n",
      "Epoch 379/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2360 - acc: 0.9013 - val_loss: 1.0645 - val_acc: 0.6033\n",
      "Epoch 380/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2370 - acc: 0.9013 - val_loss: 1.0473 - val_acc: 0.6051\n",
      "Epoch 381/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2368 - acc: 0.9052 - val_loss: 1.0643 - val_acc: 0.6014\n",
      "Epoch 382/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2314 - acc: 0.9044 - val_loss: 1.0757 - val_acc: 0.5960\n",
      "Epoch 383/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2338 - acc: 0.9037 - val_loss: 1.0865 - val_acc: 0.5996\n",
      "Epoch 384/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2313 - acc: 0.9052 - val_loss: 1.0728 - val_acc: 0.6159\n",
      "Epoch 385/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2366 - acc: 0.8998 - val_loss: 1.0566 - val_acc: 0.5996\n",
      "Epoch 386/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2279 - acc: 0.9122 - val_loss: 1.0721 - val_acc: 0.5960\n",
      "Epoch 387/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2286 - acc: 0.9122 - val_loss: 1.0981 - val_acc: 0.5942\n",
      "Epoch 388/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2323 - acc: 0.9029 - val_loss: 1.0823 - val_acc: 0.6014\n",
      "Epoch 389/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2292 - acc: 0.9075 - val_loss: 1.0666 - val_acc: 0.5924\n",
      "Epoch 390/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2281 - acc: 0.9106 - val_loss: 1.0667 - val_acc: 0.6014\n",
      "Epoch 391/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2314 - acc: 0.8998 - val_loss: 1.0747 - val_acc: 0.5996\n",
      "Epoch 392/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2270 - acc: 0.8974 - val_loss: 1.1125 - val_acc: 0.6069\n",
      "Epoch 393/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2253 - acc: 0.9060 - val_loss: 1.0878 - val_acc: 0.6033\n",
      "Epoch 394/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2221 - acc: 0.9138 - val_loss: 1.0767 - val_acc: 0.6178\n",
      "Epoch 395/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2223 - acc: 0.9106 - val_loss: 1.1186 - val_acc: 0.5924\n",
      "Epoch 396/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2236 - acc: 0.9099 - val_loss: 1.0882 - val_acc: 0.5996\n",
      "Epoch 397/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2188 - acc: 0.9099 - val_loss: 1.1445 - val_acc: 0.6014\n",
      "Epoch 398/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2191 - acc: 0.9138 - val_loss: 1.1012 - val_acc: 0.6159\n",
      "Epoch 399/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2190 - acc: 0.9106 - val_loss: 1.1082 - val_acc: 0.6014\n",
      "Epoch 400/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2163 - acc: 0.9130 - val_loss: 1.1321 - val_acc: 0.5870\n",
      "Epoch 401/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2144 - acc: 0.9138 - val_loss: 1.1187 - val_acc: 0.6014\n",
      "Epoch 402/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2165 - acc: 0.9060 - val_loss: 1.1083 - val_acc: 0.6014\n",
      "Epoch 403/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2137 - acc: 0.9184 - val_loss: 1.1350 - val_acc: 0.6178\n",
      "Epoch 404/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2145 - acc: 0.9122 - val_loss: 1.0916 - val_acc: 0.6033\n",
      "Epoch 405/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2133 - acc: 0.9130 - val_loss: 1.1454 - val_acc: 0.5978\n",
      "Epoch 406/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2140 - acc: 0.9083 - val_loss: 1.1263 - val_acc: 0.6178\n",
      "Epoch 407/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2158 - acc: 0.9099 - val_loss: 1.1617 - val_acc: 0.6033\n",
      "Epoch 408/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2142 - acc: 0.9130 - val_loss: 1.1530 - val_acc: 0.5906\n",
      "Epoch 409/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2091 - acc: 0.9176 - val_loss: 1.1314 - val_acc: 0.5996\n",
      "Epoch 410/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2111 - acc: 0.9184 - val_loss: 1.1329 - val_acc: 0.5996\n",
      "Epoch 411/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2102 - acc: 0.9153 - val_loss: 1.1089 - val_acc: 0.5978\n",
      "Epoch 412/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.2116 - acc: 0.9161 - val_loss: 1.1600 - val_acc: 0.6051\n",
      "Epoch 413/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.2059 - acc: 0.9153 - val_loss: 1.1554 - val_acc: 0.5870\n",
      "Epoch 414/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2061 - acc: 0.9083 - val_loss: 1.1228 - val_acc: 0.6087\n",
      "Epoch 415/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2030 - acc: 0.9192 - val_loss: 1.1812 - val_acc: 0.5924\n",
      "Epoch 416/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2064 - acc: 0.9153 - val_loss: 1.1525 - val_acc: 0.5978\n",
      "Epoch 417/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2038 - acc: 0.9169 - val_loss: 1.1817 - val_acc: 0.5906\n",
      "Epoch 418/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2046 - acc: 0.9153 - val_loss: 1.1480 - val_acc: 0.6141\n",
      "Epoch 419/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2015 - acc: 0.9246 - val_loss: 1.1754 - val_acc: 0.5870\n",
      "Epoch 420/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2004 - acc: 0.9223 - val_loss: 1.1818 - val_acc: 0.6069\n",
      "Epoch 421/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1991 - acc: 0.9277 - val_loss: 1.1445 - val_acc: 0.5996\n",
      "Epoch 422/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1983 - acc: 0.9176 - val_loss: 1.1720 - val_acc: 0.5797\n",
      "Epoch 423/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.2046 - acc: 0.9200 - val_loss: 1.1645 - val_acc: 0.5888\n",
      "Epoch 424/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1969 - acc: 0.9200 - val_loss: 1.1784 - val_acc: 0.5924\n",
      "Epoch 425/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1963 - acc: 0.9231 - val_loss: 1.1738 - val_acc: 0.5996\n",
      "Epoch 426/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1955 - acc: 0.9192 - val_loss: 1.1879 - val_acc: 0.5888\n",
      "Epoch 427/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1956 - acc: 0.9270 - val_loss: 1.2011 - val_acc: 0.5960\n",
      "Epoch 428/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1978 - acc: 0.9239 - val_loss: 1.1967 - val_acc: 0.5906\n",
      "Epoch 429/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1935 - acc: 0.9293 - val_loss: 1.1913 - val_acc: 0.5942\n",
      "Epoch 430/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1935 - acc: 0.9239 - val_loss: 1.1921 - val_acc: 0.6014\n",
      "Epoch 431/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1907 - acc: 0.9215 - val_loss: 1.2007 - val_acc: 0.5978\n",
      "Epoch 432/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1884 - acc: 0.9223 - val_loss: 1.1908 - val_acc: 0.6069\n",
      "Epoch 433/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1888 - acc: 0.9239 - val_loss: 1.2047 - val_acc: 0.5924\n",
      "Epoch 434/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1917 - acc: 0.9262 - val_loss: 1.1765 - val_acc: 0.5996\n",
      "Epoch 435/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1911 - acc: 0.9207 - val_loss: 1.1989 - val_acc: 0.5942\n",
      "Epoch 436/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1869 - acc: 0.9285 - val_loss: 1.2128 - val_acc: 0.5924\n",
      "Epoch 437/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1891 - acc: 0.9207 - val_loss: 1.2021 - val_acc: 0.6159\n",
      "Epoch 438/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1873 - acc: 0.9308 - val_loss: 1.1931 - val_acc: 0.6051\n",
      "Epoch 439/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1872 - acc: 0.9246 - val_loss: 1.2093 - val_acc: 0.5870\n",
      "Epoch 440/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1851 - acc: 0.9301 - val_loss: 1.1929 - val_acc: 0.5996\n",
      "Epoch 441/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1846 - acc: 0.9371 - val_loss: 1.2389 - val_acc: 0.5978\n",
      "Epoch 442/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1805 - acc: 0.9277 - val_loss: 1.2301 - val_acc: 0.5779\n",
      "Epoch 443/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1924 - acc: 0.9130 - val_loss: 1.2292 - val_acc: 0.5851\n",
      "Epoch 444/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1845 - acc: 0.9285 - val_loss: 1.2417 - val_acc: 0.6178\n",
      "Epoch 445/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1804 - acc: 0.9347 - val_loss: 1.2199 - val_acc: 0.5942\n",
      "Epoch 446/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1794 - acc: 0.9301 - val_loss: 1.2439 - val_acc: 0.5978\n",
      "Epoch 447/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1761 - acc: 0.9308 - val_loss: 1.2469 - val_acc: 0.5942\n",
      "Epoch 448/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1748 - acc: 0.9324 - val_loss: 1.2407 - val_acc: 0.5960\n",
      "Epoch 449/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1760 - acc: 0.9355 - val_loss: 1.2218 - val_acc: 0.6069\n",
      "Epoch 450/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1793 - acc: 0.9332 - val_loss: 1.2342 - val_acc: 0.6141\n",
      "Epoch 451/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1728 - acc: 0.9324 - val_loss: 1.2610 - val_acc: 0.6033\n",
      "Epoch 452/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1781 - acc: 0.9363 - val_loss: 1.2557 - val_acc: 0.6014\n",
      "Epoch 453/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1733 - acc: 0.9371 - val_loss: 1.2587 - val_acc: 0.5815\n",
      "Epoch 454/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1726 - acc: 0.9371 - val_loss: 1.2698 - val_acc: 0.6014\n",
      "Epoch 455/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1705 - acc: 0.9355 - val_loss: 1.2258 - val_acc: 0.5978\n",
      "Epoch 456/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1725 - acc: 0.9425 - val_loss: 1.2374 - val_acc: 0.5996\n",
      "Epoch 457/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1692 - acc: 0.9363 - val_loss: 1.2697 - val_acc: 0.6033\n",
      "Epoch 458/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1711 - acc: 0.9332 - val_loss: 1.2649 - val_acc: 0.5960\n",
      "Epoch 459/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1672 - acc: 0.9378 - val_loss: 1.2476 - val_acc: 0.5978\n",
      "Epoch 460/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1658 - acc: 0.9441 - val_loss: 1.2743 - val_acc: 0.6014\n",
      "Epoch 461/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1670 - acc: 0.9402 - val_loss: 1.2687 - val_acc: 0.6159\n",
      "Epoch 462/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1667 - acc: 0.9394 - val_loss: 1.2638 - val_acc: 0.5960\n",
      "Epoch 463/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1629 - acc: 0.9433 - val_loss: 1.2643 - val_acc: 0.6033\n",
      "Epoch 464/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1647 - acc: 0.9409 - val_loss: 1.2712 - val_acc: 0.6123\n",
      "Epoch 465/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1607 - acc: 0.9402 - val_loss: 1.3256 - val_acc: 0.5870\n",
      "Epoch 466/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1632 - acc: 0.9409 - val_loss: 1.3106 - val_acc: 0.6014\n",
      "Epoch 467/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1624 - acc: 0.9409 - val_loss: 1.3127 - val_acc: 0.6014\n",
      "Epoch 468/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1644 - acc: 0.9347 - val_loss: 1.2730 - val_acc: 0.5888\n",
      "Epoch 469/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1628 - acc: 0.9456 - val_loss: 1.2810 - val_acc: 0.6051\n",
      "Epoch 470/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1615 - acc: 0.9417 - val_loss: 1.3214 - val_acc: 0.6033\n",
      "Epoch 471/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1562 - acc: 0.9472 - val_loss: 1.3263 - val_acc: 0.6051\n",
      "Epoch 472/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1617 - acc: 0.9378 - val_loss: 1.3051 - val_acc: 0.5870\n",
      "Epoch 473/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1579 - acc: 0.9472 - val_loss: 1.3163 - val_acc: 0.5996\n",
      "Epoch 474/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1641 - acc: 0.9394 - val_loss: 1.3037 - val_acc: 0.6178\n",
      "Epoch 475/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1567 - acc: 0.9495 - val_loss: 1.3477 - val_acc: 0.6123\n",
      "Epoch 476/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1537 - acc: 0.9479 - val_loss: 1.3073 - val_acc: 0.5924\n",
      "Epoch 477/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1527 - acc: 0.9472 - val_loss: 1.3287 - val_acc: 0.6123\n",
      "Epoch 478/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.1526 - acc: 0.9487 - val_loss: 1.3317 - val_acc: 0.5978\n",
      "Epoch 479/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.1513 - acc: 0.9464 - val_loss: 1.3085 - val_acc: 0.5942\n",
      "Epoch 480/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1508 - acc: 0.9479 - val_loss: 1.3414 - val_acc: 0.5924\n",
      "Epoch 481/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1503 - acc: 0.9518 - val_loss: 1.3301 - val_acc: 0.6014\n",
      "Epoch 482/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1487 - acc: 0.9510 - val_loss: 1.3395 - val_acc: 0.5924\n",
      "Epoch 483/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1551 - acc: 0.9441 - val_loss: 1.3421 - val_acc: 0.5924\n",
      "Epoch 484/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1502 - acc: 0.9495 - val_loss: 1.3403 - val_acc: 0.6105\n",
      "Epoch 485/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1484 - acc: 0.9487 - val_loss: 1.3341 - val_acc: 0.6178\n",
      "Epoch 486/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1492 - acc: 0.9472 - val_loss: 1.3312 - val_acc: 0.6178\n",
      "Epoch 487/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1465 - acc: 0.9479 - val_loss: 1.3421 - val_acc: 0.6014\n",
      "Epoch 488/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1457 - acc: 0.9479 - val_loss: 1.3485 - val_acc: 0.5978\n",
      "Epoch 489/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1469 - acc: 0.9526 - val_loss: 1.3608 - val_acc: 0.5996\n",
      "Epoch 490/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1459 - acc: 0.9510 - val_loss: 1.3980 - val_acc: 0.5924\n",
      "Epoch 491/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1432 - acc: 0.9518 - val_loss: 1.3524 - val_acc: 0.6033\n",
      "Epoch 492/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1412 - acc: 0.9565 - val_loss: 1.3550 - val_acc: 0.6123\n",
      "Epoch 493/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1423 - acc: 0.9503 - val_loss: 1.3573 - val_acc: 0.5888\n",
      "Epoch 494/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1403 - acc: 0.9565 - val_loss: 1.3854 - val_acc: 0.5870\n",
      "Epoch 495/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1436 - acc: 0.9510 - val_loss: 1.3912 - val_acc: 0.6051\n",
      "Epoch 496/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1377 - acc: 0.9588 - val_loss: 1.3763 - val_acc: 0.5960\n",
      "Epoch 497/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1384 - acc: 0.9542 - val_loss: 1.3808 - val_acc: 0.6159\n",
      "Epoch 498/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1376 - acc: 0.9557 - val_loss: 1.3586 - val_acc: 0.6051\n",
      "Epoch 499/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1373 - acc: 0.9580 - val_loss: 1.3914 - val_acc: 0.6069\n",
      "Epoch 500/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1344 - acc: 0.9557 - val_loss: 1.3720 - val_acc: 0.5978\n",
      "Epoch 501/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1347 - acc: 0.9611 - val_loss: 1.3989 - val_acc: 0.6033\n",
      "Epoch 502/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1360 - acc: 0.9503 - val_loss: 1.4121 - val_acc: 0.6069\n",
      "Epoch 503/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1375 - acc: 0.9534 - val_loss: 1.4232 - val_acc: 0.5851\n",
      "Epoch 504/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1375 - acc: 0.9542 - val_loss: 1.4203 - val_acc: 0.6033\n",
      "Epoch 505/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1321 - acc: 0.9619 - val_loss: 1.3986 - val_acc: 0.6033\n",
      "Epoch 506/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1311 - acc: 0.9580 - val_loss: 1.4141 - val_acc: 0.5978\n",
      "Epoch 507/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1341 - acc: 0.9580 - val_loss: 1.3910 - val_acc: 0.6051\n",
      "Epoch 508/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1299 - acc: 0.9588 - val_loss: 1.4341 - val_acc: 0.5942\n",
      "Epoch 509/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1274 - acc: 0.9643 - val_loss: 1.4174 - val_acc: 0.5978\n",
      "Epoch 510/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1288 - acc: 0.9611 - val_loss: 1.4015 - val_acc: 0.6141\n",
      "Epoch 511/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1297 - acc: 0.9580 - val_loss: 1.3980 - val_acc: 0.6141\n",
      "Epoch 512/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1329 - acc: 0.9565 - val_loss: 1.3914 - val_acc: 0.6014\n",
      "Epoch 513/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1272 - acc: 0.9604 - val_loss: 1.4096 - val_acc: 0.6033\n",
      "Epoch 514/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1263 - acc: 0.9611 - val_loss: 1.4302 - val_acc: 0.5996\n",
      "Epoch 515/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1239 - acc: 0.9658 - val_loss: 1.4159 - val_acc: 0.6033\n",
      "Epoch 516/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1223 - acc: 0.9643 - val_loss: 1.4384 - val_acc: 0.6033\n",
      "Epoch 517/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1266 - acc: 0.9627 - val_loss: 1.4405 - val_acc: 0.6033\n",
      "Epoch 518/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1276 - acc: 0.9596 - val_loss: 1.4481 - val_acc: 0.5960\n",
      "Epoch 519/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1232 - acc: 0.9627 - val_loss: 1.4704 - val_acc: 0.6069\n",
      "Epoch 520/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1199 - acc: 0.9650 - val_loss: 1.4412 - val_acc: 0.6051\n",
      "Epoch 521/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1205 - acc: 0.9643 - val_loss: 1.4679 - val_acc: 0.6051\n",
      "Epoch 522/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1199 - acc: 0.9627 - val_loss: 1.4665 - val_acc: 0.5906\n",
      "Epoch 523/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1208 - acc: 0.9596 - val_loss: 1.4857 - val_acc: 0.6014\n",
      "Epoch 524/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1207 - acc: 0.9611 - val_loss: 1.5112 - val_acc: 0.6178\n",
      "Epoch 525/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1184 - acc: 0.9627 - val_loss: 1.4751 - val_acc: 0.5960\n",
      "Epoch 526/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1165 - acc: 0.9674 - val_loss: 1.4548 - val_acc: 0.5978\n",
      "Epoch 527/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1150 - acc: 0.9674 - val_loss: 1.4751 - val_acc: 0.6033\n",
      "Epoch 528/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1171 - acc: 0.9674 - val_loss: 1.4799 - val_acc: 0.5906\n",
      "Epoch 529/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1157 - acc: 0.9681 - val_loss: 1.4904 - val_acc: 0.6014\n",
      "Epoch 530/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1133 - acc: 0.9697 - val_loss: 1.4543 - val_acc: 0.6069\n",
      "Epoch 531/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1174 - acc: 0.9658 - val_loss: 1.4506 - val_acc: 0.6141\n",
      "Epoch 532/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1186 - acc: 0.9611 - val_loss: 1.4650 - val_acc: 0.6033\n",
      "Epoch 533/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1129 - acc: 0.9697 - val_loss: 1.4760 - val_acc: 0.5942\n",
      "Epoch 534/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1171 - acc: 0.9650 - val_loss: 1.4773 - val_acc: 0.5924\n",
      "Epoch 535/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1109 - acc: 0.9689 - val_loss: 1.5196 - val_acc: 0.6159\n",
      "Epoch 536/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1109 - acc: 0.9674 - val_loss: 1.5243 - val_acc: 0.5978\n",
      "Epoch 537/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1083 - acc: 0.9713 - val_loss: 1.4965 - val_acc: 0.6141\n",
      "Epoch 538/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1098 - acc: 0.9681 - val_loss: 1.4976 - val_acc: 0.5851\n",
      "Epoch 539/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1106 - acc: 0.9697 - val_loss: 1.5098 - val_acc: 0.5960\n",
      "Epoch 540/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1093 - acc: 0.9705 - val_loss: 1.5319 - val_acc: 0.5960\n",
      "Epoch 541/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1082 - acc: 0.9720 - val_loss: 1.5089 - val_acc: 0.5978\n",
      "Epoch 542/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1130 - acc: 0.9596 - val_loss: 1.5135 - val_acc: 0.5870\n",
      "Epoch 543/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1092 - acc: 0.9681 - val_loss: 1.5297 - val_acc: 0.6033\n",
      "Epoch 544/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.1023 - acc: 0.9751 - val_loss: 1.5247 - val_acc: 0.6159\n",
      "Epoch 545/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1033 - acc: 0.9736 - val_loss: 1.5403 - val_acc: 0.6178\n",
      "Epoch 546/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1016 - acc: 0.9744 - val_loss: 1.5147 - val_acc: 0.6087\n",
      "Epoch 547/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1025 - acc: 0.9751 - val_loss: 1.5553 - val_acc: 0.6232\n",
      "Epoch 548/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1058 - acc: 0.9697 - val_loss: 1.5266 - val_acc: 0.6105\n",
      "Epoch 549/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1005 - acc: 0.9728 - val_loss: 1.5454 - val_acc: 0.6214\n",
      "Epoch 550/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1014 - acc: 0.9705 - val_loss: 1.5517 - val_acc: 0.5906\n",
      "Epoch 551/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1001 - acc: 0.9736 - val_loss: 1.5293 - val_acc: 0.6105\n",
      "Epoch 552/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.1011 - acc: 0.9697 - val_loss: 1.5742 - val_acc: 0.5960\n",
      "Epoch 553/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0999 - acc: 0.9713 - val_loss: 1.5558 - val_acc: 0.6087\n",
      "Epoch 554/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0980 - acc: 0.9728 - val_loss: 1.5378 - val_acc: 0.5888\n",
      "Epoch 555/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0964 - acc: 0.9790 - val_loss: 1.5877 - val_acc: 0.5851\n",
      "Epoch 556/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0971 - acc: 0.9759 - val_loss: 1.5955 - val_acc: 0.5978\n",
      "Epoch 557/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0966 - acc: 0.9744 - val_loss: 1.5861 - val_acc: 0.6141\n",
      "Epoch 558/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0940 - acc: 0.9790 - val_loss: 1.5731 - val_acc: 0.5906\n",
      "Epoch 559/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0920 - acc: 0.9790 - val_loss: 1.5529 - val_acc: 0.6105\n",
      "Epoch 560/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0917 - acc: 0.9775 - val_loss: 1.5819 - val_acc: 0.5996\n",
      "Epoch 561/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0939 - acc: 0.9767 - val_loss: 1.5657 - val_acc: 0.6069\n",
      "Epoch 562/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0924 - acc: 0.9775 - val_loss: 1.5959 - val_acc: 0.5996\n",
      "Epoch 563/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0914 - acc: 0.9775 - val_loss: 1.6038 - val_acc: 0.6105\n",
      "Epoch 564/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0944 - acc: 0.9720 - val_loss: 1.6053 - val_acc: 0.5996\n",
      "Epoch 565/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0936 - acc: 0.9775 - val_loss: 1.5863 - val_acc: 0.5960\n",
      "Epoch 566/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0941 - acc: 0.9705 - val_loss: 1.6184 - val_acc: 0.5942\n",
      "Epoch 567/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0908 - acc: 0.9759 - val_loss: 1.6209 - val_acc: 0.6141\n",
      "Epoch 568/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0882 - acc: 0.9767 - val_loss: 1.6241 - val_acc: 0.6087\n",
      "Epoch 569/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0876 - acc: 0.9798 - val_loss: 1.6321 - val_acc: 0.6250\n",
      "Epoch 570/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0904 - acc: 0.9759 - val_loss: 1.6149 - val_acc: 0.6051\n",
      "Epoch 571/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0890 - acc: 0.9782 - val_loss: 1.6234 - val_acc: 0.6087\n",
      "Epoch 572/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0861 - acc: 0.9814 - val_loss: 1.6651 - val_acc: 0.6214\n",
      "Epoch 573/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0857 - acc: 0.9798 - val_loss: 1.6347 - val_acc: 0.5996\n",
      "Epoch 574/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0829 - acc: 0.9829 - val_loss: 1.6474 - val_acc: 0.6051\n",
      "Epoch 575/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0830 - acc: 0.9806 - val_loss: 1.6500 - val_acc: 0.6105\n",
      "Epoch 576/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0871 - acc: 0.9767 - val_loss: 1.6775 - val_acc: 0.5888\n",
      "Epoch 577/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0842 - acc: 0.9782 - val_loss: 1.6648 - val_acc: 0.6051\n",
      "Epoch 578/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0836 - acc: 0.9775 - val_loss: 1.6390 - val_acc: 0.5924\n",
      "Epoch 579/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0813 - acc: 0.9837 - val_loss: 1.6744 - val_acc: 0.6196\n",
      "Epoch 580/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0857 - acc: 0.9767 - val_loss: 1.6392 - val_acc: 0.6141\n",
      "Epoch 581/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0794 - acc: 0.9845 - val_loss: 1.6657 - val_acc: 0.6232\n",
      "Epoch 582/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0780 - acc: 0.9829 - val_loss: 1.6878 - val_acc: 0.6286\n",
      "Epoch 583/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0787 - acc: 0.9775 - val_loss: 1.6695 - val_acc: 0.5906\n",
      "Epoch 584/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0791 - acc: 0.9837 - val_loss: 1.6587 - val_acc: 0.6214\n",
      "Epoch 585/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0795 - acc: 0.9821 - val_loss: 1.7054 - val_acc: 0.6196\n",
      "Epoch 586/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0801 - acc: 0.9775 - val_loss: 1.6637 - val_acc: 0.6069\n",
      "Epoch 587/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0782 - acc: 0.9837 - val_loss: 1.6846 - val_acc: 0.6014\n",
      "Epoch 588/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0763 - acc: 0.9829 - val_loss: 1.7048 - val_acc: 0.6250\n",
      "Epoch 589/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0745 - acc: 0.9821 - val_loss: 1.6886 - val_acc: 0.6232\n",
      "Epoch 590/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0769 - acc: 0.9814 - val_loss: 1.6915 - val_acc: 0.6033\n",
      "Epoch 591/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0772 - acc: 0.9806 - val_loss: 1.6904 - val_acc: 0.6268\n",
      "Epoch 592/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0749 - acc: 0.9829 - val_loss: 1.6964 - val_acc: 0.6051\n",
      "Epoch 593/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0736 - acc: 0.9821 - val_loss: 1.6795 - val_acc: 0.6196\n",
      "Epoch 594/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0744 - acc: 0.9837 - val_loss: 1.6917 - val_acc: 0.6159\n",
      "Epoch 595/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0709 - acc: 0.9845 - val_loss: 1.7050 - val_acc: 0.6051\n",
      "Epoch 596/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0721 - acc: 0.9860 - val_loss: 1.7256 - val_acc: 0.6178\n",
      "Epoch 597/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0722 - acc: 0.9806 - val_loss: 1.7319 - val_acc: 0.5906\n",
      "Epoch 598/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0737 - acc: 0.9806 - val_loss: 1.6950 - val_acc: 0.6159\n",
      "Epoch 599/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9868 - val_loss: 1.7130 - val_acc: 0.6141\n",
      "Epoch 600/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0710 - acc: 0.9852 - val_loss: 1.7211 - val_acc: 0.6178\n",
      "Epoch 601/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0700 - acc: 0.9837 - val_loss: 1.7212 - val_acc: 0.6159\n",
      "Epoch 602/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0683 - acc: 0.9860 - val_loss: 1.7285 - val_acc: 0.6069\n",
      "Epoch 603/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0666 - acc: 0.9876 - val_loss: 1.7295 - val_acc: 0.6051\n",
      "Epoch 604/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0673 - acc: 0.9852 - val_loss: 1.7802 - val_acc: 0.5996\n",
      "Epoch 605/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0715 - acc: 0.9845 - val_loss: 1.7567 - val_acc: 0.6159\n",
      "Epoch 606/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0643 - acc: 0.9883 - val_loss: 1.7362 - val_acc: 0.6178\n",
      "Epoch 607/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0667 - acc: 0.9852 - val_loss: 1.7213 - val_acc: 0.6069\n",
      "Epoch 608/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0645 - acc: 0.9852 - val_loss: 1.7625 - val_acc: 0.6196\n",
      "Epoch 609/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0642 - acc: 0.9883 - val_loss: 1.7672 - val_acc: 0.6214\n",
      "Epoch 610/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.0629 - acc: 0.9876 - val_loss: 1.7701 - val_acc: 0.6033\n",
      "Epoch 611/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0627 - acc: 0.9868 - val_loss: 1.7908 - val_acc: 0.5942\n",
      "Epoch 612/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0635 - acc: 0.9907 - val_loss: 1.7642 - val_acc: 0.5996\n",
      "Epoch 613/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0684 - acc: 0.9790 - val_loss: 1.7700 - val_acc: 0.6033\n",
      "Epoch 614/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0609 - acc: 0.9868 - val_loss: 1.7807 - val_acc: 0.6268\n",
      "Epoch 615/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0602 - acc: 0.9899 - val_loss: 1.8022 - val_acc: 0.6159\n",
      "Epoch 616/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0624 - acc: 0.9860 - val_loss: 1.8364 - val_acc: 0.6069\n",
      "Epoch 617/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0619 - acc: 0.9876 - val_loss: 1.8041 - val_acc: 0.6033\n",
      "Epoch 618/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0580 - acc: 0.9860 - val_loss: 1.8216 - val_acc: 0.5996\n",
      "Epoch 619/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0595 - acc: 0.9868 - val_loss: 1.8127 - val_acc: 0.6014\n",
      "Epoch 620/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0581 - acc: 0.9907 - val_loss: 1.8107 - val_acc: 0.6178\n",
      "Epoch 621/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0567 - acc: 0.9899 - val_loss: 1.7923 - val_acc: 0.6014\n",
      "Epoch 622/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0592 - acc: 0.9891 - val_loss: 1.7758 - val_acc: 0.5996\n",
      "Epoch 623/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0581 - acc: 0.9891 - val_loss: 1.7945 - val_acc: 0.6105\n",
      "Epoch 624/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0559 - acc: 0.9891 - val_loss: 1.7859 - val_acc: 0.6123\n",
      "Epoch 625/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0557 - acc: 0.9883 - val_loss: 1.8316 - val_acc: 0.6232\n",
      "Epoch 626/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0565 - acc: 0.9915 - val_loss: 1.8230 - val_acc: 0.6014\n",
      "Epoch 627/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0578 - acc: 0.9876 - val_loss: 1.8323 - val_acc: 0.6051\n",
      "Epoch 628/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0534 - acc: 0.9915 - val_loss: 1.8164 - val_acc: 0.6178\n",
      "Epoch 629/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0530 - acc: 0.9907 - val_loss: 1.8307 - val_acc: 0.6141\n",
      "Epoch 630/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0507 - acc: 0.9899 - val_loss: 1.8764 - val_acc: 0.6087\n",
      "Epoch 631/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0577 - acc: 0.9868 - val_loss: 1.8473 - val_acc: 0.5960\n",
      "Epoch 632/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0531 - acc: 0.9915 - val_loss: 1.8678 - val_acc: 0.6141\n",
      "Epoch 633/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0501 - acc: 0.9915 - val_loss: 1.8428 - val_acc: 0.6105\n",
      "Epoch 634/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0515 - acc: 0.9915 - val_loss: 1.8752 - val_acc: 0.6250\n",
      "Epoch 635/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0486 - acc: 0.9907 - val_loss: 1.8765 - val_acc: 0.6178\n",
      "Epoch 636/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0507 - acc: 0.9922 - val_loss: 1.8629 - val_acc: 0.5960\n",
      "Epoch 637/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0499 - acc: 0.9899 - val_loss: 1.8899 - val_acc: 0.6159\n",
      "Epoch 638/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0481 - acc: 0.9922 - val_loss: 1.8798 - val_acc: 0.6178\n",
      "Epoch 639/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0477 - acc: 0.9915 - val_loss: 1.9133 - val_acc: 0.6341\n",
      "Epoch 640/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0499 - acc: 0.9907 - val_loss: 1.8885 - val_acc: 0.6069\n",
      "Epoch 641/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0479 - acc: 0.9915 - val_loss: 1.8997 - val_acc: 0.6178\n",
      "Epoch 642/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0477 - acc: 0.9922 - val_loss: 1.9073 - val_acc: 0.6087\n",
      "Epoch 643/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0464 - acc: 0.9922 - val_loss: 1.8873 - val_acc: 0.6087\n",
      "Epoch 644/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0444 - acc: 0.9930 - val_loss: 1.9133 - val_acc: 0.6250\n",
      "Epoch 645/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0453 - acc: 0.9907 - val_loss: 1.9270 - val_acc: 0.6051\n",
      "Epoch 646/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0460 - acc: 0.9915 - val_loss: 1.9084 - val_acc: 0.6141\n",
      "Epoch 647/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0434 - acc: 0.9930 - val_loss: 1.8884 - val_acc: 0.6178\n",
      "Epoch 648/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0461 - acc: 0.9907 - val_loss: 1.9232 - val_acc: 0.5924\n",
      "Epoch 649/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0461 - acc: 0.9922 - val_loss: 1.9060 - val_acc: 0.6159\n",
      "Epoch 650/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0475 - acc: 0.9930 - val_loss: 1.9261 - val_acc: 0.6178\n",
      "Epoch 651/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9946 - val_loss: 1.9380 - val_acc: 0.6250\n",
      "Epoch 652/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0434 - acc: 0.9930 - val_loss: 1.9128 - val_acc: 0.6105\n",
      "Epoch 653/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0417 - acc: 0.9938 - val_loss: 1.9601 - val_acc: 0.6105\n",
      "Epoch 654/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0429 - acc: 0.9915 - val_loss: 1.9287 - val_acc: 0.6159\n",
      "Epoch 655/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0404 - acc: 0.9938 - val_loss: 1.9538 - val_acc: 0.6196\n",
      "Epoch 656/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0417 - acc: 0.9930 - val_loss: 1.9367 - val_acc: 0.6087\n",
      "Epoch 657/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0405 - acc: 0.9938 - val_loss: 1.9500 - val_acc: 0.6178\n",
      "Epoch 658/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0399 - acc: 0.9930 - val_loss: 1.9352 - val_acc: 0.6087\n",
      "Epoch 659/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0404 - acc: 0.9938 - val_loss: 1.9281 - val_acc: 0.6250\n",
      "Epoch 660/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9922 - val_loss: 1.9746 - val_acc: 0.6105\n",
      "Epoch 661/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0385 - acc: 0.9946 - val_loss: 1.9615 - val_acc: 0.6178\n",
      "Epoch 662/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0375 - acc: 0.9946 - val_loss: 1.9725 - val_acc: 0.6178\n",
      "Epoch 663/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0398 - acc: 0.9946 - val_loss: 1.9584 - val_acc: 0.6232\n",
      "Epoch 664/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0390 - acc: 0.9922 - val_loss: 1.9303 - val_acc: 0.6196\n",
      "Epoch 665/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0364 - acc: 0.9953 - val_loss: 1.9739 - val_acc: 0.6214\n",
      "Epoch 666/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0365 - acc: 0.9938 - val_loss: 1.9952 - val_acc: 0.6123\n",
      "Epoch 667/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0347 - acc: 0.9946 - val_loss: 1.9758 - val_acc: 0.6178\n",
      "Epoch 668/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0356 - acc: 0.9938 - val_loss: 1.9724 - val_acc: 0.6141\n",
      "Epoch 669/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0364 - acc: 0.9953 - val_loss: 1.9918 - val_acc: 0.6087\n",
      "Epoch 670/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0351 - acc: 0.9938 - val_loss: 1.9941 - val_acc: 0.6268\n",
      "Epoch 671/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0357 - acc: 0.9953 - val_loss: 1.9983 - val_acc: 0.6123\n",
      "Epoch 672/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9946 - val_loss: 2.0608 - val_acc: 0.5996\n",
      "Epoch 673/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9930 - val_loss: 2.0013 - val_acc: 0.5942\n",
      "Epoch 674/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0351 - acc: 0.9953 - val_loss: 2.0096 - val_acc: 0.6105\n",
      "Epoch 675/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.0333 - acc: 0.9961 - val_loss: 2.0471 - val_acc: 0.6123\n",
      "Epoch 676/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.0327 - acc: 0.9953 - val_loss: 2.0301 - val_acc: 0.6286\n",
      "Epoch 677/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0340 - acc: 0.9953 - val_loss: 2.0070 - val_acc: 0.6159\n",
      "Epoch 678/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0316 - acc: 0.9961 - val_loss: 2.0183 - val_acc: 0.6123\n",
      "Epoch 679/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0326 - acc: 0.9953 - val_loss: 2.0088 - val_acc: 0.6214\n",
      "Epoch 680/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0315 - acc: 0.9953 - val_loss: 2.0018 - val_acc: 0.6196\n",
      "Epoch 681/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0314 - acc: 0.9953 - val_loss: 2.0445 - val_acc: 0.6069\n",
      "Epoch 682/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0302 - acc: 0.9953 - val_loss: 2.0240 - val_acc: 0.6304\n",
      "Epoch 683/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0284 - acc: 0.9969 - val_loss: 2.0651 - val_acc: 0.6087\n",
      "Epoch 684/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0300 - acc: 0.9961 - val_loss: 2.0481 - val_acc: 0.6214\n",
      "Epoch 685/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0288 - acc: 0.9953 - val_loss: 2.0848 - val_acc: 0.6159\n",
      "Epoch 686/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0284 - acc: 0.9977 - val_loss: 2.0729 - val_acc: 0.6105\n",
      "Epoch 687/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0287 - acc: 0.9961 - val_loss: 2.0696 - val_acc: 0.5996\n",
      "Epoch 688/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0291 - acc: 0.9961 - val_loss: 2.0485 - val_acc: 0.6178\n",
      "Epoch 689/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0279 - acc: 0.9961 - val_loss: 2.0632 - val_acc: 0.6141\n",
      "Epoch 690/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0273 - acc: 0.9969 - val_loss: 2.0817 - val_acc: 0.6033\n",
      "Epoch 691/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0284 - acc: 0.9969 - val_loss: 2.0671 - val_acc: 0.6214\n",
      "Epoch 692/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0285 - acc: 0.9961 - val_loss: 2.0950 - val_acc: 0.6159\n",
      "Epoch 693/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0278 - acc: 0.9946 - val_loss: 2.1360 - val_acc: 0.6196\n",
      "Epoch 694/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0299 - acc: 0.9938 - val_loss: 2.0702 - val_acc: 0.6105\n",
      "Epoch 695/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0260 - acc: 0.9977 - val_loss: 2.0928 - val_acc: 0.6051\n",
      "Epoch 696/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0286 - acc: 0.9969 - val_loss: 2.1006 - val_acc: 0.6051\n",
      "Epoch 697/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0254 - acc: 0.9961 - val_loss: 2.1101 - val_acc: 0.6159\n",
      "Epoch 698/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0252 - acc: 0.9977 - val_loss: 2.1394 - val_acc: 0.6014\n",
      "Epoch 699/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0261 - acc: 0.9984 - val_loss: 2.1050 - val_acc: 0.6359\n",
      "Epoch 700/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0285 - acc: 0.9961 - val_loss: 2.1044 - val_acc: 0.6141\n",
      "Epoch 701/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0247 - acc: 0.9969 - val_loss: 2.1164 - val_acc: 0.6232\n",
      "Epoch 702/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0238 - acc: 0.9969 - val_loss: 2.1459 - val_acc: 0.6178\n",
      "Epoch 703/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0243 - acc: 0.9969 - val_loss: 2.1183 - val_acc: 0.6159\n",
      "Epoch 704/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0234 - acc: 0.9984 - val_loss: 2.1215 - val_acc: 0.6069\n",
      "Epoch 705/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0257 - acc: 0.9969 - val_loss: 2.1035 - val_acc: 0.6250\n",
      "Epoch 706/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0237 - acc: 0.9969 - val_loss: 2.1384 - val_acc: 0.6178\n",
      "Epoch 707/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0223 - acc: 0.9969 - val_loss: 2.1546 - val_acc: 0.6105\n",
      "Epoch 708/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0219 - acc: 0.9977 - val_loss: 2.1514 - val_acc: 0.6268\n",
      "Epoch 709/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0233 - acc: 0.9969 - val_loss: 2.1340 - val_acc: 0.6196\n",
      "Epoch 710/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0251 - acc: 0.9961 - val_loss: 2.1637 - val_acc: 0.6250\n",
      "Epoch 711/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0223 - acc: 0.9977 - val_loss: 2.1571 - val_acc: 0.6178\n",
      "Epoch 712/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0209 - acc: 0.9977 - val_loss: 2.1589 - val_acc: 0.6268\n",
      "Epoch 713/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0212 - acc: 0.9984 - val_loss: 2.1698 - val_acc: 0.6105\n",
      "Epoch 714/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0201 - acc: 0.9984 - val_loss: 2.1776 - val_acc: 0.6069\n",
      "Epoch 715/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0208 - acc: 0.9984 - val_loss: 2.1728 - val_acc: 0.6250\n",
      "Epoch 716/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0204 - acc: 0.9984 - val_loss: 2.1932 - val_acc: 0.6014\n",
      "Epoch 717/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0200 - acc: 0.9984 - val_loss: 2.2026 - val_acc: 0.6159\n",
      "Epoch 718/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0200 - acc: 0.9984 - val_loss: 2.1829 - val_acc: 0.6286\n",
      "Epoch 719/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0192 - acc: 0.9992 - val_loss: 2.1945 - val_acc: 0.6087\n",
      "Epoch 720/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0183 - acc: 0.9984 - val_loss: 2.1802 - val_acc: 0.6214\n",
      "Epoch 721/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0213 - acc: 0.9969 - val_loss: 2.1842 - val_acc: 0.6069\n",
      "Epoch 722/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0181 - acc: 0.9977 - val_loss: 2.1990 - val_acc: 0.6286\n",
      "Epoch 723/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0187 - acc: 0.9984 - val_loss: 2.2058 - val_acc: 0.6178\n",
      "Epoch 724/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0184 - acc: 0.9992 - val_loss: 2.2366 - val_acc: 0.6051\n",
      "Epoch 725/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0177 - acc: 0.9984 - val_loss: 2.1841 - val_acc: 0.6105\n",
      "Epoch 726/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0176 - acc: 0.9984 - val_loss: 2.2286 - val_acc: 0.6214\n",
      "Epoch 727/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0179 - acc: 0.9977 - val_loss: 2.2101 - val_acc: 0.6123\n",
      "Epoch 728/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0181 - acc: 0.9984 - val_loss: 2.2161 - val_acc: 0.6178\n",
      "Epoch 729/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0173 - acc: 0.9984 - val_loss: 2.2443 - val_acc: 0.6178\n",
      "Epoch 730/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0177 - acc: 0.9984 - val_loss: 2.2489 - val_acc: 0.6123\n",
      "Epoch 731/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0172 - acc: 0.9984 - val_loss: 2.2703 - val_acc: 0.6087\n",
      "Epoch 732/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0163 - acc: 0.9984 - val_loss: 2.2487 - val_acc: 0.6033\n",
      "Epoch 733/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0160 - acc: 0.9992 - val_loss: 2.2371 - val_acc: 0.6214\n",
      "Epoch 734/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0155 - acc: 0.9984 - val_loss: 2.2495 - val_acc: 0.6196\n",
      "Epoch 735/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0151 - acc: 0.9984 - val_loss: 2.2676 - val_acc: 0.6123\n",
      "Epoch 736/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0160 - acc: 0.9992 - val_loss: 2.2645 - val_acc: 0.6268\n",
      "Epoch 737/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0153 - acc: 0.9992 - val_loss: 2.2678 - val_acc: 0.6123\n",
      "Epoch 738/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0151 - acc: 0.9992 - val_loss: 2.2642 - val_acc: 0.6159\n",
      "Epoch 739/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0152 - acc: 0.9984 - val_loss: 2.2844 - val_acc: 0.6178\n",
      "Epoch 740/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.0159 - acc: 0.9984 - val_loss: 2.2542 - val_acc: 0.6214\n",
      "Epoch 741/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.0148 - acc: 0.9984 - val_loss: 2.3060 - val_acc: 0.6196\n",
      "Epoch 742/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.3123 - val_acc: 0.6250\n",
      "Epoch 743/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0140 - acc: 0.9992 - val_loss: 2.2868 - val_acc: 0.6250\n",
      "Epoch 744/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0139 - acc: 0.9992 - val_loss: 2.3117 - val_acc: 0.6141\n",
      "Epoch 745/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0137 - acc: 0.9984 - val_loss: 2.3156 - val_acc: 0.6214\n",
      "Epoch 746/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0136 - acc: 0.9992 - val_loss: 2.3075 - val_acc: 0.6178\n",
      "Epoch 747/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0130 - acc: 0.9992 - val_loss: 2.3221 - val_acc: 0.6141\n",
      "Epoch 748/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0138 - acc: 0.9984 - val_loss: 2.3299 - val_acc: 0.6250\n",
      "Epoch 749/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0136 - acc: 0.9992 - val_loss: 2.3203 - val_acc: 0.5942\n",
      "Epoch 750/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.3313 - val_acc: 0.6123\n",
      "Epoch 751/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0139 - acc: 0.9992 - val_loss: 2.3323 - val_acc: 0.6178\n",
      "Epoch 752/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.3418 - val_acc: 0.6159\n",
      "Epoch 753/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.3640 - val_acc: 0.6087\n",
      "Epoch 754/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0120 - acc: 0.9984 - val_loss: 2.3651 - val_acc: 0.6159\n",
      "Epoch 755/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 2.3228 - val_acc: 0.6250\n",
      "Epoch 756/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0129 - acc: 0.9992 - val_loss: 2.3669 - val_acc: 0.5996\n",
      "Epoch 757/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0154 - acc: 0.9977 - val_loss: 2.3678 - val_acc: 0.6051\n",
      "Epoch 758/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0111 - acc: 0.9992 - val_loss: 2.3606 - val_acc: 0.6087\n",
      "Epoch 759/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0109 - acc: 0.9992 - val_loss: 2.3421 - val_acc: 0.6159\n",
      "Epoch 760/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 2.3721 - val_acc: 0.6123\n",
      "Epoch 761/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 2.3693 - val_acc: 0.6250\n",
      "Epoch 762/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0112 - acc: 0.9992 - val_loss: 2.3925 - val_acc: 0.6141\n",
      "Epoch 763/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.3846 - val_acc: 0.6105\n",
      "Epoch 764/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.4286 - val_acc: 0.5924\n",
      "Epoch 765/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0108 - acc: 0.9992 - val_loss: 2.3705 - val_acc: 0.6087\n",
      "Epoch 766/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.4049 - val_acc: 0.6087\n",
      "Epoch 767/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.3832 - val_acc: 0.6214\n",
      "Epoch 768/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.4158 - val_acc: 0.6159\n",
      "Epoch 769/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.4048 - val_acc: 0.6141\n",
      "Epoch 770/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.4155 - val_acc: 0.6123\n",
      "Epoch 771/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.4184 - val_acc: 0.6141\n",
      "Epoch 772/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.4034 - val_acc: 0.6232\n",
      "Epoch 773/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0130 - acc: 0.9992 - val_loss: 2.4401 - val_acc: 0.6123\n",
      "Epoch 774/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.4116 - val_acc: 0.6268\n",
      "Epoch 775/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.4423 - val_acc: 0.6123\n",
      "Epoch 776/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0100 - acc: 0.9992 - val_loss: 2.4094 - val_acc: 0.6178\n",
      "Epoch 777/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.4513 - val_acc: 0.6069\n",
      "Epoch 778/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.5308 - val_acc: 0.5924\n",
      "Epoch 779/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.4347 - val_acc: 0.6159\n",
      "Epoch 780/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.4823 - val_acc: 0.6014\n",
      "Epoch 781/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.4736 - val_acc: 0.6123\n",
      "Epoch 782/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.4670 - val_acc: 0.6159\n",
      "Epoch 783/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.4759 - val_acc: 0.6123\n",
      "Epoch 784/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.4950 - val_acc: 0.6033\n",
      "Epoch 785/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.4691 - val_acc: 0.6105\n",
      "Epoch 786/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.4746 - val_acc: 0.6178\n",
      "Epoch 787/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.4864 - val_acc: 0.6087\n",
      "Epoch 788/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.4585 - val_acc: 0.6196\n",
      "Epoch 789/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.4843 - val_acc: 0.6123\n",
      "Epoch 790/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.5117 - val_acc: 0.6159\n",
      "Epoch 791/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.5166 - val_acc: 0.6178\n",
      "Epoch 792/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.5177 - val_acc: 0.6123\n",
      "Epoch 793/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.4975 - val_acc: 0.6141\n",
      "Epoch 794/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.5366 - val_acc: 0.6069\n",
      "Epoch 795/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.5382 - val_acc: 0.6123\n",
      "Epoch 796/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.5269 - val_acc: 0.6141\n",
      "Epoch 797/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.5397 - val_acc: 0.6141\n",
      "Epoch 798/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.5391 - val_acc: 0.6141\n",
      "Epoch 799/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.5558 - val_acc: 0.6033\n",
      "Epoch 800/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.5555 - val_acc: 0.6159\n",
      "Epoch 801/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.5505 - val_acc: 0.6105\n",
      "Epoch 802/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.5508 - val_acc: 0.6105\n",
      "Epoch 803/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.5499 - val_acc: 0.6141\n",
      "Epoch 804/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.5899 - val_acc: 0.6105\n",
      "Epoch 805/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.5565 - val_acc: 0.6232\n",
      "Epoch 806/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.5920 - val_acc: 0.6033\n",
      "Epoch 807/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.5689 - val_acc: 0.6178\n",
      "Epoch 808/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.5651 - val_acc: 0.6178\n",
      "Epoch 809/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.5991 - val_acc: 0.6123\n",
      "Epoch 810/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.6216 - val_acc: 0.6033\n",
      "Epoch 811/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.5918 - val_acc: 0.6069\n",
      "Epoch 812/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.5975 - val_acc: 0.6178\n",
      "Epoch 813/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.6051 - val_acc: 0.6087\n",
      "Epoch 814/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.6246 - val_acc: 0.6178\n",
      "Epoch 815/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.6071 - val_acc: 0.6178\n",
      "Epoch 816/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.5831 - val_acc: 0.6178\n",
      "Epoch 817/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.6308 - val_acc: 0.6141\n",
      "Epoch 818/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.6258 - val_acc: 0.6159\n",
      "Epoch 819/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.6220 - val_acc: 0.6196\n",
      "Epoch 820/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.6303 - val_acc: 0.6141\n",
      "Epoch 821/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.6280 - val_acc: 0.6268\n",
      "Epoch 822/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.6451 - val_acc: 0.6087\n",
      "Epoch 823/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.6515 - val_acc: 0.6196\n",
      "Epoch 824/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.6565 - val_acc: 0.6087\n",
      "Epoch 825/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.6426 - val_acc: 0.6196\n",
      "Epoch 826/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.6644 - val_acc: 0.6141\n",
      "Epoch 827/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.6673 - val_acc: 0.6178\n",
      "Epoch 828/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.6440 - val_acc: 0.6232\n",
      "Epoch 829/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.6771 - val_acc: 0.6196\n",
      "Epoch 830/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 2.6724 - val_acc: 0.6178\n",
      "Epoch 831/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.7089 - val_acc: 0.6087\n",
      "Epoch 832/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.6839 - val_acc: 0.6123\n",
      "Epoch 833/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 2.6893 - val_acc: 0.6178\n",
      "Epoch 834/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.7138 - val_acc: 0.6196\n",
      "Epoch 835/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.7095 - val_acc: 0.6123\n",
      "Epoch 836/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.7132 - val_acc: 0.6123\n",
      "Epoch 837/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.7328 - val_acc: 0.6087\n",
      "Epoch 838/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.7300 - val_acc: 0.6178\n",
      "Epoch 839/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 2.7532 - val_acc: 0.6033\n",
      "Epoch 840/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.7455 - val_acc: 0.6087\n",
      "Epoch 841/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.7614 - val_acc: 0.6051\n",
      "Epoch 842/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.7514 - val_acc: 0.6141\n",
      "Epoch 843/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.7377 - val_acc: 0.6123\n",
      "Epoch 844/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.7393 - val_acc: 0.6123\n",
      "Epoch 845/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.7625 - val_acc: 0.6033\n",
      "Epoch 846/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.7555 - val_acc: 0.6214\n",
      "Epoch 847/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.7620 - val_acc: 0.6123\n",
      "Epoch 848/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.7736 - val_acc: 0.6178\n",
      "Epoch 849/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.7921 - val_acc: 0.6087\n",
      "Epoch 850/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.7747 - val_acc: 0.6141\n",
      "Epoch 851/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.7752 - val_acc: 0.6141\n",
      "Epoch 852/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.7571 - val_acc: 0.6304\n",
      "Epoch 853/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 2.7745 - val_acc: 0.6087\n",
      "Epoch 854/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.7593 - val_acc: 0.6232\n",
      "Epoch 855/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.8078 - val_acc: 0.6141\n",
      "Epoch 856/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.8168 - val_acc: 0.6105\n",
      "Epoch 857/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.8083 - val_acc: 0.6178\n",
      "Epoch 858/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.7928 - val_acc: 0.6159\n",
      "Epoch 859/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.8206 - val_acc: 0.6123\n",
      "Epoch 860/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.8469 - val_acc: 0.6087\n",
      "Epoch 861/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.7949 - val_acc: 0.6196\n",
      "Epoch 862/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.8341 - val_acc: 0.6159\n",
      "Epoch 863/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.8497 - val_acc: 0.6087\n",
      "Epoch 864/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.8511 - val_acc: 0.6141\n",
      "Epoch 865/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.8281 - val_acc: 0.6141\n",
      "Epoch 866/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.8378 - val_acc: 0.6105\n",
      "Epoch 867/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.8554 - val_acc: 0.6069\n",
      "Epoch 868/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.8441 - val_acc: 0.6178\n",
      "Epoch 869/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.8442 - val_acc: 0.6196\n",
      "Epoch 870/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.8493 - val_acc: 0.6123\n",
      "Epoch 871/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.8664 - val_acc: 0.6141\n",
      "Epoch 872/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.8700 - val_acc: 0.6196\n",
      "Epoch 873/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.8707 - val_acc: 0.6123\n",
      "Epoch 874/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.8897 - val_acc: 0.6123\n",
      "Epoch 875/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.8867 - val_acc: 0.6105\n",
      "Epoch 876/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.9095 - val_acc: 0.6087\n",
      "Epoch 877/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.9090 - val_acc: 0.6087\n",
      "Epoch 878/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.8932 - val_acc: 0.6141\n",
      "Epoch 879/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.8922 - val_acc: 0.6069\n",
      "Epoch 880/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.9252 - val_acc: 0.6105\n",
      "Epoch 881/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.9031 - val_acc: 0.6123\n",
      "Epoch 882/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.9332 - val_acc: 0.6051\n",
      "Epoch 883/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.9300 - val_acc: 0.6105\n",
      "Epoch 884/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.9531 - val_acc: 0.6123\n",
      "Epoch 885/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.9231 - val_acc: 0.6123\n",
      "Epoch 886/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.9423 - val_acc: 0.6105\n",
      "Epoch 887/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.9222 - val_acc: 0.6123\n",
      "Epoch 888/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.9416 - val_acc: 0.6178\n",
      "Epoch 889/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.9506 - val_acc: 0.6014\n",
      "Epoch 890/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.9285 - val_acc: 0.6196\n",
      "Epoch 891/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.9732 - val_acc: 0.6105\n",
      "Epoch 892/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.9741 - val_acc: 0.6087\n",
      "Epoch 893/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.9548 - val_acc: 0.6159\n",
      "Epoch 894/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.9720 - val_acc: 0.6159\n",
      "Epoch 895/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.9803 - val_acc: 0.6105\n",
      "Epoch 896/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 3.0780 - val_acc: 0.5942\n",
      "Epoch 897/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.9342 - val_acc: 0.6105\n",
      "Epoch 898/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.9538 - val_acc: 0.6159\n",
      "Epoch 899/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.1751e-04 - acc: 1.0000 - val_loss: 2.9670 - val_acc: 0.6141\n",
      "Epoch 900/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.9798e-04 - acc: 1.0000 - val_loss: 2.9893 - val_acc: 0.6141\n",
      "Epoch 901/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.6579e-04 - acc: 1.0000 - val_loss: 2.9961 - val_acc: 0.6087\n",
      "Epoch 902/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.5131e-04 - acc: 1.0000 - val_loss: 2.9655 - val_acc: 0.6141\n",
      "Epoch 903/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.6810e-04 - acc: 1.0000 - val_loss: 3.0227 - val_acc: 0.6051\n",
      "Epoch 904/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.2864e-04 - acc: 1.0000 - val_loss: 2.9993 - val_acc: 0.6123\n",
      "Epoch 905/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.6309e-04 - acc: 1.0000 - val_loss: 3.0008 - val_acc: 0.6087\n",
      "Epoch 906/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.3323e-04 - acc: 1.0000 - val_loss: 3.0128 - val_acc: 0.6141\n",
      "Epoch 907/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.2232e-04 - acc: 1.0000 - val_loss: 3.0131 - val_acc: 0.6159\n",
      "Epoch 908/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.9224e-04 - acc: 1.0000 - val_loss: 3.0135 - val_acc: 0.6123\n",
      "Epoch 909/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.4709e-04 - acc: 1.0000 - val_loss: 3.0192 - val_acc: 0.6159\n",
      "Epoch 910/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.5075e-04 - acc: 1.0000 - val_loss: 3.0418 - val_acc: 0.6178\n",
      "Epoch 911/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.0313e-04 - acc: 1.0000 - val_loss: 3.0420 - val_acc: 0.6087\n",
      "Epoch 912/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 2.9539 - val_acc: 0.5960\n",
      "Epoch 913/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0364 - acc: 0.9876 - val_loss: 2.8542 - val_acc: 0.6051\n",
      "Epoch 914/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.8465 - val_acc: 0.6105\n",
      "Epoch 915/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.8981 - val_acc: 0.6105\n",
      "Epoch 916/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.9176 - val_acc: 0.6105\n",
      "Epoch 917/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.9435 - val_acc: 0.6051\n",
      "Epoch 918/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.3914e-04 - acc: 1.0000 - val_loss: 2.9441 - val_acc: 0.6159\n",
      "Epoch 919/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.0723e-04 - acc: 1.0000 - val_loss: 2.9626 - val_acc: 0.6105\n",
      "Epoch 920/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.3917e-04 - acc: 1.0000 - val_loss: 2.9736 - val_acc: 0.6069\n",
      "Epoch 921/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.1981e-04 - acc: 1.0000 - val_loss: 2.9868 - val_acc: 0.6105\n",
      "Epoch 922/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.9521e-04 - acc: 1.0000 - val_loss: 2.9849 - val_acc: 0.6123\n",
      "Epoch 923/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.7703e-04 - acc: 1.0000 - val_loss: 2.9878 - val_acc: 0.6105\n",
      "Epoch 924/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.5825e-04 - acc: 1.0000 - val_loss: 2.9949 - val_acc: 0.6123\n",
      "Epoch 925/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.4527e-04 - acc: 1.0000 - val_loss: 2.9961 - val_acc: 0.6105\n",
      "Epoch 926/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.3108e-04 - acc: 1.0000 - val_loss: 2.9947 - val_acc: 0.6087\n",
      "Epoch 927/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.2322e-04 - acc: 1.0000 - val_loss: 2.9991 - val_acc: 0.6087\n",
      "Epoch 928/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.0889e-04 - acc: 1.0000 - val_loss: 3.0011 - val_acc: 0.6087\n",
      "Epoch 929/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.0142e-04 - acc: 1.0000 - val_loss: 3.0010 - val_acc: 0.6069\n",
      "Epoch 930/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.9502e-04 - acc: 1.0000 - val_loss: 2.9916 - val_acc: 0.6123\n",
      "Epoch 931/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.8049e-04 - acc: 1.0000 - val_loss: 3.0084 - val_acc: 0.6087\n",
      "Epoch 932/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.7730e-04 - acc: 1.0000 - val_loss: 3.0013 - val_acc: 0.6087\n",
      "Epoch 933/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.7334e-04 - acc: 1.0000 - val_loss: 2.9975 - val_acc: 0.6105\n",
      "Epoch 934/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.6694e-04 - acc: 1.0000 - val_loss: 2.9993 - val_acc: 0.6105\n",
      "Epoch 935/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.6192e-04 - acc: 1.0000 - val_loss: 2.9983 - val_acc: 0.6105\n",
      "Epoch 936/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.5088e-04 - acc: 1.0000 - val_loss: 3.0074 - val_acc: 0.6087\n",
      "Epoch 937/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 6.4623e-04 - acc: 1.0000 - val_loss: 3.0117 - val_acc: 0.6014\n",
      "Epoch 938/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.4376e-04 - acc: 1.0000 - val_loss: 3.0156 - val_acc: 0.6014\n",
      "Epoch 939/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.4336e-04 - acc: 1.0000 - val_loss: 3.0213 - val_acc: 0.5996\n",
      "Epoch 940/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.4027e-04 - acc: 1.0000 - val_loss: 3.0151 - val_acc: 0.6033\n",
      "Epoch 941/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.2681e-04 - acc: 1.0000 - val_loss: 3.0098 - val_acc: 0.6087\n",
      "Epoch 942/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.1942e-04 - acc: 1.0000 - val_loss: 3.0087 - val_acc: 0.6069\n",
      "Epoch 943/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.1632e-04 - acc: 1.0000 - val_loss: 3.0189 - val_acc: 0.6014\n",
      "Epoch 944/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.1423e-04 - acc: 1.0000 - val_loss: 3.0156 - val_acc: 0.6069\n",
      "Epoch 945/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.0649e-04 - acc: 1.0000 - val_loss: 3.0187 - val_acc: 0.6014\n",
      "Epoch 946/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.0884e-04 - acc: 1.0000 - val_loss: 3.0253 - val_acc: 0.5996\n",
      "Epoch 947/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.0711e-04 - acc: 1.0000 - val_loss: 3.0186 - val_acc: 0.6051\n",
      "Epoch 948/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.0267e-04 - acc: 1.0000 - val_loss: 3.0178 - val_acc: 0.6051\n",
      "Epoch 949/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.9576e-04 - acc: 1.0000 - val_loss: 3.0221 - val_acc: 0.6033\n",
      "Epoch 950/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.9392e-04 - acc: 1.0000 - val_loss: 3.0239 - val_acc: 0.6069\n",
      "Epoch 951/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.9553e-04 - acc: 1.0000 - val_loss: 3.0260 - val_acc: 0.6051\n",
      "Epoch 952/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.8195e-04 - acc: 1.0000 - val_loss: 3.0314 - val_acc: 0.6014\n",
      "Epoch 953/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.7958e-04 - acc: 1.0000 - val_loss: 3.0249 - val_acc: 0.6014\n",
      "Epoch 954/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.6833e-04 - acc: 1.0000 - val_loss: 3.0194 - val_acc: 0.6069\n",
      "Epoch 955/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.7081e-04 - acc: 1.0000 - val_loss: 3.0318 - val_acc: 0.6051\n",
      "Epoch 956/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.6293e-04 - acc: 1.0000 - val_loss: 3.0292 - val_acc: 0.6051\n",
      "Epoch 957/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.6949e-04 - acc: 1.0000 - val_loss: 3.0325 - val_acc: 0.6033\n",
      "Epoch 958/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.5672e-04 - acc: 1.0000 - val_loss: 3.0370 - val_acc: 0.6069\n",
      "Epoch 959/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.6281e-04 - acc: 1.0000 - val_loss: 3.0367 - val_acc: 0.6087\n",
      "Epoch 960/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.5483e-04 - acc: 1.0000 - val_loss: 3.0438 - val_acc: 0.6033\n",
      "Epoch 961/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.4667e-04 - acc: 1.0000 - val_loss: 3.0459 - val_acc: 0.6033\n",
      "Epoch 962/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.4293e-04 - acc: 1.0000 - val_loss: 3.0546 - val_acc: 0.6033\n",
      "Epoch 963/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.4917e-04 - acc: 1.0000 - val_loss: 3.0532 - val_acc: 0.6051\n",
      "Epoch 964/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.3881e-04 - acc: 1.0000 - val_loss: 3.0555 - val_acc: 0.6014\n",
      "Epoch 965/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.3568e-04 - acc: 1.0000 - val_loss: 3.0513 - val_acc: 0.6051\n",
      "Epoch 966/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.2666e-04 - acc: 1.0000 - val_loss: 3.0502 - val_acc: 0.6087\n",
      "Epoch 967/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.2163e-04 - acc: 1.0000 - val_loss: 3.0571 - val_acc: 0.6033\n",
      "Epoch 968/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.1491e-04 - acc: 1.0000 - val_loss: 3.0457 - val_acc: 0.6123\n",
      "Epoch 969/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.2283e-04 - acc: 1.0000 - val_loss: 3.0627 - val_acc: 0.6014\n",
      "Epoch 970/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.1233e-04 - acc: 1.0000 - val_loss: 3.0509 - val_acc: 0.6123\n",
      "Epoch 971/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.1157e-04 - acc: 1.0000 - val_loss: 3.0574 - val_acc: 0.6105\n",
      "Epoch 972/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.0541e-04 - acc: 1.0000 - val_loss: 3.0685 - val_acc: 0.6014\n",
      "Epoch 973/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.2132e-04 - acc: 1.0000 - val_loss: 3.0702 - val_acc: 0.6087\n",
      "Epoch 974/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.0229e-04 - acc: 1.0000 - val_loss: 3.0697 - val_acc: 0.6087\n",
      "Epoch 975/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.9542e-04 - acc: 1.0000 - val_loss: 3.0698 - val_acc: 0.6069\n",
      "Epoch 976/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.9709e-04 - acc: 1.0000 - val_loss: 3.0805 - val_acc: 0.6033\n",
      "Epoch 977/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.9921e-04 - acc: 1.0000 - val_loss: 3.0731 - val_acc: 0.6087\n",
      "Epoch 978/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.9384e-04 - acc: 1.0000 - val_loss: 3.0726 - val_acc: 0.6105\n",
      "Epoch 979/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7905e-04 - acc: 1.0000 - val_loss: 3.0790 - val_acc: 0.6069\n",
      "Epoch 980/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.8345e-04 - acc: 1.0000 - val_loss: 3.0808 - val_acc: 0.6033\n",
      "Epoch 981/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7409e-04 - acc: 1.0000 - val_loss: 3.0825 - val_acc: 0.6069\n",
      "Epoch 982/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7368e-04 - acc: 1.0000 - val_loss: 3.0870 - val_acc: 0.6087\n",
      "Epoch 983/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7206e-04 - acc: 1.0000 - val_loss: 3.0784 - val_acc: 0.6105\n",
      "Epoch 984/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.6446e-04 - acc: 1.0000 - val_loss: 3.0797 - val_acc: 0.6105\n",
      "Epoch 985/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7890e-04 - acc: 1.0000 - val_loss: 3.0778 - val_acc: 0.6123\n",
      "Epoch 986/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.5898e-04 - acc: 1.0000 - val_loss: 3.0889 - val_acc: 0.6123\n",
      "Epoch 987/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.6157e-04 - acc: 1.0000 - val_loss: 3.0943 - val_acc: 0.6123\n",
      "Epoch 988/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7574e-04 - acc: 1.0000 - val_loss: 3.0935 - val_acc: 0.6105\n",
      "Epoch 989/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.4712e-04 - acc: 1.0000 - val_loss: 3.1096 - val_acc: 0.6033\n",
      "Epoch 990/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.6697e-04 - acc: 1.0000 - val_loss: 3.1049 - val_acc: 0.6033\n",
      "Epoch 991/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.4234e-04 - acc: 1.0000 - val_loss: 3.1131 - val_acc: 0.6069\n",
      "Epoch 992/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.3230e-04 - acc: 1.0000 - val_loss: 3.0962 - val_acc: 0.6123\n",
      "Epoch 993/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.2803e-04 - acc: 1.0000 - val_loss: 3.1062 - val_acc: 0.6105\n",
      "Epoch 994/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7779e-04 - acc: 1.0000 - val_loss: 3.0959 - val_acc: 0.6069\n",
      "Epoch 995/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.3129e-04 - acc: 1.0000 - val_loss: 3.1163 - val_acc: 0.6033\n",
      "Epoch 996/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.1733e-04 - acc: 1.0000 - val_loss: 3.1169 - val_acc: 0.6069\n",
      "Epoch 997/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.1466e-04 - acc: 1.0000 - val_loss: 3.1173 - val_acc: 0.6087\n",
      "Epoch 998/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.1084e-04 - acc: 1.0000 - val_loss: 3.1159 - val_acc: 0.6123\n",
      "Epoch 999/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.2273e-04 - acc: 1.0000 - val_loss: 3.1307 - val_acc: 0.6069\n",
      "Epoch 1000/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.0972e-04 - acc: 1.0000 - val_loss: 3.1389 - val_acc: 0.6033\n",
      "Epoch 1001/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.0470e-04 - acc: 1.0000 - val_loss: 3.1183 - val_acc: 0.6123\n",
      "Epoch 1002/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 3.9889e-04 - acc: 1.0000 - val_loss: 3.1281 - val_acc: 0.6051\n",
      "Epoch 1003/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 3.9782e-04 - acc: 1.0000 - val_loss: 3.1322 - val_acc: 0.6087\n",
      "Epoch 1004/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.0292e-04 - acc: 1.0000 - val_loss: 3.1248 - val_acc: 0.6105\n",
      "Epoch 1005/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.0717e-04 - acc: 1.0000 - val_loss: 3.1271 - val_acc: 0.6123\n",
      "Epoch 1006/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.9644e-04 - acc: 1.0000 - val_loss: 3.1343 - val_acc: 0.6105\n",
      "Epoch 1007/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.8073e-04 - acc: 1.0000 - val_loss: 3.1392 - val_acc: 0.6087\n",
      "Epoch 1008/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.8679e-04 - acc: 1.0000 - val_loss: 3.1252 - val_acc: 0.6123\n",
      "Epoch 1009/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.8417e-04 - acc: 1.0000 - val_loss: 3.1421 - val_acc: 0.6069\n",
      "Epoch 1010/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.7884e-04 - acc: 1.0000 - val_loss: 3.1416 - val_acc: 0.6123\n",
      "Epoch 1011/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.7921e-04 - acc: 1.0000 - val_loss: 3.1491 - val_acc: 0.6069\n",
      "Epoch 1012/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.6866e-04 - acc: 1.0000 - val_loss: 3.1622 - val_acc: 0.6087\n",
      "Epoch 1013/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.5359e-04 - acc: 1.0000 - val_loss: 3.1366 - val_acc: 0.6105\n",
      "Epoch 1014/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.5508e-04 - acc: 1.0000 - val_loss: 3.1554 - val_acc: 0.6105\n",
      "Epoch 1015/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.6367e-04 - acc: 1.0000 - val_loss: 3.1501 - val_acc: 0.6123\n",
      "Epoch 1016/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4828e-04 - acc: 1.0000 - val_loss: 3.1608 - val_acc: 0.6123\n",
      "Epoch 1017/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4473e-04 - acc: 1.0000 - val_loss: 3.1660 - val_acc: 0.6105\n",
      "Epoch 1018/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3914e-04 - acc: 1.0000 - val_loss: 3.1694 - val_acc: 0.6105\n",
      "Epoch 1019/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3087e-04 - acc: 1.0000 - val_loss: 3.1662 - val_acc: 0.6123\n",
      "Epoch 1020/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3460e-04 - acc: 1.0000 - val_loss: 3.1699 - val_acc: 0.6087\n",
      "Epoch 1021/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4989e-04 - acc: 1.0000 - val_loss: 3.1928 - val_acc: 0.6087\n",
      "Epoch 1022/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4379e-04 - acc: 1.0000 - val_loss: 3.1777 - val_acc: 0.6105\n",
      "Epoch 1023/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3735e-04 - acc: 1.0000 - val_loss: 3.1782 - val_acc: 0.6105\n",
      "Epoch 1024/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.1426e-04 - acc: 1.0000 - val_loss: 3.1759 - val_acc: 0.6123\n",
      "Epoch 1025/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.2315e-04 - acc: 1.0000 - val_loss: 3.2022 - val_acc: 0.6105\n",
      "Epoch 1026/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4782e-04 - acc: 1.0000 - val_loss: 3.1961 - val_acc: 0.6087\n",
      "Epoch 1027/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.1769e-04 - acc: 1.0000 - val_loss: 3.1879 - val_acc: 0.6123\n",
      "Epoch 1028/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.0867e-04 - acc: 1.0000 - val_loss: 3.1855 - val_acc: 0.6123\n",
      "Epoch 1029/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3219e-04 - acc: 1.0000 - val_loss: 3.1899 - val_acc: 0.6123\n",
      "Epoch 1030/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.0240e-04 - acc: 1.0000 - val_loss: 3.1906 - val_acc: 0.6123\n",
      "Epoch 1031/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.9687e-04 - acc: 1.0000 - val_loss: 3.1871 - val_acc: 0.6141\n",
      "Epoch 1032/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.9235e-04 - acc: 1.0000 - val_loss: 3.2003 - val_acc: 0.6105\n",
      "Epoch 1033/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.8714e-04 - acc: 1.0000 - val_loss: 3.2060 - val_acc: 0.6123\n",
      "Epoch 1034/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.2025e-04 - acc: 1.0000 - val_loss: 3.2344 - val_acc: 0.6105\n",
      "Epoch 1035/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.8998e-04 - acc: 1.0000 - val_loss: 3.1928 - val_acc: 0.6105\n",
      "Epoch 1036/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.8924e-04 - acc: 1.0000 - val_loss: 3.2319 - val_acc: 0.6069\n",
      "Epoch 1037/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.9169e-04 - acc: 1.0000 - val_loss: 3.2160 - val_acc: 0.6105\n",
      "Epoch 1038/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.7264e-04 - acc: 1.0000 - val_loss: 3.2212 - val_acc: 0.6123\n",
      "Epoch 1039/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6250e-04 - acc: 1.0000 - val_loss: 3.2195 - val_acc: 0.6087\n",
      "Epoch 1040/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6560e-04 - acc: 1.0000 - val_loss: 3.2271 - val_acc: 0.6141\n",
      "Epoch 1041/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6279e-04 - acc: 1.0000 - val_loss: 3.2300 - val_acc: 0.6123\n",
      "Epoch 1042/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.5557e-04 - acc: 1.0000 - val_loss: 3.2382 - val_acc: 0.6105\n",
      "Epoch 1043/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.7609e-04 - acc: 1.0000 - val_loss: 3.2451 - val_acc: 0.6069\n",
      "Epoch 1044/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6686e-04 - acc: 1.0000 - val_loss: 3.2248 - val_acc: 0.6159\n",
      "Epoch 1045/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6986e-04 - acc: 1.0000 - val_loss: 3.2294 - val_acc: 0.6159\n",
      "Epoch 1046/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.4702e-04 - acc: 1.0000 - val_loss: 3.2307 - val_acc: 0.6159\n",
      "Epoch 1047/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.4392e-04 - acc: 1.0000 - val_loss: 3.2540 - val_acc: 0.6087\n",
      "Epoch 1048/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3904e-04 - acc: 1.0000 - val_loss: 3.2386 - val_acc: 0.6159\n",
      "Epoch 1049/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3538e-04 - acc: 1.0000 - val_loss: 3.2617 - val_acc: 0.6141\n",
      "Epoch 1050/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6875e-04 - acc: 1.0000 - val_loss: 3.2602 - val_acc: 0.6123\n",
      "Epoch 1051/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3440e-04 - acc: 1.0000 - val_loss: 3.2559 - val_acc: 0.6123\n",
      "Epoch 1052/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.4153e-04 - acc: 1.0000 - val_loss: 3.2577 - val_acc: 0.6141\n",
      "Epoch 1053/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.0933e-04 - acc: 1.0000 - val_loss: 3.2476 - val_acc: 0.6123\n",
      "Epoch 1054/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3862e-04 - acc: 1.0000 - val_loss: 3.2740 - val_acc: 0.6051\n",
      "Epoch 1055/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.1577e-04 - acc: 1.0000 - val_loss: 3.2821 - val_acc: 0.6105\n",
      "Epoch 1056/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3565e-04 - acc: 1.0000 - val_loss: 3.2858 - val_acc: 0.6087\n",
      "Epoch 1057/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3284e-04 - acc: 1.0000 - val_loss: 3.2601 - val_acc: 0.6123\n",
      "Epoch 1058/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.1147e-04 - acc: 1.0000 - val_loss: 3.2760 - val_acc: 0.6087\n",
      "Epoch 1059/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.0754e-04 - acc: 1.0000 - val_loss: 3.2744 - val_acc: 0.6123\n",
      "Epoch 1060/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.0819e-04 - acc: 1.0000 - val_loss: 3.2858 - val_acc: 0.6069\n",
      "Epoch 1061/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.0007e-04 - acc: 1.0000 - val_loss: 3.2898 - val_acc: 0.6087\n",
      "Epoch 1062/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.1656e-04 - acc: 1.0000 - val_loss: 3.2636 - val_acc: 0.6159\n",
      "Epoch 1063/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.9906e-04 - acc: 1.0000 - val_loss: 3.3168 - val_acc: 0.6033\n",
      "Epoch 1064/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.9145e-04 - acc: 1.0000 - val_loss: 3.2865 - val_acc: 0.6105\n",
      "Epoch 1065/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8736e-04 - acc: 1.0000 - val_loss: 3.2972 - val_acc: 0.6069\n",
      "Epoch 1066/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8214e-04 - acc: 1.0000 - val_loss: 3.3289 - val_acc: 0.6105\n",
      "Epoch 1067/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 1.9270e-04 - acc: 1.0000 - val_loss: 3.2935 - val_acc: 0.6178\n",
      "Epoch 1068/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 1.7930e-04 - acc: 1.0000 - val_loss: 3.2999 - val_acc: 0.6123\n",
      "Epoch 1069/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8494e-04 - acc: 1.0000 - val_loss: 3.3125 - val_acc: 0.6105\n",
      "Epoch 1070/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8080e-04 - acc: 1.0000 - val_loss: 3.2963 - val_acc: 0.6123\n",
      "Epoch 1071/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.7469e-04 - acc: 1.0000 - val_loss: 3.3033 - val_acc: 0.6159\n",
      "Epoch 1072/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.7704e-04 - acc: 1.0000 - val_loss: 3.3052 - val_acc: 0.6105\n",
      "Epoch 1073/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.7474e-04 - acc: 1.0000 - val_loss: 3.3066 - val_acc: 0.6141\n",
      "Epoch 1074/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.6528e-04 - acc: 1.0000 - val_loss: 3.3267 - val_acc: 0.6123\n",
      "Epoch 1075/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8252e-04 - acc: 1.0000 - val_loss: 3.3283 - val_acc: 0.6105\n",
      "Epoch 1076/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.6961e-04 - acc: 1.0000 - val_loss: 3.3349 - val_acc: 0.6123\n",
      "Epoch 1077/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.5795e-04 - acc: 1.0000 - val_loss: 3.3373 - val_acc: 0.6105\n",
      "Epoch 1078/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.5456e-04 - acc: 1.0000 - val_loss: 3.3468 - val_acc: 0.6105\n",
      "Epoch 1079/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.5058e-04 - acc: 1.0000 - val_loss: 3.3504 - val_acc: 0.6069\n",
      "Epoch 1080/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.4918e-04 - acc: 1.0000 - val_loss: 3.3472 - val_acc: 0.6069\n",
      "Epoch 1081/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.4731e-04 - acc: 1.0000 - val_loss: 3.3256 - val_acc: 0.6123\n",
      "Epoch 1082/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.4983e-04 - acc: 1.0000 - val_loss: 3.3368 - val_acc: 0.6141\n",
      "Epoch 1083/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.4544e-04 - acc: 1.0000 - val_loss: 3.3521 - val_acc: 0.6105\n",
      "Epoch 1084/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.4013e-04 - acc: 1.0000 - val_loss: 3.3595 - val_acc: 0.6069\n",
      "Epoch 1085/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.4272e-04 - acc: 1.0000 - val_loss: 3.3385 - val_acc: 0.6159\n",
      "Epoch 1086/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.3755e-04 - acc: 1.0000 - val_loss: 3.3627 - val_acc: 0.6123\n",
      "Epoch 1087/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.5420e-04 - acc: 1.0000 - val_loss: 3.3268 - val_acc: 0.6178\n",
      "Epoch 1088/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.4711e-04 - acc: 1.0000 - val_loss: 3.3549 - val_acc: 0.6159\n",
      "Epoch 1089/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.3362e-04 - acc: 1.0000 - val_loss: 3.3775 - val_acc: 0.6105\n",
      "Epoch 1090/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.2911e-04 - acc: 1.0000 - val_loss: 3.3624 - val_acc: 0.6178\n",
      "Epoch 1091/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.2949e-04 - acc: 1.0000 - val_loss: 3.3599 - val_acc: 0.6159\n",
      "Epoch 1092/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.2555e-04 - acc: 1.0000 - val_loss: 3.3743 - val_acc: 0.6069\n",
      "Epoch 1093/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.2703e-04 - acc: 1.0000 - val_loss: 3.3905 - val_acc: 0.6051\n",
      "Epoch 1094/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.2688e-04 - acc: 1.0000 - val_loss: 3.3976 - val_acc: 0.6051\n",
      "Epoch 1095/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.1998e-04 - acc: 1.0000 - val_loss: 3.3882 - val_acc: 0.6087\n",
      "Epoch 1096/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.2035e-04 - acc: 1.0000 - val_loss: 3.3948 - val_acc: 0.6105\n",
      "Epoch 1097/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.1764e-04 - acc: 1.0000 - val_loss: 3.3894 - val_acc: 0.6087\n",
      "Epoch 1098/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.1766e-04 - acc: 1.0000 - val_loss: 3.3923 - val_acc: 0.6105\n",
      "Epoch 1099/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.1242e-04 - acc: 1.0000 - val_loss: 3.4106 - val_acc: 0.6087\n",
      "Epoch 1100/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.0754e-04 - acc: 1.0000 - val_loss: 3.4063 - val_acc: 0.6141\n",
      "Epoch 1101/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.1103e-04 - acc: 1.0000 - val_loss: 3.3937 - val_acc: 0.6141\n",
      "Epoch 1102/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.0688e-04 - acc: 1.0000 - val_loss: 3.4290 - val_acc: 0.6105\n",
      "Epoch 1103/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.0234e-04 - acc: 1.0000 - val_loss: 3.4280 - val_acc: 0.6051\n",
      "Epoch 1104/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.9243e-05 - acc: 1.0000 - val_loss: 3.4047 - val_acc: 0.6159\n",
      "Epoch 1105/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.7854e-05 - acc: 1.0000 - val_loss: 3.4408 - val_acc: 0.6123\n",
      "Epoch 1106/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.0246e-04 - acc: 1.0000 - val_loss: 3.4197 - val_acc: 0.6105\n",
      "Epoch 1107/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.0145e-04 - acc: 1.0000 - val_loss: 3.4406 - val_acc: 0.6123\n",
      "Epoch 1108/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.6141e-05 - acc: 1.0000 - val_loss: 3.4341 - val_acc: 0.6051\n",
      "Epoch 1109/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.2673e-05 - acc: 1.0000 - val_loss: 3.4328 - val_acc: 0.6087\n",
      "Epoch 1110/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.4733e-05 - acc: 1.0000 - val_loss: 3.4292 - val_acc: 0.6123\n",
      "Epoch 1111/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.7743e-05 - acc: 1.0000 - val_loss: 3.4214 - val_acc: 0.6159\n",
      "Epoch 1112/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.6971e-05 - acc: 1.0000 - val_loss: 3.4440 - val_acc: 0.6123\n",
      "Epoch 1113/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 9.1573e-05 - acc: 1.0000 - val_loss: 3.4312 - val_acc: 0.6123\n",
      "Epoch 1114/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.8763e-05 - acc: 1.0000 - val_loss: 3.4486 - val_acc: 0.6105\n",
      "Epoch 1115/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.4807e-05 - acc: 1.0000 - val_loss: 3.4450 - val_acc: 0.6087\n",
      "Epoch 1116/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.5190e-05 - acc: 1.0000 - val_loss: 3.4515 - val_acc: 0.6087\n",
      "Epoch 1117/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.9809e-05 - acc: 1.0000 - val_loss: 3.4552 - val_acc: 0.6105\n",
      "Epoch 1118/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.9620e-05 - acc: 1.0000 - val_loss: 3.4844 - val_acc: 0.6123\n",
      "Epoch 1119/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 8.0665e-05 - acc: 1.0000 - val_loss: 3.4603 - val_acc: 0.6123\n",
      "Epoch 1120/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.7800e-05 - acc: 1.0000 - val_loss: 3.4792 - val_acc: 0.6087\n",
      "Epoch 1121/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.4105e-05 - acc: 1.0000 - val_loss: 3.4901 - val_acc: 0.6087\n",
      "Epoch 1122/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.7036e-05 - acc: 1.0000 - val_loss: 3.4987 - val_acc: 0.6069\n",
      "Epoch 1123/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.6188e-05 - acc: 1.0000 - val_loss: 3.4863 - val_acc: 0.6105\n",
      "Epoch 1124/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 6.9349e-05 - acc: 1.0000 - val_loss: 3.4966 - val_acc: 0.6069\n",
      "Epoch 1125/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 7.0076e-05 - acc: 1.0000 - val_loss: 3.4593 - val_acc: 0.6123\n",
      "Epoch 1126/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.8551e-05 - acc: 1.0000 - val_loss: 3.4691 - val_acc: 0.6178\n",
      "Epoch 1127/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.8061e-05 - acc: 1.0000 - val_loss: 3.4988 - val_acc: 0.6123\n",
      "Epoch 1128/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.6372e-05 - acc: 1.0000 - val_loss: 3.4510 - val_acc: 0.6196\n",
      "Epoch 1129/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.5161e-05 - acc: 1.0000 - val_loss: 3.4590 - val_acc: 0.6196\n",
      "Epoch 1130/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.6064e-05 - acc: 1.0000 - val_loss: 3.5098 - val_acc: 0.6123\n",
      "Epoch 1131/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.1985e-05 - acc: 1.0000 - val_loss: 3.5036 - val_acc: 0.6069\n",
      "Epoch 1132/1200\n",
      "1287/1287 [==============================] - 3s 3ms/step - loss: 6.2621e-05 - acc: 1.0000 - val_loss: 3.5158 - val_acc: 0.6105\n",
      "Epoch 1133/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 6.1620e-05 - acc: 1.0000 - val_loss: 3.5086 - val_acc: 0.6105\n",
      "Epoch 1134/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.2334e-05 - acc: 1.0000 - val_loss: 3.5472 - val_acc: 0.6087\n",
      "Epoch 1135/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 7.4732e-05 - acc: 1.0000 - val_loss: 3.5398 - val_acc: 0.6069\n",
      "Epoch 1136/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.8737e-05 - acc: 1.0000 - val_loss: 3.5139 - val_acc: 0.6123\n",
      "Epoch 1137/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.5328e-05 - acc: 1.0000 - val_loss: 3.5561 - val_acc: 0.6087\n",
      "Epoch 1138/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.5216e-05 - acc: 1.0000 - val_loss: 3.5606 - val_acc: 0.6069\n",
      "Epoch 1139/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.6685e-05 - acc: 1.0000 - val_loss: 3.5714 - val_acc: 0.6069\n",
      "Epoch 1140/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.9175e-05 - acc: 1.0000 - val_loss: 3.5589 - val_acc: 0.6105\n",
      "Epoch 1141/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.1824e-05 - acc: 1.0000 - val_loss: 3.5226 - val_acc: 0.6141\n",
      "Epoch 1142/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 5.3440e-05 - acc: 1.0000 - val_loss: 3.5441 - val_acc: 0.6087\n",
      "Epoch 1143/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.9932e-05 - acc: 1.0000 - val_loss: 3.5409 - val_acc: 0.6087\n",
      "Epoch 1144/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.7624e-05 - acc: 1.0000 - val_loss: 3.5346 - val_acc: 0.6159\n",
      "Epoch 1145/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.8243e-05 - acc: 1.0000 - val_loss: 3.5521 - val_acc: 0.6105\n",
      "Epoch 1146/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.8988e-05 - acc: 1.0000 - val_loss: 3.5129 - val_acc: 0.6159\n",
      "Epoch 1147/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.6032e-05 - acc: 1.0000 - val_loss: 3.5699 - val_acc: 0.6105\n",
      "Epoch 1148/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.5212e-05 - acc: 1.0000 - val_loss: 3.5694 - val_acc: 0.6087\n",
      "Epoch 1149/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.6805e-05 - acc: 1.0000 - val_loss: 3.5939 - val_acc: 0.6051\n",
      "Epoch 1150/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.4312e-05 - acc: 1.0000 - val_loss: 3.5762 - val_acc: 0.6159\n",
      "Epoch 1151/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.5784e-05 - acc: 1.0000 - val_loss: 3.5493 - val_acc: 0.6178\n",
      "Epoch 1152/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.5482e-05 - acc: 1.0000 - val_loss: 3.5688 - val_acc: 0.6087\n",
      "Epoch 1153/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.2602e-05 - acc: 1.0000 - val_loss: 3.5793 - val_acc: 0.6105\n",
      "Epoch 1154/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 6.3721e-05 - acc: 1.0000 - val_loss: 3.5182 - val_acc: 0.6159\n",
      "Epoch 1155/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 4.9435e-05 - acc: 1.0000 - val_loss: 3.5854 - val_acc: 0.6123\n",
      "Epoch 1156/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.8851e-05 - acc: 1.0000 - val_loss: 3.6024 - val_acc: 0.6105\n",
      "Epoch 1157/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.7396e-05 - acc: 1.0000 - val_loss: 3.5710 - val_acc: 0.6178\n",
      "Epoch 1158/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.6846e-05 - acc: 1.0000 - val_loss: 3.5891 - val_acc: 0.6105\n",
      "Epoch 1159/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.7327e-05 - acc: 1.0000 - val_loss: 3.5951 - val_acc: 0.6141\n",
      "Epoch 1160/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4625e-05 - acc: 1.0000 - val_loss: 3.5901 - val_acc: 0.6105\n",
      "Epoch 1161/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4710e-05 - acc: 1.0000 - val_loss: 3.6154 - val_acc: 0.6105\n",
      "Epoch 1162/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4574e-05 - acc: 1.0000 - val_loss: 3.5890 - val_acc: 0.6196\n",
      "Epoch 1163/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3989e-05 - acc: 1.0000 - val_loss: 3.5960 - val_acc: 0.6178\n",
      "Epoch 1164/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3237e-05 - acc: 1.0000 - val_loss: 3.6077 - val_acc: 0.6123\n",
      "Epoch 1165/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.4949e-05 - acc: 1.0000 - val_loss: 3.5858 - val_acc: 0.6159\n",
      "Epoch 1166/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.3696e-05 - acc: 1.0000 - val_loss: 3.5961 - val_acc: 0.6196\n",
      "Epoch 1167/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.1071e-05 - acc: 1.0000 - val_loss: 3.6387 - val_acc: 0.6087\n",
      "Epoch 1168/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.2572e-05 - acc: 1.0000 - val_loss: 3.6129 - val_acc: 0.6214\n",
      "Epoch 1169/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.0849e-05 - acc: 1.0000 - val_loss: 3.6166 - val_acc: 0.6141\n",
      "Epoch 1170/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.1062e-05 - acc: 1.0000 - val_loss: 3.6351 - val_acc: 0.6105\n",
      "Epoch 1171/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.1074e-05 - acc: 1.0000 - val_loss: 3.6740 - val_acc: 0.6087\n",
      "Epoch 1172/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 3.1944e-05 - acc: 1.0000 - val_loss: 3.5972 - val_acc: 0.6232\n",
      "Epoch 1173/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.9053e-05 - acc: 1.0000 - val_loss: 3.6378 - val_acc: 0.6123\n",
      "Epoch 1174/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6731e-05 - acc: 1.0000 - val_loss: 3.6337 - val_acc: 0.6105\n",
      "Epoch 1175/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6507e-05 - acc: 1.0000 - val_loss: 3.6392 - val_acc: 0.6069\n",
      "Epoch 1176/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.8675e-05 - acc: 1.0000 - val_loss: 3.6386 - val_acc: 0.6141\n",
      "Epoch 1177/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.5813e-05 - acc: 1.0000 - val_loss: 3.6578 - val_acc: 0.6196\n",
      "Epoch 1178/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.6021e-05 - acc: 1.0000 - val_loss: 3.6824 - val_acc: 0.6105\n",
      "Epoch 1179/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.8821e-05 - acc: 1.0000 - val_loss: 3.6367 - val_acc: 0.6141\n",
      "Epoch 1180/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.5073e-05 - acc: 1.0000 - val_loss: 3.6625 - val_acc: 0.6141\n",
      "Epoch 1181/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3840e-05 - acc: 1.0000 - val_loss: 3.6658 - val_acc: 0.6123\n",
      "Epoch 1182/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.4563e-05 - acc: 1.0000 - val_loss: 3.6476 - val_acc: 0.6178\n",
      "Epoch 1183/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3590e-05 - acc: 1.0000 - val_loss: 3.6539 - val_acc: 0.6087\n",
      "Epoch 1184/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.2991e-05 - acc: 1.0000 - val_loss: 3.6615 - val_acc: 0.6105\n",
      "Epoch 1185/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.4057e-05 - acc: 1.0000 - val_loss: 3.6333 - val_acc: 0.6178\n",
      "Epoch 1186/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.3227e-05 - acc: 1.0000 - val_loss: 3.6554 - val_acc: 0.6196\n",
      "Epoch 1187/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.2809e-05 - acc: 1.0000 - val_loss: 3.6649 - val_acc: 0.6105\n",
      "Epoch 1188/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.2258e-05 - acc: 1.0000 - val_loss: 3.6439 - val_acc: 0.6232\n",
      "Epoch 1189/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.1340e-05 - acc: 1.0000 - val_loss: 3.6584 - val_acc: 0.6232\n",
      "Epoch 1190/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.0473e-05 - acc: 1.0000 - val_loss: 3.6947 - val_acc: 0.6159\n",
      "Epoch 1191/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 2.1021e-05 - acc: 1.0000 - val_loss: 3.6819 - val_acc: 0.6087\n",
      "Epoch 1192/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.9044e-05 - acc: 1.0000 - val_loss: 3.6941 - val_acc: 0.6178\n",
      "Epoch 1193/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.9250e-05 - acc: 1.0000 - val_loss: 3.6988 - val_acc: 0.6159\n",
      "Epoch 1194/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8551e-05 - acc: 1.0000 - val_loss: 3.7017 - val_acc: 0.6178\n",
      "Epoch 1195/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8860e-05 - acc: 1.0000 - val_loss: 3.6925 - val_acc: 0.6105\n",
      "Epoch 1196/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8820e-05 - acc: 1.0000 - val_loss: 3.6835 - val_acc: 0.6159\n",
      "Epoch 1197/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.8027e-05 - acc: 1.0000 - val_loss: 3.6997 - val_acc: 0.6141\n",
      "Epoch 1198/1200\n",
      "1287/1287 [==============================] - 4s 3ms/step - loss: 1.7942e-05 - acc: 1.0000 - val_loss: 3.6686 - val_acc: 0.6286\n",
      "Epoch 1199/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.7709e-05 - acc: 1.0000 - val_loss: 3.7209 - val_acc: 0.6178\n",
      "Epoch 1200/1200\n",
      "1287/1287 [==============================] - 3s 2ms/step - loss: 1.6350e-05 - acc: 1.0000 - val_loss: 3.7202 - val_acc: 0.6159\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.00001)\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.00001)\n",
    "\n",
    "model1.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_9 = model1.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=1200,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_model_1 = model1.save('../models/grayscale_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(filters=10, kernel_size=10, strides=2, activation='relu',\n",
    "                        input_shape=(256, 256,  1)))\n",
    "model2.add(layers.AveragePooling2D((10, 10)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=5, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((6, 6)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=40, kernel_size=3, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=80, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=160, kernel_size=1, strides=2,activation='relu'))\n",
    "# model.add(layers.AveragePooling2D((1, 1)))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "model2.add(layers.Dense(100, activation='relu'))\n",
    "model2.add(layers.Dense(200, activation='relu'))\n",
    "model2.add(layers.Dense(200, activation='relu'))\n",
    "model2.add(layers.Dense(200, activation='relu'))\n",
    "model2.add(layers.Dense(200, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1264 samples, validate on 542 samples\n",
      "Epoch 1/700\n",
      "1264/1264 [==============================] - 12s 9ms/step - loss: 0.7637 - accuracy: 0.5008 - val_loss: 0.7500 - val_accuracy: 0.4114\n",
      "Epoch 2/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.8570 - accuracy: 0.4937 - val_loss: 0.8064 - val_accuracy: 0.4133\n",
      "Epoch 3/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.7265 - accuracy: 0.4818 - val_loss: 0.6783 - val_accuracy: 0.5867\n",
      "Epoch 4/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.7069 - accuracy: 0.5198 - val_loss: 0.6812 - val_accuracy: 0.5867\n",
      "Epoch 5/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.7089 - accuracy: 0.5451 - val_loss: 0.6928 - val_accuracy: 0.5867\n",
      "Epoch 6/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6953 - accuracy: 0.5119 - val_loss: 0.6737 - val_accuracy: 0.5867\n",
      "Epoch 7/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6945 - accuracy: 0.5451 - val_loss: 0.6729 - val_accuracy: 0.5867\n",
      "Epoch 8/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6917 - accuracy: 0.5451 - val_loss: 0.6885 - val_accuracy: 0.5867\n",
      "Epoch 9/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6905 - accuracy: 0.5451 - val_loss: 0.6812 - val_accuracy: 0.5867\n",
      "Epoch 10/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6881 - accuracy: 0.5451 - val_loss: 0.6771 - val_accuracy: 0.5867\n",
      "Epoch 11/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6872 - accuracy: 0.5451 - val_loss: 0.6756 - val_accuracy: 0.5867\n",
      "Epoch 12/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6869 - accuracy: 0.5451 - val_loss: 0.6745 - val_accuracy: 0.5867\n",
      "Epoch 13/700\n",
      "1264/1264 [==============================] - 11s 8ms/step - loss: 0.6863 - accuracy: 0.5451 - val_loss: 0.6736 - val_accuracy: 0.5867\n",
      "Epoch 14/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6860 - accuracy: 0.5451 - val_loss: 0.6735 - val_accuracy: 0.5867\n",
      "Epoch 15/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6858 - accuracy: 0.5451 - val_loss: 0.6758 - val_accuracy: 0.5867\n",
      "Epoch 16/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6851 - accuracy: 0.5506 - val_loss: 0.6773 - val_accuracy: 0.5923\n",
      "Epoch 17/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6848 - accuracy: 0.5498 - val_loss: 0.6902 - val_accuracy: 0.4668\n",
      "Epoch 18/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6835 - accuracy: 0.5301 - val_loss: 0.6650 - val_accuracy: 0.5867\n",
      "Epoch 19/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6900 - accuracy: 0.5451 - val_loss: 0.6712 - val_accuracy: 0.5867\n",
      "Epoch 20/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6835 - accuracy: 0.5491 - val_loss: 0.6835 - val_accuracy: 0.5849\n",
      "Epoch 21/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6849 - accuracy: 0.5641 - val_loss: 0.6721 - val_accuracy: 0.5867\n",
      "Epoch 22/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6824 - accuracy: 0.5451 - val_loss: 0.6624 - val_accuracy: 0.5867\n",
      "Epoch 23/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6819 - accuracy: 0.5451 - val_loss: 0.6658 - val_accuracy: 0.5867\n",
      "Epoch 24/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6791 - accuracy: 0.5451 - val_loss: 0.6688 - val_accuracy: 0.5867\n",
      "Epoch 25/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6792 - accuracy: 0.5451 - val_loss: 0.6680 - val_accuracy: 0.5867\n",
      "Epoch 26/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6774 - accuracy: 0.5419 - val_loss: 0.6664 - val_accuracy: 0.5849\n",
      "Epoch 27/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6750 - accuracy: 0.5443 - val_loss: 0.6562 - val_accuracy: 0.5867\n",
      "Epoch 28/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6748 - accuracy: 0.5451 - val_loss: 0.6569 - val_accuracy: 0.5793\n",
      "Epoch 29/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6711 - accuracy: 0.5419 - val_loss: 0.6658 - val_accuracy: 0.5756\n",
      "Epoch 30/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6721 - accuracy: 0.5301 - val_loss: 0.6536 - val_accuracy: 0.5683\n",
      "Epoch 31/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6687 - accuracy: 0.5277 - val_loss: 0.6534 - val_accuracy: 0.5738\n",
      "Epoch 32/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6690 - accuracy: 0.5427 - val_loss: 0.6535 - val_accuracy: 0.5720\n",
      "Epoch 33/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6677 - accuracy: 0.5332 - val_loss: 0.6458 - val_accuracy: 0.5664\n",
      "Epoch 34/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6631 - accuracy: 0.5530 - val_loss: 0.6573 - val_accuracy: 0.6089\n",
      "Epoch 35/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6629 - accuracy: 0.5657 - val_loss: 0.6467 - val_accuracy: 0.5904\n",
      "Epoch 36/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6608 - accuracy: 0.5506 - val_loss: 0.6393 - val_accuracy: 0.5756\n",
      "Epoch 37/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6611 - accuracy: 0.5356 - val_loss: 0.6420 - val_accuracy: 0.6070\n",
      "Epoch 38/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6580 - accuracy: 0.5823 - val_loss: 0.6461 - val_accuracy: 0.6292\n",
      "Epoch 39/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6548 - accuracy: 0.5815 - val_loss: 0.6320 - val_accuracy: 0.5812\n",
      "Epoch 40/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6533 - accuracy: 0.5680 - val_loss: 0.6608 - val_accuracy: 0.5074\n",
      "Epoch 41/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6630 - accuracy: 0.5229 - val_loss: 0.6316 - val_accuracy: 0.6070\n",
      "Epoch 42/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6544 - accuracy: 0.5609 - val_loss: 0.6480 - val_accuracy: 0.6458\n",
      "Epoch 43/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6613 - accuracy: 0.5593 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
      "Epoch 44/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6547 - accuracy: 0.5870 - val_loss: 0.6272 - val_accuracy: 0.5923\n",
      "Epoch 45/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6536 - accuracy: 0.5601 - val_loss: 0.6544 - val_accuracy: 0.5185\n",
      "Epoch 46/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6585 - accuracy: 0.5356 - val_loss: 0.6390 - val_accuracy: 0.6605\n",
      "Epoch 47/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6482 - accuracy: 0.6092 - val_loss: 0.6256 - val_accuracy: 0.6033\n",
      "Epoch 48/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6538 - accuracy: 0.5744 - val_loss: 0.6565 - val_accuracy: 0.5074\n",
      "Epoch 49/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6577 - accuracy: 0.5285 - val_loss: 0.6343 - val_accuracy: 0.6310\n",
      "Epoch 50/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6455 - accuracy: 0.6028 - val_loss: 0.6209 - val_accuracy: 0.6365\n",
      "Epoch 51/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6547 - accuracy: 0.5894 - val_loss: 0.6217 - val_accuracy: 0.6421\n",
      "Epoch 52/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6515 - accuracy: 0.5902 - val_loss: 0.6441 - val_accuracy: 0.6273\n",
      "Epoch 53/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6545 - accuracy: 0.5578 - val_loss: 0.6458 - val_accuracy: 0.6328\n",
      "Epoch 54/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6469 - accuracy: 0.5949 - val_loss: 0.6224 - val_accuracy: 0.6089\n",
      "Epoch 55/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6504 - accuracy: 0.5831 - val_loss: 0.6422 - val_accuracy: 0.6513\n",
      "Epoch 56/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6484 - accuracy: 0.6052 - val_loss: 0.6227 - val_accuracy: 0.6568\n",
      "Epoch 57/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6417 - accuracy: 0.6218 - val_loss: 0.6294 - val_accuracy: 0.6624\n",
      "Epoch 58/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6418 - accuracy: 0.6321 - val_loss: 0.6174 - val_accuracy: 0.6531\n",
      "Epoch 59/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6445 - accuracy: 0.6100 - val_loss: 0.6251 - val_accuracy: 0.6587\n",
      "Epoch 60/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6388 - accuracy: 0.6266 - val_loss: 0.6179 - val_accuracy: 0.6845\n",
      "Epoch 61/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6370 - accuracy: 0.6305 - val_loss: 0.6245 - val_accuracy: 0.6661\n",
      "Epoch 62/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6396 - accuracy: 0.6290 - val_loss: 0.6505 - val_accuracy: 0.5535\n",
      "Epoch 63/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6445 - accuracy: 0.5949 - val_loss: 0.6112 - val_accuracy: 0.6716\n",
      "Epoch 64/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6511 - accuracy: 0.5775 - val_loss: 0.6266 - val_accuracy: 0.6568\n",
      "Epoch 65/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6605 - accuracy: 0.6139 - val_loss: 0.6431 - val_accuracy: 0.6199\n",
      "Epoch 66/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6533 - accuracy: 0.5641 - val_loss: 0.6350 - val_accuracy: 0.6273\n",
      "Epoch 67/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6402 - accuracy: 0.6100 - val_loss: 0.6165 - val_accuracy: 0.6661\n",
      "Epoch 68/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6480 - accuracy: 0.6171 - val_loss: 0.6442 - val_accuracy: 0.6347\n",
      "Epoch 69/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6394 - accuracy: 0.6171 - val_loss: 0.6189 - val_accuracy: 0.6292\n",
      "Epoch 70/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6470 - accuracy: 0.6116 - val_loss: 0.6441 - val_accuracy: 0.6070\n",
      "Epoch 71/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6444 - accuracy: 0.5791 - val_loss: 0.6155 - val_accuracy: 0.6753\n",
      "Epoch 72/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6374 - accuracy: 0.6258 - val_loss: 0.6184 - val_accuracy: 0.6716\n",
      "Epoch 73/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6322 - accuracy: 0.6353 - val_loss: 0.6297 - val_accuracy: 0.6605\n",
      "Epoch 74/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6337 - accuracy: 0.6361 - val_loss: 0.6114 - val_accuracy: 0.6661\n",
      "Epoch 75/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6389 - accuracy: 0.6155 - val_loss: 0.6124 - val_accuracy: 0.6734\n",
      "Epoch 76/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6330 - accuracy: 0.6266 - val_loss: 0.6166 - val_accuracy: 0.6661\n",
      "Epoch 77/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6350 - accuracy: 0.6147 - val_loss: 0.6085 - val_accuracy: 0.6771\n",
      "Epoch 78/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6450 - accuracy: 0.6210 - val_loss: 0.6454 - val_accuracy: 0.5830\n",
      "Epoch 79/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6412 - accuracy: 0.5854 - val_loss: 0.6088 - val_accuracy: 0.6679\n",
      "Epoch 80/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6324 - accuracy: 0.6226 - val_loss: 0.6157 - val_accuracy: 0.6642\n",
      "Epoch 81/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6278 - accuracy: 0.6321 - val_loss: 0.6126 - val_accuracy: 0.6624\n",
      "Epoch 82/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6240 - accuracy: 0.6313 - val_loss: 0.6155 - val_accuracy: 0.6624\n",
      "Epoch 83/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6218 - accuracy: 0.6353 - val_loss: 0.6059 - val_accuracy: 0.6882\n",
      "Epoch 84/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6202 - accuracy: 0.6432 - val_loss: 0.6095 - val_accuracy: 0.6661\n",
      "Epoch 85/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6179 - accuracy: 0.6440 - val_loss: 0.6179 - val_accuracy: 0.6568\n",
      "Epoch 86/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6170 - accuracy: 0.6440 - val_loss: 0.6007 - val_accuracy: 0.6753\n",
      "Epoch 87/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6179 - accuracy: 0.6377 - val_loss: 0.6014 - val_accuracy: 0.6900\n",
      "Epoch 88/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6241 - accuracy: 0.6345 - val_loss: 0.6140 - val_accuracy: 0.6624\n",
      "Epoch 89/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6450 - accuracy: 0.6242 - val_loss: 0.6850 - val_accuracy: 0.4834\n",
      "Epoch 90/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6552 - accuracy: 0.5641 - val_loss: 0.6018 - val_accuracy: 0.6900\n",
      "Epoch 91/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6165 - accuracy: 0.6353 - val_loss: 0.6234 - val_accuracy: 0.6605\n",
      "Epoch 92/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6221 - accuracy: 0.6329 - val_loss: 0.6092 - val_accuracy: 0.6771\n",
      "Epoch 93/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6190 - accuracy: 0.6384 - val_loss: 0.6130 - val_accuracy: 0.6753\n",
      "Epoch 94/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6166 - accuracy: 0.6590 - val_loss: 0.6161 - val_accuracy: 0.6734\n",
      "Epoch 95/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6163 - accuracy: 0.6424 - val_loss: 0.6151 - val_accuracy: 0.6642\n",
      "Epoch 96/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6167 - accuracy: 0.6630 - val_loss: 0.6101 - val_accuracy: 0.6790\n",
      "Epoch 97/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6120 - accuracy: 0.6574 - val_loss: 0.6059 - val_accuracy: 0.6827\n",
      "Epoch 98/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6124 - accuracy: 0.6511 - val_loss: 0.6059 - val_accuracy: 0.6790\n",
      "Epoch 99/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6108 - accuracy: 0.6622 - val_loss: 0.6827 - val_accuracy: 0.4982\n",
      "Epoch 100/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6515 - accuracy: 0.5759 - val_loss: 0.6027 - val_accuracy: 0.6882\n",
      "Epoch 101/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6078 - accuracy: 0.6535 - val_loss: 0.6169 - val_accuracy: 0.6771\n",
      "Epoch 102/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6104 - accuracy: 0.6543 - val_loss: 0.6092 - val_accuracy: 0.6716\n",
      "Epoch 103/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6093 - accuracy: 0.6448 - val_loss: 0.6008 - val_accuracy: 0.6808\n",
      "Epoch 104/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6121 - accuracy: 0.6614 - val_loss: 0.6042 - val_accuracy: 0.6845\n",
      "Epoch 105/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6031 - accuracy: 0.6622 - val_loss: 0.6041 - val_accuracy: 0.6808\n",
      "Epoch 106/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6037 - accuracy: 0.6519 - val_loss: 0.6029 - val_accuracy: 0.6845\n",
      "Epoch 107/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6039 - accuracy: 0.6812 - val_loss: 0.6995 - val_accuracy: 0.4963\n",
      "Epoch 108/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6408 - accuracy: 0.5870 - val_loss: 0.6181 - val_accuracy: 0.6679\n",
      "Epoch 109/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6227 - accuracy: 0.6392 - val_loss: 0.6233 - val_accuracy: 0.6550\n",
      "Epoch 110/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6228 - accuracy: 0.6456 - val_loss: 0.6239 - val_accuracy: 0.6568\n",
      "Epoch 111/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6263 - accuracy: 0.5973 - val_loss: 0.6148 - val_accuracy: 0.6642\n",
      "Epoch 112/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6272 - accuracy: 0.6479 - val_loss: 0.6223 - val_accuracy: 0.6568\n",
      "Epoch 113/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6137 - accuracy: 0.6345 - val_loss: 0.6050 - val_accuracy: 0.6919\n",
      "Epoch 114/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6115 - accuracy: 0.6646 - val_loss: 0.6299 - val_accuracy: 0.6402\n",
      "Epoch 115/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6151 - accuracy: 0.6345 - val_loss: 0.6095 - val_accuracy: 0.6790\n",
      "Epoch 116/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6137 - accuracy: 0.6709 - val_loss: 0.6236 - val_accuracy: 0.6624\n",
      "Epoch 117/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6083 - accuracy: 0.6503 - val_loss: 0.6069 - val_accuracy: 0.6771\n",
      "Epoch 118/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6004 - accuracy: 0.6780 - val_loss: 0.6129 - val_accuracy: 0.6771\n",
      "Epoch 119/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5973 - accuracy: 0.6622 - val_loss: 0.6017 - val_accuracy: 0.6845\n",
      "Epoch 120/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5966 - accuracy: 0.6780 - val_loss: 0.6089 - val_accuracy: 0.6845\n",
      "Epoch 121/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5971 - accuracy: 0.6661 - val_loss: 0.6367 - val_accuracy: 0.6328\n",
      "Epoch 122/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5977 - accuracy: 0.6669 - val_loss: 0.6050 - val_accuracy: 0.6937\n",
      "Epoch 123/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5875 - accuracy: 0.6661 - val_loss: 0.6057 - val_accuracy: 0.6937\n",
      "Epoch 124/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5853 - accuracy: 0.6764 - val_loss: 0.6158 - val_accuracy: 0.6845\n",
      "Epoch 125/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5847 - accuracy: 0.6820 - val_loss: 0.6515 - val_accuracy: 0.6421\n",
      "Epoch 126/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5975 - accuracy: 0.6804 - val_loss: 0.6715 - val_accuracy: 0.6015\n",
      "Epoch 127/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6099 - accuracy: 0.6456 - val_loss: 0.6222 - val_accuracy: 0.6568\n",
      "Epoch 128/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6023 - accuracy: 0.6274 - val_loss: 0.6158 - val_accuracy: 0.6697\n",
      "Epoch 129/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5845 - accuracy: 0.6780 - val_loss: 0.6192 - val_accuracy: 0.6827\n",
      "Epoch 130/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5813 - accuracy: 0.6820 - val_loss: 0.6300 - val_accuracy: 0.6734\n",
      "Epoch 131/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5765 - accuracy: 0.6796 - val_loss: 0.6344 - val_accuracy: 0.6679\n",
      "Epoch 132/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5778 - accuracy: 0.6756 - val_loss: 0.6153 - val_accuracy: 0.6863\n",
      "Epoch 133/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5863 - accuracy: 0.6788 - val_loss: 0.6466 - val_accuracy: 0.6734\n",
      "Epoch 134/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5839 - accuracy: 0.6717 - val_loss: 0.6383 - val_accuracy: 0.6679\n",
      "Epoch 135/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5776 - accuracy: 0.6820 - val_loss: 0.6225 - val_accuracy: 0.6863\n",
      "Epoch 136/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5664 - accuracy: 0.7017 - val_loss: 0.6673 - val_accuracy: 0.6365\n",
      "Epoch 137/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5935 - accuracy: 0.6646 - val_loss: 0.6249 - val_accuracy: 0.6882\n",
      "Epoch 138/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5713 - accuracy: 0.6851 - val_loss: 0.6225 - val_accuracy: 0.6845\n",
      "Epoch 139/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5819 - accuracy: 0.6851 - val_loss: 0.6472 - val_accuracy: 0.6661\n",
      "Epoch 140/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5872 - accuracy: 0.6820 - val_loss: 0.6912 - val_accuracy: 0.5406\n",
      "Epoch 141/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5803 - accuracy: 0.6614 - val_loss: 0.6312 - val_accuracy: 0.6900\n",
      "Epoch 142/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5718 - accuracy: 0.6828 - val_loss: 0.6391 - val_accuracy: 0.6716\n",
      "Epoch 143/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5613 - accuracy: 0.7017 - val_loss: 0.6466 - val_accuracy: 0.6771\n",
      "Epoch 144/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5548 - accuracy: 0.6978 - val_loss: 0.6497 - val_accuracy: 0.6790\n",
      "Epoch 145/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5474 - accuracy: 0.7002 - val_loss: 0.6732 - val_accuracy: 0.6808\n",
      "Epoch 146/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5445 - accuracy: 0.7057 - val_loss: 0.6671 - val_accuracy: 0.6790\n",
      "Epoch 147/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5372 - accuracy: 0.7057 - val_loss: 0.6830 - val_accuracy: 0.6827\n",
      "Epoch 148/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5504 - accuracy: 0.7104 - val_loss: 0.6455 - val_accuracy: 0.6900\n",
      "Epoch 149/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5602 - accuracy: 0.6946 - val_loss: 0.6513 - val_accuracy: 0.6771\n",
      "Epoch 150/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5542 - accuracy: 0.7057 - val_loss: 0.6576 - val_accuracy: 0.6753\n",
      "Epoch 151/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5768 - accuracy: 0.6709 - val_loss: 0.6985 - val_accuracy: 0.6679\n",
      "Epoch 152/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5647 - accuracy: 0.6986 - val_loss: 0.6772 - val_accuracy: 0.6421\n",
      "Epoch 153/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5648 - accuracy: 0.6891 - val_loss: 0.6492 - val_accuracy: 0.6587\n",
      "Epoch 154/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5767 - accuracy: 0.6978 - val_loss: 0.6578 - val_accuracy: 0.6439\n",
      "Epoch 155/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5656 - accuracy: 0.6843 - val_loss: 0.6147 - val_accuracy: 0.6753\n",
      "Epoch 156/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5599 - accuracy: 0.6907 - val_loss: 0.6369 - val_accuracy: 0.6771\n",
      "Epoch 157/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5490 - accuracy: 0.7041 - val_loss: 0.6636 - val_accuracy: 0.6568\n",
      "Epoch 158/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5431 - accuracy: 0.7089 - val_loss: 0.6557 - val_accuracy: 0.6808\n",
      "Epoch 159/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5691 - accuracy: 0.6938 - val_loss: 0.6759 - val_accuracy: 0.6605\n",
      "Epoch 160/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5720 - accuracy: 0.6946 - val_loss: 0.7499 - val_accuracy: 0.5277\n",
      "Epoch 161/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5694 - accuracy: 0.6685 - val_loss: 0.6391 - val_accuracy: 0.6753\n",
      "Epoch 162/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5544 - accuracy: 0.7017 - val_loss: 0.7067 - val_accuracy: 0.6402\n",
      "Epoch 163/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5536 - accuracy: 0.6883 - val_loss: 0.6418 - val_accuracy: 0.6790\n",
      "Epoch 164/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5532 - accuracy: 0.6970 - val_loss: 0.6480 - val_accuracy: 0.6771\n",
      "Epoch 165/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5672 - accuracy: 0.6986 - val_loss: 0.7222 - val_accuracy: 0.6089\n",
      "Epoch 166/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5510 - accuracy: 0.6820 - val_loss: 0.6358 - val_accuracy: 0.6863\n",
      "Epoch 167/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5413 - accuracy: 0.7128 - val_loss: 0.6667 - val_accuracy: 0.6753\n",
      "Epoch 168/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5274 - accuracy: 0.7160 - val_loss: 0.6585 - val_accuracy: 0.6790\n",
      "Epoch 169/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5243 - accuracy: 0.7223 - val_loss: 0.6746 - val_accuracy: 0.6642\n",
      "Epoch 170/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5187 - accuracy: 0.7286 - val_loss: 0.6784 - val_accuracy: 0.6845\n",
      "Epoch 171/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5190 - accuracy: 0.7184 - val_loss: 0.8144 - val_accuracy: 0.6476\n",
      "Epoch 172/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5206 - accuracy: 0.7239 - val_loss: 0.7552 - val_accuracy: 0.6587\n",
      "Epoch 173/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5403 - accuracy: 0.7120 - val_loss: 0.6524 - val_accuracy: 0.6771\n",
      "Epoch 174/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5874 - accuracy: 0.6859 - val_loss: 0.6395 - val_accuracy: 0.6790\n",
      "Epoch 175/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5474 - accuracy: 0.7057 - val_loss: 0.7217 - val_accuracy: 0.5941\n",
      "Epoch 176/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5406 - accuracy: 0.7017 - val_loss: 0.6466 - val_accuracy: 0.6771\n",
      "Epoch 177/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5300 - accuracy: 0.7231 - val_loss: 0.6902 - val_accuracy: 0.6808\n",
      "Epoch 178/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5281 - accuracy: 0.7239 - val_loss: 0.6712 - val_accuracy: 0.6642\n",
      "Epoch 179/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5186 - accuracy: 0.7223 - val_loss: 0.6788 - val_accuracy: 0.6845\n",
      "Epoch 180/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5214 - accuracy: 0.7207 - val_loss: 0.7854 - val_accuracy: 0.6531\n",
      "Epoch 181/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5323 - accuracy: 0.7112 - val_loss: 0.6758 - val_accuracy: 0.6808\n",
      "Epoch 182/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5453 - accuracy: 0.6986 - val_loss: 0.6865 - val_accuracy: 0.6624\n",
      "Epoch 183/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5501 - accuracy: 0.7017 - val_loss: 0.6754 - val_accuracy: 0.6679\n",
      "Epoch 184/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5277 - accuracy: 0.7231 - val_loss: 0.6704 - val_accuracy: 0.6679\n",
      "Epoch 185/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5285 - accuracy: 0.7065 - val_loss: 0.6870 - val_accuracy: 0.6642\n",
      "Epoch 186/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5132 - accuracy: 0.7176 - val_loss: 0.7309 - val_accuracy: 0.6642\n",
      "Epoch 187/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5163 - accuracy: 0.7223 - val_loss: 0.7088 - val_accuracy: 0.6716\n",
      "Epoch 188/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5013 - accuracy: 0.7263 - val_loss: 0.7508 - val_accuracy: 0.6605\n",
      "Epoch 189/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5056 - accuracy: 0.7271 - val_loss: 0.8359 - val_accuracy: 0.6513\n",
      "Epoch 190/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4912 - accuracy: 0.7413 - val_loss: 0.7399 - val_accuracy: 0.6716\n",
      "Epoch 191/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.7443 - val_accuracy: 0.6661\n",
      "Epoch 192/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5052 - accuracy: 0.7350 - val_loss: 0.8872 - val_accuracy: 0.6310\n",
      "Epoch 193/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5196 - accuracy: 0.7302 - val_loss: 0.7931 - val_accuracy: 0.6605\n",
      "Epoch 194/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5085 - accuracy: 0.7223 - val_loss: 0.7178 - val_accuracy: 0.6734\n",
      "Epoch 195/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5195 - accuracy: 0.7120 - val_loss: 0.7047 - val_accuracy: 0.6642\n",
      "Epoch 196/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5706 - accuracy: 0.7009 - val_loss: 0.8162 - val_accuracy: 0.6347\n",
      "Epoch 197/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5637 - accuracy: 0.6709 - val_loss: 0.6787 - val_accuracy: 0.6421\n",
      "Epoch 198/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6073 - accuracy: 0.6527 - val_loss: 0.6741 - val_accuracy: 0.6531\n",
      "Epoch 199/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5560 - accuracy: 0.6741 - val_loss: 0.7049 - val_accuracy: 0.6550\n",
      "Epoch 200/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5450 - accuracy: 0.7144 - val_loss: 0.6472 - val_accuracy: 0.6863\n",
      "Epoch 201/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5297 - accuracy: 0.7176 - val_loss: 0.7009 - val_accuracy: 0.6494\n",
      "Epoch 202/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5251 - accuracy: 0.7239 - val_loss: 0.6594 - val_accuracy: 0.6642\n",
      "Epoch 203/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5242 - accuracy: 0.7097 - val_loss: 0.6720 - val_accuracy: 0.6458\n",
      "Epoch 204/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5198 - accuracy: 0.7184 - val_loss: 0.7783 - val_accuracy: 0.6421\n",
      "Epoch 205/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5133 - accuracy: 0.7247 - val_loss: 0.6909 - val_accuracy: 0.6642\n",
      "Epoch 206/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5141 - accuracy: 0.7168 - val_loss: 0.7577 - val_accuracy: 0.6531\n",
      "Epoch 207/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5046 - accuracy: 0.7263 - val_loss: 0.7121 - val_accuracy: 0.6753\n",
      "Epoch 208/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5134 - accuracy: 0.7231 - val_loss: 0.6929 - val_accuracy: 0.6734\n",
      "Epoch 209/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5086 - accuracy: 0.7358 - val_loss: 0.7448 - val_accuracy: 0.6624\n",
      "Epoch 210/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4941 - accuracy: 0.7318 - val_loss: 0.7798 - val_accuracy: 0.6734\n",
      "Epoch 211/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4884 - accuracy: 0.7358 - val_loss: 0.8171 - val_accuracy: 0.6494\n",
      "Epoch 212/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4828 - accuracy: 0.7421 - val_loss: 0.8181 - val_accuracy: 0.6494\n",
      "Epoch 213/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4829 - accuracy: 0.7302 - val_loss: 0.7678 - val_accuracy: 0.6624\n",
      "Epoch 214/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5333 - accuracy: 0.7247 - val_loss: 0.7649 - val_accuracy: 0.6661\n",
      "Epoch 215/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4958 - accuracy: 0.7437 - val_loss: 0.7104 - val_accuracy: 0.6697\n",
      "Epoch 216/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5131 - accuracy: 0.7160 - val_loss: 0.7662 - val_accuracy: 0.6107\n",
      "Epoch 217/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5564 - accuracy: 0.6875 - val_loss: 0.6654 - val_accuracy: 0.6753\n",
      "Epoch 218/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5313 - accuracy: 0.7065 - val_loss: 0.7187 - val_accuracy: 0.6697\n",
      "Epoch 219/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5254 - accuracy: 0.7191 - val_loss: 0.7546 - val_accuracy: 0.6476\n",
      "Epoch 220/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5461 - accuracy: 0.7025 - val_loss: 0.7541 - val_accuracy: 0.6236\n",
      "Epoch 221/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5951 - accuracy: 0.6843 - val_loss: 0.8535 - val_accuracy: 0.5074\n",
      "Epoch 222/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5607 - accuracy: 0.6717 - val_loss: 0.7046 - val_accuracy: 0.6697\n",
      "Epoch 223/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5530 - accuracy: 0.6978 - val_loss: 0.7581 - val_accuracy: 0.5738\n",
      "Epoch 224/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5390 - accuracy: 0.6559 - val_loss: 0.7108 - val_accuracy: 0.6384\n",
      "Epoch 225/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5176 - accuracy: 0.7184 - val_loss: 0.6982 - val_accuracy: 0.6734\n",
      "Epoch 226/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5131 - accuracy: 0.7302 - val_loss: 0.8602 - val_accuracy: 0.6384\n",
      "Epoch 227/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5079 - accuracy: 0.7207 - val_loss: 0.7055 - val_accuracy: 0.6587\n",
      "Epoch 228/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5146 - accuracy: 0.7302 - val_loss: 0.8659 - val_accuracy: 0.6365\n",
      "Epoch 229/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5024 - accuracy: 0.7239 - val_loss: 0.6879 - val_accuracy: 0.6771\n",
      "Epoch 230/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5067 - accuracy: 0.7294 - val_loss: 0.7224 - val_accuracy: 0.6531\n",
      "Epoch 231/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4916 - accuracy: 0.7278 - val_loss: 0.7292 - val_accuracy: 0.6790\n",
      "Epoch 232/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4781 - accuracy: 0.7445 - val_loss: 0.9377 - val_accuracy: 0.6421\n",
      "Epoch 233/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4816 - accuracy: 0.7429 - val_loss: 0.7298 - val_accuracy: 0.6642\n",
      "Epoch 234/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4875 - accuracy: 0.7500 - val_loss: 0.7476 - val_accuracy: 0.6531\n",
      "Epoch 235/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4744 - accuracy: 0.7460 - val_loss: 0.8466 - val_accuracy: 0.6568\n",
      "Epoch 236/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4738 - accuracy: 0.7373 - val_loss: 0.7346 - val_accuracy: 0.6661\n",
      "Epoch 237/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4687 - accuracy: 0.7476 - val_loss: 0.7638 - val_accuracy: 0.6328\n",
      "Epoch 238/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4655 - accuracy: 0.7405 - val_loss: 0.9091 - val_accuracy: 0.6347\n",
      "Epoch 239/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4586 - accuracy: 0.7484 - val_loss: 0.7730 - val_accuracy: 0.6716\n",
      "Epoch 240/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4769 - accuracy: 0.7421 - val_loss: 0.7932 - val_accuracy: 0.6605\n",
      "Epoch 241/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4855 - accuracy: 0.7453 - val_loss: 1.0216 - val_accuracy: 0.6384\n",
      "Epoch 242/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4873 - accuracy: 0.7350 - val_loss: 0.7272 - val_accuracy: 0.6679\n",
      "Epoch 243/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4737 - accuracy: 0.7421 - val_loss: 0.7783 - val_accuracy: 0.6421\n",
      "Epoch 244/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4704 - accuracy: 0.7540 - val_loss: 0.8237 - val_accuracy: 0.6439\n",
      "Epoch 245/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4587 - accuracy: 0.7524 - val_loss: 0.9143 - val_accuracy: 0.6587\n",
      "Epoch 246/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4534 - accuracy: 0.7674 - val_loss: 0.8402 - val_accuracy: 0.6550\n",
      "Epoch 247/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4553 - accuracy: 0.7650 - val_loss: 0.8247 - val_accuracy: 0.6624\n",
      "Epoch 248/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4550 - accuracy: 0.7674 - val_loss: 1.0106 - val_accuracy: 0.6624\n",
      "Epoch 249/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4844 - accuracy: 0.7445 - val_loss: 1.1095 - val_accuracy: 0.5793\n",
      "Epoch 250/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5950 - accuracy: 0.7073 - val_loss: 0.8427 - val_accuracy: 0.6494\n",
      "Epoch 251/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4983 - accuracy: 0.7334 - val_loss: 0.7126 - val_accuracy: 0.6661\n",
      "Epoch 252/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4989 - accuracy: 0.7286 - val_loss: 0.6855 - val_accuracy: 0.6697\n",
      "Epoch 253/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5055 - accuracy: 0.7215 - val_loss: 0.7346 - val_accuracy: 0.6384\n",
      "Epoch 254/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4812 - accuracy: 0.7366 - val_loss: 0.8139 - val_accuracy: 0.6531\n",
      "Epoch 255/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4764 - accuracy: 0.7508 - val_loss: 0.7559 - val_accuracy: 0.6328\n",
      "Epoch 256/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4646 - accuracy: 0.7524 - val_loss: 0.7532 - val_accuracy: 0.6568\n",
      "Epoch 257/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4972 - accuracy: 0.7334 - val_loss: 0.6954 - val_accuracy: 0.6476\n",
      "Epoch 258/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5205 - accuracy: 0.7199 - val_loss: 0.6768 - val_accuracy: 0.6697\n",
      "Epoch 259/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5015 - accuracy: 0.7326 - val_loss: 0.7030 - val_accuracy: 0.6679\n",
      "Epoch 260/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4874 - accuracy: 0.7302 - val_loss: 0.7142 - val_accuracy: 0.6402\n",
      "Epoch 261/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4768 - accuracy: 0.7532 - val_loss: 0.8116 - val_accuracy: 0.6476\n",
      "Epoch 262/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4846 - accuracy: 0.7476 - val_loss: 0.8981 - val_accuracy: 0.6328\n",
      "Epoch 263/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4667 - accuracy: 0.7460 - val_loss: 0.7720 - val_accuracy: 0.6550\n",
      "Epoch 264/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4888 - accuracy: 0.7437 - val_loss: 0.7454 - val_accuracy: 0.6402\n",
      "Epoch 265/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5388 - accuracy: 0.7002 - val_loss: 0.8297 - val_accuracy: 0.6181\n",
      "Epoch 266/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5204 - accuracy: 0.7334 - val_loss: 0.6751 - val_accuracy: 0.6624\n",
      "Epoch 267/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5375 - accuracy: 0.7041 - val_loss: 0.7357 - val_accuracy: 0.6458\n",
      "Epoch 268/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5085 - accuracy: 0.7326 - val_loss: 0.7371 - val_accuracy: 0.6236\n",
      "Epoch 269/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5053 - accuracy: 0.7318 - val_loss: 0.7357 - val_accuracy: 0.6273\n",
      "Epoch 270/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4820 - accuracy: 0.7421 - val_loss: 0.7752 - val_accuracy: 0.6439\n",
      "Epoch 271/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4704 - accuracy: 0.7571 - val_loss: 0.7610 - val_accuracy: 0.6494\n",
      "Epoch 272/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4694 - accuracy: 0.7540 - val_loss: 0.7931 - val_accuracy: 0.6531\n",
      "Epoch 273/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4734 - accuracy: 0.7413 - val_loss: 0.8196 - val_accuracy: 0.6568\n",
      "Epoch 274/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4623 - accuracy: 0.7476 - val_loss: 0.8103 - val_accuracy: 0.6642\n",
      "Epoch 275/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4644 - accuracy: 0.7484 - val_loss: 0.7990 - val_accuracy: 0.6421\n",
      "Epoch 276/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5196 - accuracy: 0.7255 - val_loss: 0.8714 - val_accuracy: 0.6384\n",
      "Epoch 277/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5102 - accuracy: 0.7199 - val_loss: 0.7796 - val_accuracy: 0.6513\n",
      "Epoch 278/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4889 - accuracy: 0.7366 - val_loss: 0.7935 - val_accuracy: 0.6642\n",
      "Epoch 279/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4750 - accuracy: 0.7445 - val_loss: 0.8289 - val_accuracy: 0.6513\n",
      "Epoch 280/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4619 - accuracy: 0.7532 - val_loss: 0.8814 - val_accuracy: 0.6421\n",
      "Epoch 281/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4630 - accuracy: 0.7468 - val_loss: 0.8190 - val_accuracy: 0.6716\n",
      "Epoch 282/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4495 - accuracy: 0.7555 - val_loss: 0.9385 - val_accuracy: 0.6661\n",
      "Epoch 283/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4468 - accuracy: 0.7627 - val_loss: 0.9292 - val_accuracy: 0.6476\n",
      "Epoch 284/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4342 - accuracy: 0.7579 - val_loss: 0.9734 - val_accuracy: 0.6550\n",
      "Epoch 285/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4408 - accuracy: 0.7619 - val_loss: 0.8652 - val_accuracy: 0.6550\n",
      "Epoch 286/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4463 - accuracy: 0.7595 - val_loss: 0.9365 - val_accuracy: 0.6347\n",
      "Epoch 287/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4433 - accuracy: 0.7674 - val_loss: 1.0283 - val_accuracy: 0.6310\n",
      "Epoch 288/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4421 - accuracy: 0.7587 - val_loss: 0.9907 - val_accuracy: 0.6236\n",
      "Epoch 289/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4345 - accuracy: 0.7579 - val_loss: 0.9641 - val_accuracy: 0.6587\n",
      "Epoch 290/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4286 - accuracy: 0.7666 - val_loss: 0.9236 - val_accuracy: 0.6494\n",
      "Epoch 291/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4267 - accuracy: 0.7627 - val_loss: 1.0470 - val_accuracy: 0.6661\n",
      "Epoch 292/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4221 - accuracy: 0.7824 - val_loss: 1.1433 - val_accuracy: 0.6292\n",
      "Epoch 293/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4781 - accuracy: 0.7476 - val_loss: 1.1287 - val_accuracy: 0.6292\n",
      "Epoch 294/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4495 - accuracy: 0.7642 - val_loss: 0.8927 - val_accuracy: 0.6402\n",
      "Epoch 295/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4939 - accuracy: 0.7302 - val_loss: 1.0976 - val_accuracy: 0.6052\n",
      "Epoch 296/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4495 - accuracy: 0.7587 - val_loss: 1.0195 - val_accuracy: 0.6661\n",
      "Epoch 297/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4569 - accuracy: 0.7429 - val_loss: 0.8721 - val_accuracy: 0.6513\n",
      "Epoch 298/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4476 - accuracy: 0.7603 - val_loss: 0.9961 - val_accuracy: 0.6458\n",
      "Epoch 299/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4623 - accuracy: 0.7619 - val_loss: 0.8912 - val_accuracy: 0.6605\n",
      "Epoch 300/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4455 - accuracy: 0.7619 - val_loss: 1.1497 - val_accuracy: 0.6587\n",
      "Epoch 301/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4661 - accuracy: 0.7666 - val_loss: 0.8221 - val_accuracy: 0.6531\n",
      "Epoch 302/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4761 - accuracy: 0.7366 - val_loss: 0.9397 - val_accuracy: 0.6476\n",
      "Epoch 303/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5025 - accuracy: 0.7508 - val_loss: 0.9332 - val_accuracy: 0.6365\n",
      "Epoch 304/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4575 - accuracy: 0.7563 - val_loss: 0.9000 - val_accuracy: 0.6531\n",
      "Epoch 305/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4487 - accuracy: 0.7650 - val_loss: 1.0409 - val_accuracy: 0.6292\n",
      "Epoch 306/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4415 - accuracy: 0.7627 - val_loss: 0.8665 - val_accuracy: 0.6513\n",
      "Epoch 307/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4483 - accuracy: 0.7508 - val_loss: 1.0937 - val_accuracy: 0.6107\n",
      "Epoch 308/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4746 - accuracy: 0.7405 - val_loss: 0.8539 - val_accuracy: 0.6605\n",
      "Epoch 309/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4552 - accuracy: 0.7524 - val_loss: 0.8992 - val_accuracy: 0.6661\n",
      "Epoch 310/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4349 - accuracy: 0.7619 - val_loss: 0.8637 - val_accuracy: 0.6476\n",
      "Epoch 311/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4330 - accuracy: 0.7603 - val_loss: 0.8859 - val_accuracy: 0.6421\n",
      "Epoch 312/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4302 - accuracy: 0.7658 - val_loss: 0.9496 - val_accuracy: 0.6568\n",
      "Epoch 313/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4352 - accuracy: 0.7658 - val_loss: 0.9997 - val_accuracy: 0.6624\n",
      "Epoch 314/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4238 - accuracy: 0.7642 - val_loss: 0.9190 - val_accuracy: 0.6642\n",
      "Epoch 315/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4497 - accuracy: 0.7453 - val_loss: 1.1485 - val_accuracy: 0.6292\n",
      "Epoch 316/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4824 - accuracy: 0.7429 - val_loss: 1.0737 - val_accuracy: 0.6568\n",
      "Epoch 317/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4642 - accuracy: 0.7492 - val_loss: 0.8557 - val_accuracy: 0.6347\n",
      "Epoch 318/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4861 - accuracy: 0.7381 - val_loss: 0.8503 - val_accuracy: 0.6310\n",
      "Epoch 319/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4687 - accuracy: 0.7421 - val_loss: 1.1184 - val_accuracy: 0.6513\n",
      "Epoch 320/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4729 - accuracy: 0.7540 - val_loss: 0.8911 - val_accuracy: 0.6679\n",
      "Epoch 321/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4504 - accuracy: 0.7492 - val_loss: 1.0317 - val_accuracy: 0.6458\n",
      "Epoch 322/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4359 - accuracy: 0.7698 - val_loss: 1.2097 - val_accuracy: 0.6458\n",
      "Epoch 323/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4222 - accuracy: 0.7809 - val_loss: 1.0389 - val_accuracy: 0.6550\n",
      "Epoch 324/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4163 - accuracy: 0.7777 - val_loss: 1.0173 - val_accuracy: 0.6568\n",
      "Epoch 325/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4294 - accuracy: 0.7658 - val_loss: 1.0771 - val_accuracy: 0.6550\n",
      "Epoch 326/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4718 - accuracy: 0.7437 - val_loss: 0.9875 - val_accuracy: 0.6568\n",
      "Epoch 327/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4766 - accuracy: 0.7373 - val_loss: 0.9188 - val_accuracy: 0.6568\n",
      "Epoch 328/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5022 - accuracy: 0.7358 - val_loss: 0.8463 - val_accuracy: 0.6679\n",
      "Epoch 329/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4811 - accuracy: 0.7381 - val_loss: 0.9196 - val_accuracy: 0.6421\n",
      "Epoch 330/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5108 - accuracy: 0.7223 - val_loss: 0.8491 - val_accuracy: 0.6605\n",
      "Epoch 331/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4915 - accuracy: 0.7358 - val_loss: 0.9614 - val_accuracy: 0.6568\n",
      "Epoch 332/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4646 - accuracy: 0.7413 - val_loss: 0.9099 - val_accuracy: 0.6679\n",
      "Epoch 333/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4571 - accuracy: 0.7603 - val_loss: 0.8777 - val_accuracy: 0.6642\n",
      "Epoch 334/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4533 - accuracy: 0.7532 - val_loss: 0.9663 - val_accuracy: 0.6716\n",
      "Epoch 335/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4495 - accuracy: 0.7642 - val_loss: 0.9245 - val_accuracy: 0.6550\n",
      "Epoch 336/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4359 - accuracy: 0.7722 - val_loss: 1.0329 - val_accuracy: 0.6679\n",
      "Epoch 337/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4404 - accuracy: 0.7745 - val_loss: 0.8930 - val_accuracy: 0.6624\n",
      "Epoch 338/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4414 - accuracy: 0.7611 - val_loss: 0.9572 - val_accuracy: 0.6531\n",
      "Epoch 339/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4194 - accuracy: 0.7769 - val_loss: 1.2153 - val_accuracy: 0.6328\n",
      "Epoch 340/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4336 - accuracy: 0.7619 - val_loss: 0.9030 - val_accuracy: 0.6402\n",
      "Epoch 341/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4125 - accuracy: 0.7769 - val_loss: 0.9638 - val_accuracy: 0.6494\n",
      "Epoch 342/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4148 - accuracy: 0.7801 - val_loss: 0.9831 - val_accuracy: 0.6513\n",
      "Epoch 343/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4013 - accuracy: 0.7785 - val_loss: 1.0176 - val_accuracy: 0.6439\n",
      "Epoch 344/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4277 - accuracy: 0.7690 - val_loss: 1.1746 - val_accuracy: 0.6328\n",
      "Epoch 345/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4161 - accuracy: 0.7706 - val_loss: 1.3747 - val_accuracy: 0.6089\n",
      "Epoch 346/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4336 - accuracy: 0.7634 - val_loss: 0.9798 - val_accuracy: 0.6605\n",
      "Epoch 347/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4303 - accuracy: 0.7634 - val_loss: 0.9809 - val_accuracy: 0.6550\n",
      "Epoch 348/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4360 - accuracy: 0.7698 - val_loss: 1.0177 - val_accuracy: 0.6531\n",
      "Epoch 349/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4161 - accuracy: 0.7706 - val_loss: 0.9844 - val_accuracy: 0.6476\n",
      "Epoch 350/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4082 - accuracy: 0.7666 - val_loss: 1.0407 - val_accuracy: 0.6531\n",
      "Epoch 351/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4183 - accuracy: 0.7674 - val_loss: 1.1215 - val_accuracy: 0.6384\n",
      "Epoch 352/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4238 - accuracy: 0.7753 - val_loss: 0.9155 - val_accuracy: 0.6568\n",
      "Epoch 353/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4187 - accuracy: 0.7666 - val_loss: 1.1164 - val_accuracy: 0.6624\n",
      "Epoch 354/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4034 - accuracy: 0.7824 - val_loss: 1.1029 - val_accuracy: 0.6624\n",
      "Epoch 355/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4063 - accuracy: 0.7753 - val_loss: 1.0835 - val_accuracy: 0.6494\n",
      "Epoch 356/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3958 - accuracy: 0.7888 - val_loss: 1.2173 - val_accuracy: 0.6513\n",
      "Epoch 357/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3897 - accuracy: 0.7856 - val_loss: 1.3083 - val_accuracy: 0.6476\n",
      "Epoch 358/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3860 - accuracy: 0.7832 - val_loss: 1.1399 - val_accuracy: 0.6771\n",
      "Epoch 359/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3878 - accuracy: 0.7927 - val_loss: 1.2125 - val_accuracy: 0.6365\n",
      "Epoch 360/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4305 - accuracy: 0.7729 - val_loss: 1.2815 - val_accuracy: 0.6531\n",
      "Epoch 361/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4632 - accuracy: 0.7579 - val_loss: 1.2367 - val_accuracy: 0.6107\n",
      "Epoch 362/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5704 - accuracy: 0.6748 - val_loss: 1.5092 - val_accuracy: 0.6070\n",
      "Epoch 363/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4509 - accuracy: 0.7049 - val_loss: 0.8854 - val_accuracy: 0.6273\n",
      "Epoch 364/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4995 - accuracy: 0.7373 - val_loss: 0.9299 - val_accuracy: 0.6236\n",
      "Epoch 365/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4769 - accuracy: 0.7429 - val_loss: 1.0507 - val_accuracy: 0.6439\n",
      "Epoch 366/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4555 - accuracy: 0.7500 - val_loss: 0.8342 - val_accuracy: 0.6587\n",
      "Epoch 367/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4503 - accuracy: 0.7579 - val_loss: 0.9920 - val_accuracy: 0.6384\n",
      "Epoch 368/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4297 - accuracy: 0.7516 - val_loss: 1.1617 - val_accuracy: 0.6513\n",
      "Epoch 369/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4110 - accuracy: 0.7745 - val_loss: 1.1817 - val_accuracy: 0.6587\n",
      "Epoch 370/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3882 - accuracy: 0.7848 - val_loss: 1.1412 - val_accuracy: 0.6513\n",
      "Epoch 371/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3913 - accuracy: 0.7872 - val_loss: 1.2478 - val_accuracy: 0.6642\n",
      "Epoch 372/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3878 - accuracy: 0.7856 - val_loss: 1.1876 - val_accuracy: 0.6513\n",
      "Epoch 373/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3952 - accuracy: 0.7824 - val_loss: 1.3359 - val_accuracy: 0.6605\n",
      "Epoch 374/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4062 - accuracy: 0.7951 - val_loss: 1.1041 - val_accuracy: 0.6587\n",
      "Epoch 375/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3992 - accuracy: 0.7801 - val_loss: 1.1256 - val_accuracy: 0.6568\n",
      "Epoch 376/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4021 - accuracy: 0.7911 - val_loss: 1.2489 - val_accuracy: 0.6384\n",
      "Epoch 377/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3932 - accuracy: 0.7864 - val_loss: 1.4642 - val_accuracy: 0.6365\n",
      "Epoch 378/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4043 - accuracy: 0.7888 - val_loss: 1.2505 - val_accuracy: 0.6458\n",
      "Epoch 379/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3944 - accuracy: 0.7927 - val_loss: 1.3995 - val_accuracy: 0.6255\n",
      "Epoch 380/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4113 - accuracy: 0.7658 - val_loss: 1.6566 - val_accuracy: 0.6494\n",
      "Epoch 381/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4225 - accuracy: 0.7698 - val_loss: 1.3517 - val_accuracy: 0.6531\n",
      "Epoch 382/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3949 - accuracy: 0.7793 - val_loss: 1.3345 - val_accuracy: 0.6550\n",
      "Epoch 383/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3712 - accuracy: 0.8030 - val_loss: 1.4817 - val_accuracy: 0.6494\n",
      "Epoch 384/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3732 - accuracy: 0.8030 - val_loss: 1.2777 - val_accuracy: 0.6605\n",
      "Epoch 385/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3735 - accuracy: 0.8046 - val_loss: 1.3270 - val_accuracy: 0.6513\n",
      "Epoch 386/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3681 - accuracy: 0.8054 - val_loss: 1.4437 - val_accuracy: 0.6476\n",
      "Epoch 387/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3863 - accuracy: 0.7927 - val_loss: 1.1859 - val_accuracy: 0.6384\n",
      "Epoch 388/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4001 - accuracy: 0.7801 - val_loss: 1.4422 - val_accuracy: 0.6236\n",
      "Epoch 389/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3955 - accuracy: 0.7832 - val_loss: 1.3900 - val_accuracy: 0.6421\n",
      "Epoch 390/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3880 - accuracy: 0.7793 - val_loss: 1.2613 - val_accuracy: 0.6568\n",
      "Epoch 391/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3939 - accuracy: 0.7927 - val_loss: 1.4867 - val_accuracy: 0.6347\n",
      "Epoch 392/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3815 - accuracy: 0.7880 - val_loss: 1.6213 - val_accuracy: 0.6402\n",
      "Epoch 393/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4097 - accuracy: 0.7690 - val_loss: 1.5133 - val_accuracy: 0.6347\n",
      "Epoch 394/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4264 - accuracy: 0.7729 - val_loss: 1.0335 - val_accuracy: 0.6587\n",
      "Epoch 395/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4336 - accuracy: 0.7737 - val_loss: 1.0684 - val_accuracy: 0.6605\n",
      "Epoch 396/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4297 - accuracy: 0.7650 - val_loss: 1.4196 - val_accuracy: 0.6384\n",
      "Epoch 397/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4224 - accuracy: 0.7753 - val_loss: 1.3652 - val_accuracy: 0.6273\n",
      "Epoch 398/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4081 - accuracy: 0.7769 - val_loss: 1.6302 - val_accuracy: 0.6236\n",
      "Epoch 399/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4048 - accuracy: 0.7753 - val_loss: 1.6728 - val_accuracy: 0.6402\n",
      "Epoch 400/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3958 - accuracy: 0.7785 - val_loss: 1.4490 - val_accuracy: 0.6439\n",
      "Epoch 401/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4046 - accuracy: 0.7809 - val_loss: 1.5179 - val_accuracy: 0.6070\n",
      "Epoch 402/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4929 - accuracy: 0.7247 - val_loss: 1.5105 - val_accuracy: 0.6421\n",
      "Epoch 403/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4263 - accuracy: 0.7714 - val_loss: 1.3874 - val_accuracy: 0.6531\n",
      "Epoch 404/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4028 - accuracy: 0.7896 - val_loss: 1.2907 - val_accuracy: 0.6587\n",
      "Epoch 405/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 1.1427 - val_accuracy: 0.6439\n",
      "Epoch 406/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4100 - accuracy: 0.7832 - val_loss: 1.3724 - val_accuracy: 0.6310\n",
      "Epoch 407/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3993 - accuracy: 0.7848 - val_loss: 1.2440 - val_accuracy: 0.6568\n",
      "Epoch 408/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3918 - accuracy: 0.7903 - val_loss: 1.2487 - val_accuracy: 0.6439\n",
      "Epoch 409/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3895 - accuracy: 0.7864 - val_loss: 1.4500 - val_accuracy: 0.6347\n",
      "Epoch 410/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3992 - accuracy: 0.7856 - val_loss: 1.4071 - val_accuracy: 0.6273\n",
      "Epoch 411/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3870 - accuracy: 0.7785 - val_loss: 1.4160 - val_accuracy: 0.6384\n",
      "Epoch 412/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3982 - accuracy: 0.7761 - val_loss: 1.6995 - val_accuracy: 0.6347\n",
      "Epoch 413/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3867 - accuracy: 0.7856 - val_loss: 1.5488 - val_accuracy: 0.6494\n",
      "Epoch 414/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4088 - accuracy: 0.7848 - val_loss: 1.4625 - val_accuracy: 0.6218\n",
      "Epoch 415/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4238 - accuracy: 0.7611 - val_loss: 1.5749 - val_accuracy: 0.6347\n",
      "Epoch 416/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3785 - accuracy: 0.7951 - val_loss: 1.3292 - val_accuracy: 0.6513\n",
      "Epoch 417/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3820 - accuracy: 0.7880 - val_loss: 1.2517 - val_accuracy: 0.6513\n",
      "Epoch 418/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3849 - accuracy: 0.7919 - val_loss: 1.2862 - val_accuracy: 0.6347\n",
      "Epoch 419/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4093 - accuracy: 0.7674 - val_loss: 1.2437 - val_accuracy: 0.6476\n",
      "Epoch 420/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3998 - accuracy: 0.7801 - val_loss: 1.7064 - val_accuracy: 0.6273\n",
      "Epoch 421/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3868 - accuracy: 0.7911 - val_loss: 1.4009 - val_accuracy: 0.6494\n",
      "Epoch 422/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3862 - accuracy: 0.7864 - val_loss: 1.5843 - val_accuracy: 0.6181\n",
      "Epoch 423/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3755 - accuracy: 0.7864 - val_loss: 1.4915 - val_accuracy: 0.6550\n",
      "Epoch 424/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3740 - accuracy: 0.7975 - val_loss: 1.6820 - val_accuracy: 0.6273\n",
      "Epoch 425/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3737 - accuracy: 0.7943 - val_loss: 1.4784 - val_accuracy: 0.6458\n",
      "Epoch 426/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3676 - accuracy: 0.7991 - val_loss: 1.6386 - val_accuracy: 0.6494\n",
      "Epoch 427/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3721 - accuracy: 0.7911 - val_loss: 1.5249 - val_accuracy: 0.6550\n",
      "Epoch 428/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3708 - accuracy: 0.7919 - val_loss: 1.6268 - val_accuracy: 0.6513\n",
      "Epoch 429/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3745 - accuracy: 0.7927 - val_loss: 1.7509 - val_accuracy: 0.6365\n",
      "Epoch 430/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3662 - accuracy: 0.7991 - val_loss: 1.6776 - val_accuracy: 0.6587\n",
      "Epoch 431/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3633 - accuracy: 0.8085 - val_loss: 1.9016 - val_accuracy: 0.6513\n",
      "Epoch 432/700\n",
      "1264/1264 [==============================] - 11s 9ms/step - loss: 0.3709 - accuracy: 0.8022 - val_loss: 1.7970 - val_accuracy: 0.6494\n",
      "Epoch 433/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3592 - accuracy: 0.7998 - val_loss: 1.6412 - val_accuracy: 0.6624\n",
      "Epoch 434/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3562 - accuracy: 0.8085 - val_loss: 1.5568 - val_accuracy: 0.6624\n",
      "Epoch 435/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3559 - accuracy: 0.8062 - val_loss: 1.6432 - val_accuracy: 0.6439\n",
      "Epoch 436/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3579 - accuracy: 0.8030 - val_loss: 1.6492 - val_accuracy: 0.6587\n",
      "Epoch 437/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3528 - accuracy: 0.8109 - val_loss: 1.8957 - val_accuracy: 0.6384\n",
      "Epoch 438/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3495 - accuracy: 0.8133 - val_loss: 1.7246 - val_accuracy: 0.6568\n",
      "Epoch 439/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3552 - accuracy: 0.8101 - val_loss: 1.8235 - val_accuracy: 0.6531\n",
      "Epoch 440/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3495 - accuracy: 0.8117 - val_loss: 1.8789 - val_accuracy: 0.6476\n",
      "Epoch 441/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3519 - accuracy: 0.8093 - val_loss: 1.8220 - val_accuracy: 0.6458\n",
      "Epoch 442/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3533 - accuracy: 0.8022 - val_loss: 1.8256 - val_accuracy: 0.6605\n",
      "Epoch 443/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3733 - accuracy: 0.8054 - val_loss: 1.7117 - val_accuracy: 0.6402\n",
      "Epoch 444/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4217 - accuracy: 0.7634 - val_loss: 1.9033 - val_accuracy: 0.6125\n",
      "Epoch 445/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3751 - accuracy: 0.7872 - val_loss: 1.5948 - val_accuracy: 0.6458\n",
      "Epoch 446/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3841 - accuracy: 0.7856 - val_loss: 1.8424 - val_accuracy: 0.6292\n",
      "Epoch 447/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4348 - accuracy: 0.7500 - val_loss: 1.5768 - val_accuracy: 0.6273\n",
      "Epoch 448/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4395 - accuracy: 0.7532 - val_loss: 1.7568 - val_accuracy: 0.6107\n",
      "Epoch 449/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4513 - accuracy: 0.7611 - val_loss: 1.1467 - val_accuracy: 0.6421\n",
      "Epoch 450/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4414 - accuracy: 0.7650 - val_loss: 1.9086 - val_accuracy: 0.5424\n",
      "Epoch 451/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4384 - accuracy: 0.7389 - val_loss: 1.4566 - val_accuracy: 0.6328\n",
      "Epoch 452/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4168 - accuracy: 0.7690 - val_loss: 1.4165 - val_accuracy: 0.6144\n",
      "Epoch 453/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4025 - accuracy: 0.7903 - val_loss: 1.1524 - val_accuracy: 0.6458\n",
      "Epoch 454/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3910 - accuracy: 0.7888 - val_loss: 1.3980 - val_accuracy: 0.6199\n",
      "Epoch 455/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3869 - accuracy: 0.7840 - val_loss: 1.4483 - val_accuracy: 0.6384\n",
      "Epoch 456/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3788 - accuracy: 0.7967 - val_loss: 1.6538 - val_accuracy: 0.6384\n",
      "Epoch 457/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3746 - accuracy: 0.7959 - val_loss: 1.6856 - val_accuracy: 0.6328\n",
      "Epoch 458/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3966 - accuracy: 0.7769 - val_loss: 1.3403 - val_accuracy: 0.6458\n",
      "Epoch 459/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3881 - accuracy: 0.7840 - val_loss: 1.3708 - val_accuracy: 0.6421\n",
      "Epoch 460/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3583 - accuracy: 0.8093 - val_loss: 1.5551 - val_accuracy: 0.6494\n",
      "Epoch 461/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3841 - accuracy: 0.7991 - val_loss: 1.1567 - val_accuracy: 0.6550\n",
      "Epoch 462/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4016 - accuracy: 0.7935 - val_loss: 1.5070 - val_accuracy: 0.6236\n",
      "Epoch 463/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4013 - accuracy: 0.7840 - val_loss: 1.7175 - val_accuracy: 0.6273\n",
      "Epoch 464/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3769 - accuracy: 0.7864 - val_loss: 1.5175 - val_accuracy: 0.6513\n",
      "Epoch 465/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3814 - accuracy: 0.7943 - val_loss: 1.3781 - val_accuracy: 0.6402\n",
      "Epoch 466/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3847 - accuracy: 0.7872 - val_loss: 1.5415 - val_accuracy: 0.6605\n",
      "Epoch 467/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3692 - accuracy: 0.7991 - val_loss: 1.6574 - val_accuracy: 0.6365\n",
      "Epoch 468/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3539 - accuracy: 0.8054 - val_loss: 1.5709 - val_accuracy: 0.6476\n",
      "Epoch 469/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3656 - accuracy: 0.8046 - val_loss: 1.5586 - val_accuracy: 0.6531\n",
      "Epoch 470/700\n",
      "1264/1264 [==============================] - 16s 13ms/step - loss: 0.3508 - accuracy: 0.8125 - val_loss: 1.5423 - val_accuracy: 0.6458\n",
      "Epoch 471/700\n",
      "1264/1264 [==============================] - 17s 13ms/step - loss: 0.3518 - accuracy: 0.8078 - val_loss: 1.3797 - val_accuracy: 0.6587\n",
      "Epoch 472/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3548 - accuracy: 0.8070 - val_loss: 1.5568 - val_accuracy: 0.6494\n",
      "Epoch 473/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3495 - accuracy: 0.8125 - val_loss: 1.6213 - val_accuracy: 0.6494\n",
      "Epoch 474/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3431 - accuracy: 0.8117 - val_loss: 1.8968 - val_accuracy: 0.6550\n",
      "Epoch 475/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3544 - accuracy: 0.8038 - val_loss: 1.8596 - val_accuracy: 0.6550\n",
      "Epoch 476/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3597 - accuracy: 0.8054 - val_loss: 1.9012 - val_accuracy: 0.6384\n",
      "Epoch 477/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3807 - accuracy: 0.7896 - val_loss: 1.9784 - val_accuracy: 0.6199\n",
      "Epoch 478/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3663 - accuracy: 0.7983 - val_loss: 1.8092 - val_accuracy: 0.6494\n",
      "Epoch 479/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3555 - accuracy: 0.7998 - val_loss: 2.0115 - val_accuracy: 0.6255\n",
      "Epoch 480/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3693 - accuracy: 0.7998 - val_loss: 1.5843 - val_accuracy: 0.6199\n",
      "Epoch 481/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4209 - accuracy: 0.7555 - val_loss: 1.8293 - val_accuracy: 0.6292\n",
      "Epoch 482/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4260 - accuracy: 0.7753 - val_loss: 2.1251 - val_accuracy: 0.6310\n",
      "Epoch 483/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3823 - accuracy: 0.7959 - val_loss: 1.4405 - val_accuracy: 0.6273\n",
      "Epoch 484/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4049 - accuracy: 0.7706 - val_loss: 1.2679 - val_accuracy: 0.6550\n",
      "Epoch 485/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3829 - accuracy: 0.7872 - val_loss: 1.8188 - val_accuracy: 0.6255\n",
      "Epoch 486/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4972 - accuracy: 0.7627 - val_loss: 1.3721 - val_accuracy: 0.6255\n",
      "Epoch 487/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4445 - accuracy: 0.7468 - val_loss: 1.5144 - val_accuracy: 0.5923\n",
      "Epoch 488/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4881 - accuracy: 0.7437 - val_loss: 1.3038 - val_accuracy: 0.6236\n",
      "Epoch 489/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5479 - accuracy: 0.6519 - val_loss: 1.4790 - val_accuracy: 0.6328\n",
      "Epoch 490/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4958 - accuracy: 0.7239 - val_loss: 1.1974 - val_accuracy: 0.4926\n",
      "Epoch 491/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5272 - accuracy: 0.7097 - val_loss: 1.1475 - val_accuracy: 0.6310\n",
      "Epoch 492/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5265 - accuracy: 0.7437 - val_loss: 1.0069 - val_accuracy: 0.6181\n",
      "Epoch 493/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4588 - accuracy: 0.7310 - val_loss: 0.9181 - val_accuracy: 0.6384\n",
      "Epoch 494/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4400 - accuracy: 0.7785 - val_loss: 1.0868 - val_accuracy: 0.6310\n",
      "Epoch 495/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4722 - accuracy: 0.7516 - val_loss: 0.9901 - val_accuracy: 0.6347\n",
      "Epoch 496/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4341 - accuracy: 0.7714 - val_loss: 0.9614 - val_accuracy: 0.6199\n",
      "Epoch 497/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4461 - accuracy: 0.7627 - val_loss: 0.9115 - val_accuracy: 0.6402\n",
      "Epoch 498/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4387 - accuracy: 0.7650 - val_loss: 1.1290 - val_accuracy: 0.6199\n",
      "Epoch 499/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4253 - accuracy: 0.7745 - val_loss: 1.0197 - val_accuracy: 0.6439\n",
      "Epoch 500/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4100 - accuracy: 0.7848 - val_loss: 1.1157 - val_accuracy: 0.6107\n",
      "Epoch 501/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4125 - accuracy: 0.7737 - val_loss: 1.2016 - val_accuracy: 0.6531\n",
      "Epoch 502/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4128 - accuracy: 0.7761 - val_loss: 1.2421 - val_accuracy: 0.6402\n",
      "Epoch 503/700\n",
      "1264/1264 [==============================] - 11s 9ms/step - loss: 0.4175 - accuracy: 0.7753 - val_loss: 1.2692 - val_accuracy: 0.6273\n",
      "Epoch 504/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3992 - accuracy: 0.7864 - val_loss: 1.3495 - val_accuracy: 0.6236\n",
      "Epoch 505/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3890 - accuracy: 0.7880 - val_loss: 1.2199 - val_accuracy: 0.6587\n",
      "Epoch 506/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3823 - accuracy: 0.7919 - val_loss: 1.2223 - val_accuracy: 0.6402\n",
      "Epoch 507/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3830 - accuracy: 0.7888 - val_loss: 1.2994 - val_accuracy: 0.6494\n",
      "Epoch 508/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3894 - accuracy: 0.7911 - val_loss: 1.5244 - val_accuracy: 0.6292\n",
      "Epoch 509/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4111 - accuracy: 0.7848 - val_loss: 1.2025 - val_accuracy: 0.6384\n",
      "Epoch 510/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4423 - accuracy: 0.7698 - val_loss: 1.2193 - val_accuracy: 0.6236\n",
      "Epoch 511/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5186 - accuracy: 0.7168 - val_loss: 1.3846 - val_accuracy: 0.6218\n",
      "Epoch 512/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4578 - accuracy: 0.7603 - val_loss: 0.8865 - val_accuracy: 0.6605\n",
      "Epoch 513/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4912 - accuracy: 0.7429 - val_loss: 0.8544 - val_accuracy: 0.6384\n",
      "Epoch 514/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4786 - accuracy: 0.7334 - val_loss: 1.0261 - val_accuracy: 0.6218\n",
      "Epoch 515/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4600 - accuracy: 0.7421 - val_loss: 1.0908 - val_accuracy: 0.6273\n",
      "Epoch 516/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4660 - accuracy: 0.7476 - val_loss: 1.0598 - val_accuracy: 0.6494\n",
      "Epoch 517/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4342 - accuracy: 0.7627 - val_loss: 1.0495 - val_accuracy: 0.6347\n",
      "Epoch 518/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4115 - accuracy: 0.7706 - val_loss: 1.0678 - val_accuracy: 0.6568\n",
      "Epoch 519/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3983 - accuracy: 0.7911 - val_loss: 1.2520 - val_accuracy: 0.6328\n",
      "Epoch 520/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3909 - accuracy: 0.7888 - val_loss: 1.3585 - val_accuracy: 0.6494\n",
      "Epoch 521/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3897 - accuracy: 0.7856 - val_loss: 1.3998 - val_accuracy: 0.6458\n",
      "Epoch 522/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3781 - accuracy: 0.8030 - val_loss: 1.4368 - val_accuracy: 0.6531\n",
      "Epoch 523/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3713 - accuracy: 0.8014 - val_loss: 1.5288 - val_accuracy: 0.6513\n",
      "Epoch 524/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3721 - accuracy: 0.8006 - val_loss: 1.5575 - val_accuracy: 0.6439\n",
      "Epoch 525/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3693 - accuracy: 0.7998 - val_loss: 1.4347 - val_accuracy: 0.6605\n",
      "Epoch 526/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3753 - accuracy: 0.8030 - val_loss: 1.5351 - val_accuracy: 0.6255\n",
      "Epoch 527/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3937 - accuracy: 0.7848 - val_loss: 1.4502 - val_accuracy: 0.6531\n",
      "Epoch 528/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3914 - accuracy: 0.7983 - val_loss: 1.4876 - val_accuracy: 0.6439\n",
      "Epoch 529/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4412 - accuracy: 0.7547 - val_loss: 1.6442 - val_accuracy: 0.6347\n",
      "Epoch 530/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4343 - accuracy: 0.7722 - val_loss: 1.0246 - val_accuracy: 0.6384\n",
      "Epoch 531/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4602 - accuracy: 0.7453 - val_loss: 1.1149 - val_accuracy: 0.6347\n",
      "Epoch 532/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4372 - accuracy: 0.7587 - val_loss: 1.1867 - val_accuracy: 0.6384\n",
      "Epoch 533/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4500 - accuracy: 0.7476 - val_loss: 1.1572 - val_accuracy: 0.6328\n",
      "Epoch 534/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4387 - accuracy: 0.7634 - val_loss: 1.2529 - val_accuracy: 0.5978\n",
      "Epoch 535/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4239 - accuracy: 0.7603 - val_loss: 1.0968 - val_accuracy: 0.6458\n",
      "Epoch 536/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4170 - accuracy: 0.7832 - val_loss: 1.3762 - val_accuracy: 0.6052\n",
      "Epoch 537/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4000 - accuracy: 0.7824 - val_loss: 1.2286 - val_accuracy: 0.6328\n",
      "Epoch 538/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3940 - accuracy: 0.7840 - val_loss: 1.3201 - val_accuracy: 0.6144\n",
      "Epoch 539/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3773 - accuracy: 0.7935 - val_loss: 1.2597 - val_accuracy: 0.6310\n",
      "Epoch 540/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3722 - accuracy: 0.7959 - val_loss: 1.3214 - val_accuracy: 0.6273\n",
      "Epoch 541/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3667 - accuracy: 0.8038 - val_loss: 1.4103 - val_accuracy: 0.6255\n",
      "Epoch 542/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3632 - accuracy: 0.8093 - val_loss: 1.4565 - val_accuracy: 0.6236\n",
      "Epoch 543/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3593 - accuracy: 0.8054 - val_loss: 1.4102 - val_accuracy: 0.6365\n",
      "Epoch 544/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3659 - accuracy: 0.7983 - val_loss: 1.5040 - val_accuracy: 0.6384\n",
      "Epoch 545/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3688 - accuracy: 0.7959 - val_loss: 1.8874 - val_accuracy: 0.6144\n",
      "Epoch 546/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3687 - accuracy: 0.7975 - val_loss: 1.5819 - val_accuracy: 0.6365\n",
      "Epoch 547/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3611 - accuracy: 0.8046 - val_loss: 1.4848 - val_accuracy: 0.6550\n",
      "Epoch 548/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3825 - accuracy: 0.7903 - val_loss: 1.5618 - val_accuracy: 0.6421\n",
      "Epoch 549/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3969 - accuracy: 0.7832 - val_loss: 1.6650 - val_accuracy: 0.6181\n",
      "Epoch 550/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3908 - accuracy: 0.7872 - val_loss: 1.4702 - val_accuracy: 0.6439\n",
      "Epoch 551/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3687 - accuracy: 0.7927 - val_loss: 1.5229 - val_accuracy: 0.6347\n",
      "Epoch 552/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3518 - accuracy: 0.7998 - val_loss: 1.3409 - val_accuracy: 0.6568\n",
      "Epoch 553/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3533 - accuracy: 0.8006 - val_loss: 1.4605 - val_accuracy: 0.6402\n",
      "Epoch 554/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3506 - accuracy: 0.7975 - val_loss: 1.4643 - val_accuracy: 0.6605\n",
      "Epoch 555/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3513 - accuracy: 0.8117 - val_loss: 1.6343 - val_accuracy: 0.6402\n",
      "Epoch 556/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3456 - accuracy: 0.8101 - val_loss: 1.6392 - val_accuracy: 0.6494\n",
      "Epoch 557/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3414 - accuracy: 0.8109 - val_loss: 1.6689 - val_accuracy: 0.6328\n",
      "Epoch 558/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3457 - accuracy: 0.8022 - val_loss: 1.6102 - val_accuracy: 0.6494\n",
      "Epoch 559/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3377 - accuracy: 0.8101 - val_loss: 1.7815 - val_accuracy: 0.6384\n",
      "Epoch 560/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3409 - accuracy: 0.8141 - val_loss: 1.8197 - val_accuracy: 0.6476\n",
      "Epoch 561/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3450 - accuracy: 0.8117 - val_loss: 1.7982 - val_accuracy: 0.6458\n",
      "Epoch 562/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3453 - accuracy: 0.8101 - val_loss: 1.9273 - val_accuracy: 0.6402\n",
      "Epoch 563/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3477 - accuracy: 0.8085 - val_loss: 1.8115 - val_accuracy: 0.6402\n",
      "Epoch 564/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3584 - accuracy: 0.7975 - val_loss: 1.9060 - val_accuracy: 0.6384\n",
      "Epoch 565/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3346 - accuracy: 0.8188 - val_loss: 2.0670 - val_accuracy: 0.6439\n",
      "Epoch 566/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3316 - accuracy: 0.8204 - val_loss: 1.9389 - val_accuracy: 0.6476\n",
      "Epoch 567/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3334 - accuracy: 0.8212 - val_loss: 2.0260 - val_accuracy: 0.6310\n",
      "Epoch 568/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3536 - accuracy: 0.7967 - val_loss: 2.0145 - val_accuracy: 0.6181\n",
      "Epoch 569/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3912 - accuracy: 0.7753 - val_loss: 2.0944 - val_accuracy: 0.6033\n",
      "Epoch 570/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4762 - accuracy: 0.7460 - val_loss: 2.0774 - val_accuracy: 0.6125\n",
      "Epoch 571/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4812 - accuracy: 0.7460 - val_loss: 1.5576 - val_accuracy: 0.6439\n",
      "Epoch 572/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5907 - accuracy: 0.7057 - val_loss: 1.5736 - val_accuracy: 0.6052\n",
      "Epoch 573/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5678 - accuracy: 0.7089 - val_loss: 0.9451 - val_accuracy: 0.4945\n",
      "Epoch 574/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6049 - accuracy: 0.6084 - val_loss: 0.7191 - val_accuracy: 0.5387\n",
      "Epoch 575/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5867 - accuracy: 0.6559 - val_loss: 0.6677 - val_accuracy: 0.6679\n",
      "Epoch 576/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6132 - accuracy: 0.6883 - val_loss: 0.6590 - val_accuracy: 0.6790\n",
      "Epoch 577/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6056 - accuracy: 0.6875 - val_loss: 0.6455 - val_accuracy: 0.6716\n",
      "Epoch 578/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5722 - accuracy: 0.7144 - val_loss: 0.6638 - val_accuracy: 0.6568\n",
      "Epoch 579/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5484 - accuracy: 0.7247 - val_loss: 0.7030 - val_accuracy: 0.6624\n",
      "Epoch 580/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5106 - accuracy: 0.7405 - val_loss: 0.7673 - val_accuracy: 0.6679\n",
      "Epoch 581/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4785 - accuracy: 0.7571 - val_loss: 0.8535 - val_accuracy: 0.6605\n",
      "Epoch 582/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4473 - accuracy: 0.7729 - val_loss: 0.7742 - val_accuracy: 0.6494\n",
      "Epoch 583/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4317 - accuracy: 0.7722 - val_loss: 0.8372 - val_accuracy: 0.6808\n",
      "Epoch 584/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4114 - accuracy: 0.8046 - val_loss: 0.9396 - val_accuracy: 0.6494\n",
      "Epoch 585/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4042 - accuracy: 0.7951 - val_loss: 0.8951 - val_accuracy: 0.6421\n",
      "Epoch 586/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3898 - accuracy: 0.8014 - val_loss: 1.0092 - val_accuracy: 0.6513\n",
      "Epoch 587/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3795 - accuracy: 0.7998 - val_loss: 1.0510 - val_accuracy: 0.6365\n",
      "Epoch 588/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3689 - accuracy: 0.8046 - val_loss: 1.1668 - val_accuracy: 0.6236\n",
      "Epoch 589/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3569 - accuracy: 0.8101 - val_loss: 1.5163 - val_accuracy: 0.6218\n",
      "Epoch 590/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3575 - accuracy: 0.8054 - val_loss: 1.2997 - val_accuracy: 0.6347\n",
      "Epoch 591/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3622 - accuracy: 0.8093 - val_loss: 1.7500 - val_accuracy: 0.6125\n",
      "Epoch 592/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3530 - accuracy: 0.8109 - val_loss: 1.6057 - val_accuracy: 0.6421\n",
      "Epoch 593/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3681 - accuracy: 0.8006 - val_loss: 1.5378 - val_accuracy: 0.6328\n",
      "Epoch 594/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3617 - accuracy: 0.8054 - val_loss: 1.9764 - val_accuracy: 0.6199\n",
      "Epoch 595/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3791 - accuracy: 0.7880 - val_loss: 1.6888 - val_accuracy: 0.6052\n",
      "Epoch 596/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3776 - accuracy: 0.7998 - val_loss: 1.2210 - val_accuracy: 0.6402\n",
      "Epoch 597/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3851 - accuracy: 0.7951 - val_loss: 1.4809 - val_accuracy: 0.6144\n",
      "Epoch 598/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3635 - accuracy: 0.7927 - val_loss: 1.8959 - val_accuracy: 0.6218\n",
      "Epoch 599/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3789 - accuracy: 0.7848 - val_loss: 1.7623 - val_accuracy: 0.6144\n",
      "Epoch 600/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3694 - accuracy: 0.7967 - val_loss: 1.6798 - val_accuracy: 0.6107\n",
      "Epoch 601/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4115 - accuracy: 0.7714 - val_loss: 2.0750 - val_accuracy: 0.5203\n",
      "Epoch 602/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5095 - accuracy: 0.7152 - val_loss: 0.8950 - val_accuracy: 0.5867\n",
      "Epoch 603/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6320 - accuracy: 0.6092 - val_loss: 0.7405 - val_accuracy: 0.6328\n",
      "Epoch 604/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6415 - accuracy: 0.6464 - val_loss: 0.6796 - val_accuracy: 0.6255\n",
      "Epoch 605/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6282 - accuracy: 0.6353 - val_loss: 0.6627 - val_accuracy: 0.6292\n",
      "Epoch 606/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6174 - accuracy: 0.6559 - val_loss: 0.6962 - val_accuracy: 0.6384\n",
      "Epoch 607/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.6037 - accuracy: 0.6725 - val_loss: 0.7742 - val_accuracy: 0.6494\n",
      "Epoch 608/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5680 - accuracy: 0.7104 - val_loss: 0.7507 - val_accuracy: 0.6402\n",
      "Epoch 609/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5516 - accuracy: 0.7081 - val_loss: 0.8406 - val_accuracy: 0.6421\n",
      "Epoch 610/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5522 - accuracy: 0.7152 - val_loss: 0.7995 - val_accuracy: 0.6568\n",
      "Epoch 611/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5257 - accuracy: 0.7358 - val_loss: 0.8291 - val_accuracy: 0.6236\n",
      "Epoch 612/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5091 - accuracy: 0.7326 - val_loss: 0.9132 - val_accuracy: 0.6476\n",
      "Epoch 613/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4987 - accuracy: 0.7453 - val_loss: 0.9696 - val_accuracy: 0.6476\n",
      "Epoch 614/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4682 - accuracy: 0.7611 - val_loss: 1.1064 - val_accuracy: 0.6255\n",
      "Epoch 615/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4374 - accuracy: 0.7785 - val_loss: 1.2687 - val_accuracy: 0.6476\n",
      "Epoch 616/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4152 - accuracy: 0.7848 - val_loss: 1.5000 - val_accuracy: 0.6107\n",
      "Epoch 617/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3919 - accuracy: 0.7729 - val_loss: 1.4717 - val_accuracy: 0.6402\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3892 - accuracy: 0.7903 - val_loss: 1.7737 - val_accuracy: 0.6052\n",
      "Epoch 619/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3900 - accuracy: 0.7840 - val_loss: 1.8563 - val_accuracy: 0.6494\n",
      "Epoch 620/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3769 - accuracy: 0.8006 - val_loss: 1.5884 - val_accuracy: 0.6162\n",
      "Epoch 621/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3757 - accuracy: 0.7959 - val_loss: 1.3404 - val_accuracy: 0.6439\n",
      "Epoch 622/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3960 - accuracy: 0.7761 - val_loss: 1.3720 - val_accuracy: 0.6550\n",
      "Epoch 623/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4083 - accuracy: 0.7824 - val_loss: 1.9363 - val_accuracy: 0.5830\n",
      "Epoch 624/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4124 - accuracy: 0.7832 - val_loss: 1.4539 - val_accuracy: 0.6494\n",
      "Epoch 625/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4170 - accuracy: 0.7777 - val_loss: 1.5248 - val_accuracy: 0.5295\n",
      "Epoch 626/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4538 - accuracy: 0.7468 - val_loss: 1.2137 - val_accuracy: 0.6421\n",
      "Epoch 627/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4405 - accuracy: 0.7650 - val_loss: 1.4825 - val_accuracy: 0.5240\n",
      "Epoch 628/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4156 - accuracy: 0.7184 - val_loss: 1.5907 - val_accuracy: 0.6421\n",
      "Epoch 629/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3869 - accuracy: 0.7943 - val_loss: 1.6303 - val_accuracy: 0.6568\n",
      "Epoch 630/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3612 - accuracy: 0.7951 - val_loss: 1.5157 - val_accuracy: 0.6292\n",
      "Epoch 631/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3810 - accuracy: 0.7856 - val_loss: 1.3513 - val_accuracy: 0.6439\n",
      "Epoch 632/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3707 - accuracy: 0.7959 - val_loss: 1.4313 - val_accuracy: 0.6402\n",
      "Epoch 633/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3574 - accuracy: 0.8046 - val_loss: 1.4013 - val_accuracy: 0.6605\n",
      "Epoch 634/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3713 - accuracy: 0.8038 - val_loss: 1.6844 - val_accuracy: 0.6421\n",
      "Epoch 635/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3574 - accuracy: 0.8046 - val_loss: 1.9018 - val_accuracy: 0.6568\n",
      "Epoch 636/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3533 - accuracy: 0.8133 - val_loss: 1.4700 - val_accuracy: 0.6328\n",
      "Epoch 637/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3531 - accuracy: 0.8062 - val_loss: 1.4004 - val_accuracy: 0.6236\n",
      "Epoch 638/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3549 - accuracy: 0.8030 - val_loss: 1.5115 - val_accuracy: 0.6384\n",
      "Epoch 639/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3478 - accuracy: 0.8030 - val_loss: 1.7072 - val_accuracy: 0.6402\n",
      "Epoch 640/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3582 - accuracy: 0.8101 - val_loss: 1.9760 - val_accuracy: 0.6162\n",
      "Epoch 641/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3496 - accuracy: 0.8022 - val_loss: 2.0245 - val_accuracy: 0.6439\n",
      "Epoch 642/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3429 - accuracy: 0.8109 - val_loss: 2.0443 - val_accuracy: 0.6365\n",
      "Epoch 643/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3389 - accuracy: 0.8006 - val_loss: 2.1339 - val_accuracy: 0.6513\n",
      "Epoch 644/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3416 - accuracy: 0.8133 - val_loss: 2.1294 - val_accuracy: 0.6273\n",
      "Epoch 645/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3344 - accuracy: 0.8054 - val_loss: 2.0525 - val_accuracy: 0.6365\n",
      "Epoch 646/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3326 - accuracy: 0.8125 - val_loss: 2.1420 - val_accuracy: 0.6513\n",
      "Epoch 647/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3507 - accuracy: 0.8117 - val_loss: 2.1906 - val_accuracy: 0.6476\n",
      "Epoch 648/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3345 - accuracy: 0.8101 - val_loss: 2.1553 - val_accuracy: 0.6328\n",
      "Epoch 649/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3348 - accuracy: 0.8204 - val_loss: 2.2041 - val_accuracy: 0.6328\n",
      "Epoch 650/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3404 - accuracy: 0.8022 - val_loss: 2.4336 - val_accuracy: 0.6439\n",
      "Epoch 651/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3581 - accuracy: 0.8093 - val_loss: 2.2439 - val_accuracy: 0.6162\n",
      "Epoch 652/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3403 - accuracy: 0.8030 - val_loss: 2.1391 - val_accuracy: 0.6439\n",
      "Epoch 653/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3544 - accuracy: 0.8038 - val_loss: 2.3659 - val_accuracy: 0.6292\n",
      "Epoch 654/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3412 - accuracy: 0.8014 - val_loss: 2.4704 - val_accuracy: 0.6255\n",
      "Epoch 655/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3379 - accuracy: 0.8093 - val_loss: 2.5362 - val_accuracy: 0.6162\n",
      "Epoch 656/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3313 - accuracy: 0.8085 - val_loss: 2.4688 - val_accuracy: 0.6384\n",
      "Epoch 657/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3311 - accuracy: 0.8228 - val_loss: 2.5294 - val_accuracy: 0.6236\n",
      "Epoch 658/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3274 - accuracy: 0.8204 - val_loss: 2.6783 - val_accuracy: 0.6292\n",
      "Epoch 659/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3295 - accuracy: 0.8172 - val_loss: 2.3670 - val_accuracy: 0.6310\n",
      "Epoch 660/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3444 - accuracy: 0.8125 - val_loss: 2.3448 - val_accuracy: 0.6310\n",
      "Epoch 661/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3286 - accuracy: 0.8157 - val_loss: 2.8445 - val_accuracy: 0.6310\n",
      "Epoch 662/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3393 - accuracy: 0.8149 - val_loss: 1.9487 - val_accuracy: 0.6476\n",
      "Epoch 663/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3509 - accuracy: 0.8046 - val_loss: 1.9641 - val_accuracy: 0.6347\n",
      "Epoch 664/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3954 - accuracy: 0.7872 - val_loss: 2.4759 - val_accuracy: 0.6476\n",
      "Epoch 665/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5352 - accuracy: 0.7255 - val_loss: 1.2674 - val_accuracy: 0.6199\n",
      "Epoch 666/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5475 - accuracy: 0.7097 - val_loss: 1.2091 - val_accuracy: 0.6218\n",
      "Epoch 667/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5228 - accuracy: 0.7397 - val_loss: 0.9392 - val_accuracy: 0.6531\n",
      "Epoch 668/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5307 - accuracy: 0.7207 - val_loss: 0.8371 - val_accuracy: 0.6624\n",
      "Epoch 669/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5035 - accuracy: 0.7255 - val_loss: 0.9093 - val_accuracy: 0.5074\n",
      "Epoch 670/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.5023 - accuracy: 0.6851 - val_loss: 0.8366 - val_accuracy: 0.6439\n",
      "Epoch 671/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4839 - accuracy: 0.7421 - val_loss: 0.9404 - val_accuracy: 0.6347\n",
      "Epoch 672/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4637 - accuracy: 0.7532 - val_loss: 0.9751 - val_accuracy: 0.6292\n",
      "Epoch 673/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4643 - accuracy: 0.7437 - val_loss: 1.0171 - val_accuracy: 0.6255\n",
      "Epoch 674/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4518 - accuracy: 0.7460 - val_loss: 1.1497 - val_accuracy: 0.6421\n",
      "Epoch 675/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4662 - accuracy: 0.7555 - val_loss: 0.9623 - val_accuracy: 0.6605\n",
      "Epoch 676/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4639 - accuracy: 0.7381 - val_loss: 0.9164 - val_accuracy: 0.6236\n",
      "Epoch 677/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4790 - accuracy: 0.7476 - val_loss: 0.9628 - val_accuracy: 0.6476\n",
      "Epoch 678/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4588 - accuracy: 0.7484 - val_loss: 1.0959 - val_accuracy: 0.6568\n",
      "Epoch 679/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4435 - accuracy: 0.7682 - val_loss: 1.1716 - val_accuracy: 0.6218\n",
      "Epoch 680/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4429 - accuracy: 0.7460 - val_loss: 0.9915 - val_accuracy: 0.6531\n",
      "Epoch 681/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4532 - accuracy: 0.7595 - val_loss: 1.0986 - val_accuracy: 0.6310\n",
      "Epoch 682/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4321 - accuracy: 0.7619 - val_loss: 1.0700 - val_accuracy: 0.6458\n",
      "Epoch 683/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4236 - accuracy: 0.7706 - val_loss: 1.2237 - val_accuracy: 0.6273\n",
      "Epoch 684/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4143 - accuracy: 0.7650 - val_loss: 1.0557 - val_accuracy: 0.6550\n",
      "Epoch 685/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4236 - accuracy: 0.7729 - val_loss: 1.2135 - val_accuracy: 0.6347\n",
      "Epoch 686/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4126 - accuracy: 0.7729 - val_loss: 1.3078 - val_accuracy: 0.6402\n",
      "Epoch 687/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4046 - accuracy: 0.7832 - val_loss: 1.3295 - val_accuracy: 0.6070\n",
      "Epoch 688/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4196 - accuracy: 0.7682 - val_loss: 1.2920 - val_accuracy: 0.6439\n",
      "Epoch 689/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4028 - accuracy: 0.7745 - val_loss: 1.2739 - val_accuracy: 0.6384\n",
      "Epoch 690/700\n",
      "1000/1264 [======================>.......] - ETA: 1s - loss: 0.3977 - accuracy: 0.7820Epoch 691/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3948 - accuracy: 0.7848 - val_loss: 1.3924 - val_accuracy: 0.6384\n",
      "Epoch 692/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3907 - accuracy: 0.7896 - val_loss: 1.4022 - val_accuracy: 0.6384\n",
      "Epoch 693/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3893 - accuracy: 0.7816 - val_loss: 1.2699 - val_accuracy: 0.6513\n",
      "Epoch 694/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3961 - accuracy: 0.7832 - val_loss: 1.6530 - val_accuracy: 0.6273\n",
      "Epoch 695/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3948 - accuracy: 0.7832 - val_loss: 1.3977 - val_accuracy: 0.6587\n",
      "Epoch 696/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3822 - accuracy: 0.7983 - val_loss: 1.6857 - val_accuracy: 0.6292\n",
      "Epoch 697/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4100 - accuracy: 0.7848 - val_loss: 1.3738 - val_accuracy: 0.6365\n",
      "Epoch 698/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4052 - accuracy: 0.7785 - val_loss: 1.6417 - val_accuracy: 0.6328\n",
      "Epoch 699/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.4196 - accuracy: 0.7722 - val_loss: 1.3997 - val_accuracy: 0.6587\n",
      "Epoch 700/700\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3943 - accuracy: 0.7785 - val_loss: 1.2842 - val_accuracy: 0.6587\n"
     ]
    }
   ],
   "source": [
    "# from keras.optimizers import Adam\n",
    "# opt = Adam(lr=0.00001)\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.00001)\n",
    "from keras.callbacks import callbacks\n",
    "stopping = callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=30)\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=700,\n",
    "                    batch_size=500,\n",
    "#                     callbacks=[stopping],\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.575487881448305, 0.6544276475906372]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "grayscale_model_1 = load_model('../models/grayscale_model_1.h5')\n",
    "grayscale_model_1.evaluate(x=test_images, y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('../models/grayscale_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3493588840987203, 0.6371490359306335]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grayscale_model_2 = load_model('../models/grayscale_model_2.h5')\n",
    "grayscale_model_2.evaluate(x=test_images, y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
